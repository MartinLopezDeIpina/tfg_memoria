@misc{vaswani_attention_2023,
	title = {Attention Is All You Need},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	number = {{arXiv}:1706.03762},
	publisher = {{arXiv}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	urldate = {2025-03-21},
	date = {2023-08-02},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {PDF:/home/martin/Zotero/storage/DTPFS8X6/Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf},
}

@misc{wang_executable_2024,
	title = {Executable Code Actions Elicit Better {LLM} Agents},
	url = {http://arxiv.org/abs/2402.01030},
	abstract = {Large Language Model ({LLM}) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges. {LLM} agents are typically prompted to produce actions by generating {JSON} or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools). This work proposes to use executable Python code to consolidate {LLM} agents’ actions into a unified action space ({CodeAct}). Integrated with a Python interpreter, {CodeAct} can execute code actions and dynamically revise prior actions or emit new actions upon new observations through multi-turn interactions. Our extensive analysis of 17 {LLMs} on {APIBank} and a newly curated benchmark shows that {CodeAct} outperforms widely used alternatives (up to 20\% higher success rate). The encouraging performance of {CodeAct} motivates us to build an open-source {LLM} agent that interacts with environments by executing interpretable code and collaborates with users using natural language. To this end, we collect an instruction-tuning dataset {CodeActInstruct} that consists of 7k multi-turn interactions using {CodeAct}. We show that it can be used with existing data to improve models in agent-oriented tasks without compromising their general capability. {CodeActAgent}, finetuned from Llama2 and Mistral, is integrated with Python interpreter and uniquely tailored to perform sophisticated tasks (e.g., model training) using existing libraries and autonomously self-debug1.},
	number = {{arXiv}:2402.01030},
	publisher = {{arXiv}},
	author = {Wang, Xingyao and Chen, Yangyi and Yuan, Lifan and Zhang, Yizhe and Li, Yunzhu and Peng, Hao and Ji, Heng},
	urldate = {2025-03-10},
	date = {2024-06-07},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/HIDPKQJW/Wang et al. - 2024 - Executable Code Actions Elicit Better LLM Agents.pdf:application/pdf},
}

@misc{zhuge_mindstorms_2023,
	title = {Mindstorms in Natural Language-Based Societies of Mind},
	url = {http://arxiv.org/abs/2305.17066},
	abstract = {Both Minsky’s “society of mind” and Schmidhuber’s “learning to think” inspire diverse societies of large multimodal neural networks ({NNs}) that solve problems by interviewing each other in a “mindstorm.” Recent implementations of {NN}-based societies of minds consist of large language models ({LLMs}) and other {NN}-based experts communicating through a natural language interface. In doing so, they overcome the limitations of single {LLMs}, improving multimodal zero-shot reasoning. In these natural language-based societies of mind ({NLSOMs}), new agents—all communicating through the same universal symbolic language—are easily added in a modular fashion. To demonstrate the power of {NLSOMs}, we assemble and experiment with several of them (having up to 129 members), leveraging mindstorms in them to solve some practical {AI} tasks: visual question answering, image captioning, text-to-image synthesis, 3D generation, egocentric retrieval, embodied {AI}, and general language-based task solving. We view this as a starting point towards much larger {NLSOMs} with billions of agents—some of which may be humans. And with this emergence of great societies of heterogeneous minds, many new research questions have suddenly become paramount to the future of artificial intelligence. What should be the social structure of an {NLSOM}? What would be the (dis)advantages of having a monarchical rather than a democratic structure? How can principles of {NN} economies be used to maximize the total reward of a reinforcement learning {NLSOM}? In this work, we identify, discuss, and try to answer some of these questions.},
	number = {{arXiv}:2305.17066},
	publisher = {{arXiv}},
	author = {Zhuge, Mingchen and Liu, Haozhe and Faccio, Francesco and Ashley, Dylan R. and Csordás, Róbert and Gopalakrishnan, Anand and Hamdi, Abdullah and Hammoud, Hasan Abed Al Kader and Herrmann, Vincent and Irie, Kazuki and Kirsch, Louis and Li, Bing and Li, Guohao and Liu, Shuming and Mai, Jinjie and Piękos, Piotr and Ramesh, Aditya and Schlag, Imanol and Shi, Weimin and Stanić, Aleksandar and Wang, Wenyi and Wang, Yuhui and Xu, Mengmeng and Fan, Deng-Ping and Ghanem, Bernard and Schmidhuber, Jürgen},
	urldate = {2025-03-09},
	date = {2023-05-26},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Multiagent Systems},
	file = {PDF:/home/martin/Zotero/storage/XAT4WM7F/Zhuge et al. - 2023 - Mindstorms in Natural Language-Based Societies of Mind.pdf:application/pdf},
}

@misc{madaan_memory-assisted_2023,
	title = {Memory-assisted prompt editing to improve {GPT}-3 after deployment},
	url = {http://arxiv.org/abs/2201.06009},
	abstract = {Large {LMs} such as {GPT}-3 are powerful, but can commit mistakes that are obvious to humans. For example, {GPT}-3 would mistakenly interpret "What word is similar to good?" to mean a homophone, while the user intended a synonym. Our goal is to effectively correct such errors via user interactions with the system but without retraining, which will be prohibitively costly. We pair {GPT}-3 with a growing memory of recorded cases where the model misunderstood the user's intents, along with user feedback for clarification. Such a memory allows our system to produce enhanced prompts for any new query based on the user feedback for error correction on similar cases in the past. On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed {GPT}-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the {GPT}-3. Our approach is a step towards the low-cost utility enhancement for very large pre-trained {LMs}. Code, data, and instructions to implement {MEMPROMPT} for a new task at https://www.memprompt.com/.},
	number = {{arXiv}:2201.06009},
	publisher = {{arXiv}},
	author = {Madaan, Aman and Tandon, Niket and Clark, Peter and Yang, Yiming},
	urldate = {2025-03-09},
	date = {2023-02-18},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/H2Q8BWV5/Madaan et al. - 2023 - Memory-assisted prompt editing to improve GPT-3 after deployment.pdf:application/pdf},
}

@article{du_improving_nodate,
	title = {Improving Factuality and Reasoning in Language Models  through Multiagent Debate},
	abstract = {Large language models ({LLMs}) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such "society of minds" approach has the potential to significantly advance the capabilities of {LLMs} and pave the way for further breakthroughs in language generation and understanding.},
	author = {Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/F9F8DDUM/Du et al. - Improving Factuality and Reasoning in Language Models  through Multiagent Debate.pdf:application/pdf},
}

@misc{zhang_prefer_2023,
	title = {{PREFER}: Prompt Ensemble Learning via Feedback-Reflect-Refine},
	url = {http://arxiv.org/abs/2308.12033},
	shorttitle = {{PREFER}},
	abstract = {As an effective tool for eliciting the power of Large Language Models ({LLMs}), prompting has recently demonstrated unprecedented abilities across a variety of complex tasks. To further improve the performance, prompt ensemble has attracted substantial interest for tackling the hallucination and instability of {LLMs}. However, existing methods usually adopt a two-stage paradigm, which requires a pre-prepared set of prompts with substantial manual effort, and is unable to perform directed optimization for different weak learners. In this paper, we propose a simple, universal, and automatic method named {PREFER} (Pompt Ensemble learning via Feedback-Reflect-Refine) to address the stated limitations. Specifically, given the fact that weak learners are supposed to focus on hard examples during boosting, {PREFER} builds a feedback mechanism for reflecting on the inadequacies of existing weak learners. Based on this, the {LLM} is required to automatically synthesize new prompts for iterative refinement. Moreover, to enhance stability of the prompt effect evaluation, we propose a novel prompt bagging method involving forward and backward thinking, which is superior to majority voting and is beneficial for both feedback and weight calculation in boosting. Extensive experiments demonstrate that our {PREFER} achieves state-of-the-art performance in multiple types of tasks by a significant margin. We have made our code publicly available.},
	number = {{arXiv}:2308.12033},
	publisher = {{arXiv}},
	author = {Zhang, Chenrui and Liu, Lin and Wang, Jinpeng and Wang, Chuyuan and Sun, Xiao and Wang, Hongyu and Cai, Mingchen},
	urldate = {2025-03-09},
	date = {2023-08-23},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/CIU4L7UM/Zhang et al. - 2023 - PREFER Prompt Ensemble Learning via Feedback-Reflect-Refine.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/FFA8SZSY/2308.html:text/html},
}

@misc{yao_retroformer_2024,
	title = {Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization},
	url = {http://arxiv.org/abs/2308.02151},
	shorttitle = {Retroformer},
	abstract = {Recent months have seen the emergence of a powerful new trend in which large language models ({LLMs}) are augmented to become autonomous language agents capable of performing objective oriented multi-step tasks on their own, rather than merely responding to queries from human users. Most existing language agents, however, are not optimized using environment-specific rewards. Although some agents enable iterative refinement through verbal feedback, they do not reason and plan in ways that are compatible with gradient-based learning from rewards. This paper introduces a principled framework for reinforcing large language agents by learning a retrospective model, which automatically tunes the language agent prompts from environment feedback through policy gradient. Specifically, our proposed agent architecture learns from rewards across multiple environments and tasks, for fine-tuning a pre-trained language model which refines the language agent prompt by summarizing the root cause of prior failed attempts and proposing action plans. Experimental results on various tasks demonstrate that the language agents improve over time and that our approach considerably outperforms baselines that do not properly leverage gradients from the environment.},
	number = {{arXiv}:2308.02151},
	publisher = {{arXiv}},
	author = {Yao, Weiran and Heinecke, Shelby and Niebles, Juan Carlos and Liu, Zhiwei and Feng, Yihao and Xue, Le and Murthy, Rithesh and Chen, Zeyuan and Zhang, Jianguo and Arpit, Devansh and Xu, Ran and Mui, Phil and Wang, Huan and Xiong, Caiming and Savarese, Silvio},
	urldate = {2025-03-09},
	date = {2024-05-05},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/4JJ6NZ9N/Yao et al. - 2024 - Retroformer Retrospective Large Language Agents with Policy Gradient Optimization.pdf:application/pdf},
}

@misc{ahn_as_2022,
	title = {Do As I Can, Not As I Say: Grounding Language in Robotic Affordances},
	url = {http://arxiv.org/abs/2204.01691},
	shorttitle = {Do As I Can, Not As I Say},
	abstract = {Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a signiﬁcant weakness of language models is that they lack real-world experience, which makes it difﬁcult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, the video, and open sourced code in a tabletop domain can be found at say-can.github.io.},
	number = {{arXiv}:2204.01691},
	publisher = {{arXiv}},
	author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Ho, Daniel and Hsu, Jasmine and Ibarz, Julian and Ichter, Brian and Irpan, Alex and Jang, Eric and Ruano, Rosario Jauregui and Jeffrey, Kyle and Jesmonth, Sally and Joshi, Nikhil J. and Julian, Ryan and Kalashnikov, Dmitry and Kuang, Yuheng and Lee, Kuang-Huei and Levine, Sergey and Lu, Yao and Luu, Linda and Parada, Carolina and Pastor, Peter and Quiambao, Jornell and Rao, Kanishka and Rettinghouse, Jarek and Reyes, Diego and Sermanet, Pierre and Sievers, Nicolas and Tan, Clayton and Toshev, Alexander and Vanhoucke, Vincent and Xia, Fei and Xiao, Ted and Xu, Peng and Xu, Sichun and Yan, Mengyuan and Zeng, Andy},
	urldate = {2025-03-09},
	date = {2022-08-16},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Robotics},
	file = {PDF:/home/martin/Zotero/storage/XCWTCXZL/Ahn et al. - 2022 - Do As I Can, Not As I Say Grounding Language in Robotic Affordances.pdf:application/pdf},
}

@misc{wang_user_2024,
	title = {User Behavior Simulation with Large Language Model based Agents},
	url = {http://arxiv.org/abs/2306.02552},
	abstract = {Simulating high quality user behavior data has always been a fundamental problem in humancentered applications, where the major difficulty originates from the intricate mechanism of human decision process. Recently, substantial evidences have suggested that by learning huge amounts of web knowledge, large language models ({LLMs}) can achieve human-like intelligence. We believe these models can provide significant opportunities to more believable user behavior simulation. To inspire such direction, we propose an {LLM}-based agent framework and design a sandbox environment to simulate real user behaviors. Based on extensive experiments, we find that the simulated behaviors of our method are very close to the ones of real humans. Concerning potential applications, we simulate and study two social phenomenons including (1) information cocoons and (2) user conformity behaviors. This research provides novel simulation paradigms for human-centered applications.},
	number = {{arXiv}:2306.02552},
	publisher = {{arXiv}},
	author = {Wang, Lei and Zhang, Jingsen and Yang, Hao and Chen, Zhiyuan and Tang, Jiakai and Zhang, Zeyu and Chen, Xu and Lin, Yankai and Song, Ruihua and Zhao, Wayne Xin and Xu, Jun and Dou, Zhicheng and Wang, Jun and Wen, Ji-Rong},
	urldate = {2025-03-09},
	date = {2024-02-15},
	langid = {english},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval},
	file = {PDF:/home/martin/Zotero/storage/3U3BMXUE/Wang et al. - 2024 - User Behavior Simulation with Large Language Model based Agents.pdf:application/pdf},
}

@article{ge_openagi_nodate,
	title = {{OpenAGI}: When {LLM} Meets Domain Experts},
	abstract = {Human Intelligence ({HI}) excels at combining basic skills to solve complex tasks. This capability is vital for Artificial Intelligence ({AI}) and should be embedded in comprehensive {AI} Agents, enabling them to harness expert models for complex task-solving towards Artificial General Intelligence ({AGI}). Large Language Models ({LLMs}) show promising learning and reasoning abilities, and can effectively use external models, tools, plugins, or {APIs} to tackle complex problems. In this work, we introduce {OpenAGI}, an open-source {AGI} research and development platform designed for solving multi-step, real-world tasks. Specifically, {OpenAGI} uses a dual strategy, integrating standard benchmark tasks for benchmarking and evaluation, and open-ended tasks including more expandable models, tools, plugins, or {APIs} for creative problem-solving. Tasks are presented as natural language queries to the {LLM}, which then selects and executes appropriate models. We also propose a Reinforcement Learning from Task Feedback ({RLTF}) mechanism that uses task results to improve the {LLM}’s task-solving ability, which creates a self-improving {AI} feedback loop. While we acknowledge that {AGI} is a broad and multifaceted research challenge with no singularly defined solution path, the integration of {LLMs} with domain-specific expert models, inspired by mirroring the blend of general and specialized intelligence in humans, offers a promising approach towards {AGI}. We are open-sourcing the {OpenAGI} project’s code, dataset, benchmarks, evaluation methods, and the {UI} demo to foster community involvement in {AGI} advancement: https://github.com/agiresearch/{OpenAGI}.},
	author = {Ge, Yingqiang and Hua, Wenyue and Mei, Kai and Ji, Jianchao and Tan, Juntao and Xu, Shuyuan and Li, Zelong and Zhang, Yongfeng},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/BR8IBH4K/Ge et al. - OpenAGI When LLM Meets Domain Experts.pdf:application/pdf},
}

@misc{karpas_mrkl_2022,
	title = {{MRKL} Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning},
	url = {http://arxiv.org/abs/2205.00445},
	shorttitle = {{MRKL} Systems},
	abstract = {Huge language models ({LMs}) have ushered in a new era for {AI}, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern {AI}, {LMs} are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we deﬁne a ﬂexible architecture with multiple neural models, complemented by discrete knowledge and reasoning modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language ({MRKL}, pronounced “miracle”) system, some of the technical challenges in implementing it, and Jurassic-X, {AI}21 Labs’ {MRKL} system implementation.},
	number = {{arXiv}:2205.00445},
	publisher = {{arXiv}},
	author = {Karpas, Ehud and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and Leyton-Brown, Kevin and Muhlgay, Dor and Rozen, Noam and Schwartz, Erez and Shachaf, Gal and Shalev-Shwartz, Shai and Shashua, Amnon and Tenenholtz, Moshe},
	urldate = {2025-03-08},
	date = {2022-05-01},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/7REC92QS/Karpas et al. - 2022 - MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external k.pdf:application/pdf},
}

@misc{song_restgpt_2023,
	title = {{RestGPT}: Connecting Large Language Models with Real-World {RESTful} {APIs}},
	url = {http://arxiv.org/abs/2306.06624},
	shorttitle = {{RestGPT}},
	abstract = {Tool-augmented large language models ({LLMs}) have achieved remarkable progress in tackling a broad range of tasks. However, existing methods are mainly restricted to specifically designed tools and fail to fulfill complex instructions, having great limitations when confronted with real-world scenarios. In this paper, we explore a more realistic scenario by connecting {LLMs} with {RESTful} {APIs}, which adhere to the widely adopted {REST} software architectural style for web service development. To address the practical challenges of tackling complex instructions, we propose {RestGPT}, which exploits the power of {LLMs} and conducts a coarse-to-fine online planning mechanism to enhance the abilities of task decomposition and {API} selection. {RestGPT} also contains an {API} executor tailored for calling {RESTful} {APIs}, which can meticulously formulate parameters and parse {API} responses. To fully evaluate the performance of {RestGPT}, we propose {RestBench}, a high-quality benchmark which consists of two real-world scenarios and human-annotated instructions with gold solution paths. Experiments show that {RestGPT} is able to achieve impressive results in complex tasks and has strong robustness, which paves a new way towards {AGI}.},
	number = {{arXiv}:2306.06624},
	publisher = {{arXiv}},
	author = {Song, Yifan and Xiong, Weimin and Zhu, Dawei and Wu, Wenhao and Qian, Han and Song, Mingbo and Huang, Hailiang and Li, Cheng and Wang, Ke and Yao, Rong and Tian, Ye and Li, Sujian},
	urldate = {2025-03-08},
	date = {2023-08-27},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/SDRNQ6Z6/Song et al. - 2023 - RestGPT Connecting Large Language Models with Real-World RESTful APIs.pdf:application/pdf},
}

@misc{qin_toolllm_2023,
	title = {{ToolLLM}: Facilitating Large Language Models to Master 16000+ Real-world {APIs}},
	url = {http://arxiv.org/abs/2307.16789},
	shorttitle = {{ToolLLM}},
	abstract = {Despite the advancements of open-source large language models ({LLMs}), e.g., {LLaMA}, they remain significantly limited in tool-use capabilities, i.e., using external tools ({APIs}) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art ({SOTA}) closed-source {LLMs}, e.g., {ChatGPT}. To bridge this gap, we introduce {ToolLLM}, a general tool-use framework encompassing data construction, model training, and evaluation. We first present {ToolBench}, an instruction-tuning dataset for tool use, which is constructed automatically using {ChatGPT}. Specifically, the construction can be divided into three stages: (i) {API} collection: we collect 16, 464 real-world {RESTful} {APIs} spanning 49 categories from {RapidAPI} Hub; (ii) instruction generation: we prompt {ChatGPT} to generate diverse instructions involving these {APIs}, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use {ChatGPT} to search for a valid solution path (chain of {API} calls) for each instruction. To enhance the reasoning capabilities of {LLMs}, we develop a novel depth-first search-based decision tree algorithm. It enables {LLMs} to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of {LLMs}, we develop an automatic evaluator: {ToolEval}. Based on {ToolBench}, we fine-tune {LLaMA} to obtain an {LLM} {ToolLLaMA}, and equip it with a neural {API} retriever to recommend appropriate {APIs} for each instruction. Experiments show that {ToolLLaMA} demonstrates a remarkable ability to execute complex instructions and generalize to unseen {APIs}, and exhibits comparable performance to {ChatGPT}. Our {ToolLLaMA} also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: {APIBench}. The codes, trained models, and demo are publicly available at https://github.com/{OpenBMB}/{ToolBench}.},
	number = {{arXiv}:2307.16789},
	publisher = {{arXiv}},
	author = {Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and Zhao, Sihan and Hong, Lauren and Tian, Runchu and Xie, Ruobing and Zhou, Jie and Gerstein, Mark and Li, Dahai and Liu, Zhiyuan and Sun, Maosong},
	urldate = {2025-03-08},
	date = {2023-10-03},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/QTII83YP/Qin et al. - 2023 - ToolLLM Facilitating Large Language Models to Master 16000+ Real-world APIs.pdf:application/pdf},
}

@misc{li_api-bank_2023,
	title = {{API}-Bank: A Comprehensive Benchmark for Tool-Augmented {LLMs}},
	url = {http://arxiv.org/abs/2304.08244},
	shorttitle = {{API}-Bank},
	abstract = {Recent research has demonstrated that Large Language Models ({LLMs}) can enhance their capabilities by utilizing external tools. However, three pivotal questions remain unanswered: (1) How effective are current {LLMs} in utilizing tools? (2) How can we enhance {LLMs}’ ability to utilize tools? (3) What obstacles need to be overcome to leverage tools? To address these questions, we introduce {API}-Bank, a groundbreaking benchmark, specifically designed for tool-augmented {LLMs}. For the first question, we develop a runnable evaluation system consisting of 73 {API} tools. We annotate 314 tool-use dialogues with 753 {API} calls to assess the existing {LLMs}’ capabilities in planning, retrieving, and calling {APIs}. For the second question, we construct a comprehensive training set containing 1,888 tool-use dialogues from 2,138 {APIs} spanning 1,000 distinct domains. Using this dataset, we train Lynx, a tool-augmented {LLM} initialized from Alpaca. Experimental results demonstrate that {GPT}-3.5 exhibits improved tool utilization compared to {GPT}-3, while {GPT}-4 excels in planning. However, there is still significant potential for further improvement. Moreover, Lynx surpasses Alpaca’s tool utilization performance by more than 26 pts and approaches the effectiveness of {GPT}-3.5. Through error analysis, we highlight the key challenges for future research in this field to answer the third question 1.},
	number = {{arXiv}:2304.08244},
	publisher = {{arXiv}},
	author = {Li, Minghao and Zhao, Yingxiu and Yu, Bowen and Song, Feifan and Li, Hangyu and Yu, Haiyang and Li, Zhoujun and Huang, Fei and Li, Yongbin},
	urldate = {2025-03-08},
	date = {2023-10-25},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/JXMA3L4C/Li et al. - 2023 - API-Bank A Comprehensive Benchmark for Tool-Augmented LLMs.pdf:application/pdf},
}

@article{patil_gorilla_nodate,
	title = {Gorilla: Large Language Model Connected with Massive {APIs}},
	author = {Patil, Shishir G and Zhang, Tianjun and Wang, Xin and Gonzalez, Joseph E},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/CWAQSM3W/Patil et al. - Gorilla Large Language Model Connected with Massive APIs.pdf:application/pdf},
}

@article{ruan_tptu_nodate,
	title = {{TPTU}: Task Planning and Tool Usage of Large Language Model-based {AI} Agents},
	abstract = {With recent advancements in natural language processing, Large Language Models ({LLMs}) have emerged as powerful tools for various real-world applications. Despite their powers, the intrinsic generative abilities of {LLMs} may prove insufficient for handling complex tasks, which necessitate a combination of task planning and the usage of external tools. In this paper, we first propose a structured framework tailored for {LLM}-based {AI} Agents and then discuss the crucial capabilities necessary for tackling intricate problems. Within this framework, we design two distinct types of agents (i.e., one-step agent and sequential agent) to execute the inference process. Subsequently, we instantiate the framework using various {LLMs} and evaluate their Task Planning and Tool Usage ({TPTU}) abilities on typical tasks. By highlighting key findings and challenges, our goal is to provide a helpful resource for researchers and practitioners to leverage the power of {LLMs} in their {AI} applications. Our study emphasizes the substantial potential of these models while also identifying areas that need more investigation and improvement. The code and resources will be available on {GitHub}.},
	author = {Ruan, Jingqing and Chen, Yihong and Zhang, Bin and Xu, Zhiwei},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/8HSDEYR4/Ruan et al. - TPTU Task Planning and Tool Usage of Large Language Model-based AI Agents.pdf:application/pdf},
}

@article{nakano_webgpt_nodate,
	title = {{WebGPT}: Browser-assisted question-answering with human feedback},
	abstract = {We ﬁne-tune {GPT}-3 to answer long-form questions using a text-based webbrowsing environment, which allows the model to search and navigate the web. By setting up the task so that it can be performed by humans, we are able to train models on the task using imitation learning, and then optimize answer quality with human feedback. To make human evaluation of factual accuracy easier, models must collect references while browsing in support of their answers. We train and evaluate our models on {ELI}5, a dataset of questions asked by Reddit users. Our best model is obtained by ﬁne-tuning {GPT}-3 using behavior cloning, and then performing rejection sampling against a reward model trained to predict human preferences. This model’s answers are preferred by humans 56\% of the time to those of our human demonstrators, and 69\% of the time to the highest-voted answer from Reddit.},
	author = {Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and Jiang, Xu and Cobbe, Karl and Eloundou, Tyna and Krueger, Gretchen and Button, Kevin and Knight, Matthew and Chess, Benjamin and Schulman, John},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/5JUVJSQ5/Nakano et al. - WebGPT Browser-assisted question-answering with human feedback.pdf:application/pdf},
}

@misc{hong_metagpt_2024,
	title = {{MetaGPT}: Meta Programming for A Multi-Agent Collaborative Framework},
	url = {http://arxiv.org/abs/2308.00352},
	shorttitle = {{MetaGPT}},
	abstract = {Remarkable progress has been made on automated problem solving through societies of agents based on large language models ({LLMs}). Existing {LLM}-based multi-agent systems can already solve simple dialogue tasks. Solutions to more complex tasks, however, are complicated through logic inconsistencies due to cascading hallucinations caused by naively chaining {LLMs}. Here we introduce {MetaGPT}, an innovative meta-programming framework incorporating efficient human workflows into {LLM}-based multi-agent collaborations. {MetaGPT} encodes Standardized Operating Procedures ({SOPs}) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors. {MetaGPT} utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together. On collaborative software engineering benchmarks, {MetaGPT} generates more coherent solutions than previous chat-based multi-agent systems. Our project can be found at https://github.com/geekan/{MetaGPT}.},
	number = {{arXiv}:2308.00352},
	publisher = {{arXiv}},
	author = {Hong, Sirui and Zhuge, Mingchen and Chen, Jiaqi and Zheng, Xiawu and Cheng, Yuheng and Zhang, Ceyao and Wang, Jinlin and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and Ran, Chenyu and Xiao, Lingfeng and Wu, Chenglin and Schmidhuber, Jürgen},
	urldate = {2025-03-08},
	date = {2024-11-01},
	langid = {english},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
	file = {PDF:/home/martin/Zotero/storage/D7AIW7Y7/Hong et al. - 2024 - MetaGPT Meta Programming for A Multi-Agent Collaborative Framework.pdf:application/pdf},
}

@misc{chen_chatcot_2023,
	title = {{ChatCoT}: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models},
	url = {http://arxiv.org/abs/2305.14323},
	shorttitle = {{ChatCoT}},
	abstract = {Although large language models ({LLMs}) have achieved excellent performance in a variety of evaluation benchmarks, they still struggle in complex reasoning tasks which require specific knowledge and multi-hop reasoning. To improve the reasoning abilities, we propose {ChatCoT}, a tool-augmented chain-of-thought reasoning framework for chat-based {LLMs} (e.g., {ChatGPT}). In {ChatCoT}, we model the chainof-thought ({CoT}) reasoning as multi-turn conversations, to utilize tools in a more natural way through chatting. At each turn, {LLMs} can either interact with tools or perform the reasoning. Our approach can effectively leverage the multi-turn conversation ability of chatbased {LLMs}, and integrate the thought chain following and tools manipulation in a unified way. Specially, we initialize the early turns of the conversation by the knowledge about tools, tasks, and reasoning format, and propose an iterative tool-augmented reasoning step to perform step-by-step tool-augmented reasoning. The experiment results on two complex reasoning datasets ({MATH} and {HotpotQA}) have shown the effectiveness of {ChatCoT} on complex reasoning tasks, achieving a 7.9\% relative improvement over the state-of-the-art baseline. Our code and data are available at: https://github.com/{RUCAIBOX}/{ChatCoT}.},
	number = {{arXiv}:2305.14323},
	publisher = {{arXiv}},
	author = {Chen, Zhipeng and Zhou, Kun and Zhang, Beichen and Gong, Zheng and Zhao, Wayne Xin and Wen, Ji-Rong},
	urldate = {2025-03-07},
	date = {2023-11-06},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/S5PZEPGC/Chen et al. - 2023 - ChatCoT Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models.pdf:application/pdf},
}

@misc{miao_selfcheck_2023,
	title = {{SelfCheck}: Using {LLMs} to Zero-Shot Check Their Own Step-by-Step Reasoning},
	url = {http://arxiv.org/abs/2308.00436},
	shorttitle = {{SelfCheck}},
	abstract = {The recent progress in large language models ({LLMs}), especially the invention of chain-of-thought prompting, has made it possible to automatically answer questions by stepwise reasoning. However, when faced with more complicated problems that require non-linear thinking, even the strongest {LLMs} make mistakes. To address this, we explore whether {LLMs} are able to recognize errors in their own step-bystep reasoning, without resorting to external resources. To this end, we propose {SelfCheck}, a general-purpose zero-shot verification schema for recognizing such errors. We then use the results of these checks to improve question-answering performance by conducting weighted voting on multiple solutions to the question. We test {SelfCheck} on three datasets—{GSM}8K, {MathQA}, and {MATH}—and find that it successfully recognizes errors and, in turn, increases final answer accuracies.},
	number = {{arXiv}:2308.00436},
	publisher = {{arXiv}},
	author = {Miao, Ning and Teh, Yee Whye and Rainforth, Tom},
	urldate = {2025-03-07},
	date = {2023-10-05},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/9Q9BT5B6/Miao et al. - 2023 - SelfCheck Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning.pdf:application/pdf},
}

@article{madaan_self-refine_nodate,
	title = {{SELF}-{REFINE}: Iterative Refinement with Self-Feedback},
	abstract = {Like humans, large language models ({LLMs}) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce {SELF}-{REFINE}, an approach for improving initial outputs from {LLMs} through iterative feedback and refinement. The main idea is to generate an initial output using an {LLM}; then, the same {LLM} provides feedback for its output and uses it to refine itself, iteratively. {SELF}-{REFINE} does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single {LLM} as the generator, refiner, and feedback provider. We evaluate {SELF}-{REFINE} across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art ({GPT}-3.5 and {GPT}-4) {LLMs}. Across all evaluated tasks, outputs generated with {SELF}-{REFINE} are preferred by humans and automatic metrics over those generated with the same {LLM} using conventional one-step generation, improving by ∼20\% absolute on average in task performance. Our work demonstrates that even state-of-the-art {LLMs} like {GPT}-4 can be further improved at test-time using our simple, standalone approach.2.},
	author = {Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and Gupta, Shashank and Majumder, Bodhisattwa Prasad and Hermann, Katherine and Welleck, Sean and Yazdanbakhsh, Amir and Clark, Peter},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/MG58XESZ/Madaan et al. - SELF-REFINE Iterative Refinement with Self-Feedback.pdf:application/pdf},
}

@misc{huang_inner_2022,
	title = {Inner Monologue: Embodied Reasoning through Planning with Language Models},
	url = {http://arxiv.org/abs/2207.05608},
	shorttitle = {Inner Monologue},
	abstract = {Recent works have shown how the reasoning capabilities of Large Language Models ({LLMs}) can be applied to domains beyond natural language processing, such as planning and interaction for robots. These embodied problems require an agent to understand many semantic aspects of the world: the repertoire of skills available, how these skills influence the world, and how changes to the world map back to the language. {LLMs} planning in embodied environments need to consider not just what skills to do, but also how and when to do them - answers that change over time in response to the agent’s own choices. In this work, we investigate to what extent {LLMs} used in such embodied contexts can reason over sources of feedback provided through natural language, without any additional training. We propose that by leveraging environment feedback, {LLMs} are able to form an inner monologue that allows them to more richly process and plan in robotic control scenarios. We investigate a variety of sources of feedback, such as success detection, scene description, and human interaction. We find that closed-loop language feedback significantly improves high-level instruction completion on three domains, including simulated and real table top rearrangement tasks and long-horizon mobile manipulation tasks in a kitchen environment in the real world.},
	number = {{arXiv}:2207.05608},
	publisher = {{arXiv}},
	author = {Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and Sermanet, Pierre and Brown, Noah and Jackson, Tomas and Luu, Linda and Levine, Sergey and Hausman, Karol and Ichter, Brian},
	urldate = {2025-03-07},
	date = {2022-07-12},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {PDF:/home/martin/Zotero/storage/4R387VNH/Huang et al. - 2022 - Inner Monologue Embodied Reasoning through Planning with Language Models.pdf:application/pdf},
}

@inproceedings{song_llm-planner_2023,
	location = {Paris, France},
	title = {{LLM}-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-0718-4},
	url = {https://ieeexplore.ieee.org/document/10378628/},
	shorttitle = {{LLM}-Planner},
	eventtitle = {2023 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	pages = {2986--2997},
	booktitle = {2023 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Song, Chan Hee and Sadler, Brian M. and Wu, Jiaman and Chao, Wei-Lun and Washington, Clayton and Su, Yu},
	urldate = {2025-03-07},
	date = {2023-10-01},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/BXE7CQNL/Song et al. - 2023 - LLM-Planner Few-Shot Grounded Planning for Embodied Agents with Large Language Models.pdf:application/pdf},
}

@misc{zhang_building_2024,
	title = {Building Cooperative Embodied Agents Modularly with Large Language Models},
	url = {http://arxiv.org/abs/2307.02485},
	abstract = {In this work, we address challenging multi-agent cooperation problems with decentralized control, raw sensory observations, costly communication, and multiobjective tasks instantiated in various embodied environments. While previous research either presupposes a cost-free communication channel or relies on a centralized controller with shared observations, we harness the commonsense knowledge, reasoning ability, language comprehension, and text generation prowess of {LLMs} and seamlessly incorporate them into a cognitive-inspired modular framework that integrates with perception, memory, and execution. Thus building a Cooperative Embodied Language Agent {CoELA}, who can plan, communicate, and cooperate with others to accomplish long-horizon tasks efficiently. Our experiments on {CWAH} and {TDW}-{MAT} demonstrate that {CoELA} driven by {GPT}-4 can surpass strong planning-based methods and exhibit emergent effective communication. Though current Open {LMs} like {LLAMA}-2 still underperform, we fine-tune a {CoLLAMA} with data collected with our agents and show how they can achieve promising performance. We also conducted a user study for human-agent interaction and discovered that {CoELA} communicating in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of {LLMs} for future research in multi-agent cooperation. Videos can be found on the project website https://vis-www.cs.umass.edu/Co-{LLM}-Agents/.},
	number = {{arXiv}:2307.02485},
	publisher = {{arXiv}},
	author = {Zhang, Hongxin and Du, Weihua and Shan, Jiaming and Zhou, Qinhong and Du, Yilun and Tenenbaum, Joshua B. and Shu, Tianmin and Gan, Chuang},
	urldate = {2025-03-07},
	date = {2024-02-17},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/martin/Zotero/storage/KACH4E7Y/Zhang et al. - 2024 - Building Cooperative Embodied Agents Modularly with Large Language Models.pdf:application/pdf},
}

@misc{dagan_dynamic_2023,
	title = {Dynamic Planning with a {LLM}},
	url = {http://arxiv.org/abs/2308.06391},
	abstract = {While Large Language Models ({LLMs}) can solve many {NLP} tasks in zero-shot settings, applications involving embodied agents remain problematic. In particular, complex plans that require multi-step reasoning become difficult and too costly as the context window grows. Planning requires understanding the likely effects of one’s actions and identifying whether the current environment satisfies the goal state. While symbolic planners find optimal solutions quickly, they require a complete and accurate representation of the planning problem, severely limiting their use in practical scenarios. In contrast, modern {LLMs} cope with noisy observations and high levels of uncertainty when reasoning about a task. Our work presents {LLM} Dynamic Planner ({LLM}-{DP}): a neurosymbolic framework where an {LLM} works hand-in-hand with a traditional planner to solve an embodied task. Given action-descriptions, {LLM}-{DP} solves Alfworld faster and more efficiently than a naive {LLM} {ReAct} baseline.},
	number = {{arXiv}:2308.06391},
	publisher = {{arXiv}},
	author = {Dagan, Gautier and Keller, Frank and Lascarides, Alex},
	urldate = {2025-03-07},
	date = {2023-08-11},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Robotics},
	file = {PDF:/home/martin/Zotero/storage/D3U2QCTU/Dagan et al. - 2023 - Dynamic Planning with a LLM.pdf:application/pdf},
}

@misc{liu_llmp_2023,
	title = {{LLM}+P: Empowering Large Language Models with Optimal Planning Proficiency},
	url = {http://arxiv.org/abs/2304.11477},
	shorttitle = {{LLM}+P},
	abstract = {Large language models ({LLMs}) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, {LLMs} cannot reliably solve long-horizon planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces {LLM}+P, the first framework that incorporates the strengths of classical planners into {LLMs}. {LLM}+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. {LLM}+P does so by first converting the language description into a file written in the planning domain definition language ({PDDL}), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with {LLM}+P, we define a diverse set of different benchmark problems taken from common planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that {LLM}+P is able to provide optimal solutions for most problems, while {LLMs} fail to provide even feasible plans for most problems.{\textbackslash}footnote\{The code and results are publicly available at https://github.com/Cranial-{XIX}/llm-pddl.git.},
	number = {{arXiv}:2304.11477},
	publisher = {{arXiv}},
	author = {Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
	urldate = {2025-03-07},
	date = {2023-09-27},
	langid = {english},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
	file = {PDF:/home/martin/Zotero/storage/WABZTDZS/Liu et al. - 2023 - LLM+P Empowering Large Language Models with Optimal Planning Proficiency.pdf:application/pdf},
}
}

@misc{hao_reasoning_2023,
	title = {Reasoning with Language Model is Planning with World Model},
	url = {http://arxiv.org/abs/2305.14992},
	abstract = {Large language models ({LLMs}) have shown remarkable reasoning capabilities, especially when prompted to generate intermediate reasoning steps (e.g., Chain-of-Thought, {CoT}). However, {LLMs} can still struggle with problems that are easy for humans, such as generating action plans for executing tasks in a given environment, or performing complex math, logical, and commonsense reasoning. The deficiency stems from the key fact that {LLMs} lack an internal \${\textbackslash}textit\{world model\}\$ to predict the world \${\textbackslash}textit\{state\}\$ (e.g., environment status, intermediate variable values) and simulate long-term outcomes of actions. This prevents {LLMs} from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new {LLM} reasoning framework, \${\textbackslash}underline\{R\}\$easoning vi\${\textbackslash}underline\{a\}\$ \${\textbackslash}underline\{P\}\$lanning \${\textbackslash}textbf\{({RAP})\}\$. {RAP} repurposes the {LLM} as both a world model and a reasoning agent, and incorporates a principled planning algorithm (based on Monto Carlo Tree Search) for strategic exploration in the vast reasoning space. During reasoning, the {LLM} (as agent) incrementally builds a reasoning tree under the guidance of the {LLM} (as world model) and task-specific rewards, and obtains a high-reward reasoning path efficiently with a proper balance between exploration \${\textbackslash}textit\{vs.\}\$ exploitation. We apply {RAP} to a variety of challenging reasoning problems including plan generation, math reasoning, and logical inference. Empirical results on these tasks demonstrate the superiority of {RAP} over various strong baselines, including {CoT} and least-to-most prompting with self-consistency. {RAP} on {LLAMA}-33B surpasses {CoT} on {GPT}-4 with 33\% relative improvement in a plan generation setting.},
	number = {{arXiv}:2305.14992},
	publisher = {{arXiv}},
	author = {Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
	urldate = {2025-03-07},
	date = {2023-10-23},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/AWALL9JF/Hao et al. - 2023 - Reasoning with Language Model is Planning with World Model.pdf:application/pdf},
}

@inproceedings{gramopadhye_generating_2023,
	title = {Generating Executable Action Plans with Environmentally-Aware Language Models},
	url = {https://ieeexplore.ieee.org/document/10341989/},
	abstract = {Large Language Models ({LLMs}) trained using massive text datasets have recently shown promise in generating action plans for robotic agents from high-level text queries. However, these models typically do not consider the robot's environment, resulting in generated plans that may not actually be executable, due to ambiguities in the planned actions or environmental constraints. In this paper, we propose an approach to generate environmentally-aware action plans that agents are better able to execute. Our approach involves integrating environmental objects and object relations as additional inputs into {LLM} action plan generation to provide the system with an awareness of its surroundings, resulting in plans where each generated action is mapped to objects present in the scene. We also design a novel scoring function that, along with generating the action steps and associating them with objects, helps the system disambiguate among object instances and take into account their states. We evaluated our approach using the {VirtualHome} simulator and the {ActivityPrograms} knowledge base and found that action plans generated from our system had a 310\% improvement in executability and a 147\% improvement in correctness over prior work. The complete code and a demo of our method is publicly available at https://github.com/hri-ironlab/scene\_aware\_language\_planner.},
	eventtitle = {2023 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
	pages = {3568--3575},
	booktitle = {2023 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
	author = {Gramopadhye, Maitrey and Szafir, Daniel},
	urldate = {2025-03-06},
	date = {2023-10},
	note = {{ISSN}: 2153-0866},
	keywords = {Affordances, Codes, Cognition, Intelligent robots, Knowledge based systems, Task analysis},
	file = {IEEE Xplore Abstract Record:/home/martin/Zotero/storage/2TBH9WXP/10341989.html:text/html;Submitted Version:/home/martin/Zotero/storage/XTVC3XVJ/Gramopadhye and Szafir - 2023 - Generating Executable Action Plans with Environmentally-Aware Language Models.pdf:application/pdf},
}

@article{huang_language_nodate,
	title = {Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents},
	abstract = {Can world knowledge learned by large language models ({LLMs}) be used to act in interactive environments? In this paper, we investigate the possibility of grounding high-level tasks, expressed in natural language (e.g. “make breakfast”), to a chosen set of actionable steps (e.g. “open fridge”). While prior work focused on learning from explicit step-by-step examples of how to act, we surprisingly find that if pre-trained {LMs} are large enough and prompted appropriately, they can effectively decompose high-level tasks into midlevel plans without any further training. However, the plans produced naively by {LLMs} often cannot map precisely to admissible actions. We propose a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. Our evaluation in the recent {VirtualHome} environment shows that the resulting method substantially improves executability over the {LLM} baseline. The conducted human evaluation reveals a trade-off between executability and correctness but shows a promising sign towards extracting actionable knowledge from language models.},
	author = {Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/3Z6AZUIW/Huang et al. - Language Models as Zero-Shot Planners Extracting Actionable Knowledge for Embodied Agents.pdf:application/pdf},
}

@misc{sel_algorithm_2024,
	title = {Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models},
	url = {http://arxiv.org/abs/2308.10379},
	shorttitle = {Algorithm of Thoughts},
	abstract = {Current literature, aiming to surpass the “Chainof-Thought” approach, often resorts to external modi operandi involving halting, modifying, and then resuming the generation process to boost Large Language Models’ ({LLMs}) reasoning capacities. Due to their myopic perspective, they escalate the number of query requests, leading to increased costs, memory, and computational overheads. Addressing this, we propose the Algorithm of Thoughts—a novel strategy that propels {LLMs} through algorithmic reasoning pathways. By employing algorithmic examples fully in-context, this overarching view of the whole process exploits the innate recurrence dynamics of {LLMs}, expanding their idea exploration with merely one or a few queries. Our technique outperforms earlier single-query methods and even more recent multi-query strategies that employ an extensive tree search algorithms while using significantly fewer tokens. Intriguingly, our results suggest that instructing an {LLM} using an algorithm can lead to performance surpassing that of the algorithm itself, hinting at {LLM}’s inherent ability to weave its intuition into optimized searches. We probe into the underpinnings of our method’s efficacy and its nuances in application. The code and related content can be found in: algorithm-of-thoughts.github.io.},
	number = {{arXiv}:2308.10379},
	publisher = {{arXiv}},
	author = {Sel, Bilgehan and Al-Tawaha, Ahmad and Khattar, Vanshaj and Jia, Ruoxi and Jin, Ming},
	urldate = {2025-03-06},
	date = {2024-06-02},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/EHKHAI9Z/Sel et al. - 2024 - Algorithm of Thoughts Enhancing Exploration of Ideas in Large Language Models.pdf:application/pdf},
}

@article{besta_graph_2024,
	title = {Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
	volume = {38},
	issn = {2374-3468, 2159-5399},
	url = {http://arxiv.org/abs/2308.09687},
	shorttitle = {Graph of Thoughts},
	abstract = {We introduce Graph of Thoughts ({GoT}): a framework that advances prompting capabilities in large language models ({LLMs}) beyond those offered by paradigms such as Chain-{ofThought} or Tree of Thoughts ({ToT}). The key idea and primary advantage of {GoT} is the ability to model the information generated by an {LLM} as an arbitrary graph, where units of information (“{LLM} thoughts”) are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary {LLM} thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that {GoT} offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62\% over {ToT}, while simultaneously reducing costs by {\textgreater}31\%. We ensure that {GoT} is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the {LLM} reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.},
	pages = {17682--17690},
	number = {16},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	shortjournal = {{AAAI}},
	author = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
	urldate = {2025-03-06},
	date = {2024-03-24},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/68ERQKWJ/Besta et al. - 2024 - Graph of Thoughts Solving Elaborate Problems with Large Language Models.pdf:application/pdf},
}

@misc{wang_recmind_2024,
	title = {{RecMind}: Large Language Model Powered Agent For Recommendation},
	url = {http://arxiv.org/abs/2308.14296},
	shorttitle = {{RecMind}},
	abstract = {While the recommendation system ({RS}) has advanced significantly through deep learning, current {RS} approaches usually train and finetune models on task-specific datasets, limiting their generalizability to new recommendation tasks and their ability to leverage external knowledge due to model scale and data size constraints. Thus, we designed an {LLMpowered} autonomous recommender agent, {RecMind}, which is capable of leveraging external knowledge, utilizing tools with careful planning to provide zero-shot personalized recommendations. We propose a Self-Inspiring algorithm to improve the planning ability. At each intermediate step, the {LLM} “self-inspires” to consider all previously explored states to plan for the next step. This mechanism greatly improves the model’s ability to comprehend and utilize historical information in planning for recommendation. We evaluate {RecMind}’s performance in various recommendation scenarios. Our experiment shows that {RecMind} outperforms existing zero/few-shot {LLM}-based recommendation baseline methods in various tasks and achieves comparable performance to a fully trained recommendation model P5.},
	number = {{arXiv}:2308.14296},
	publisher = {{arXiv}},
	author = {Wang, Yancheng and Jiang, Ziyan and Chen, Zheng and Yang, Fan and Zhou, Yingxue and Cho, Eunah and Fan, Xing and Huang, Xiaojiang and Lu, Yanbin and Yang, Yingzhen},
	urldate = {2025-03-06},
	date = {2024-03-20},
	langid = {english},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval},
	file = {PDF:/home/martin/Zotero/storage/6XXCD2CZ/Wang et al. - 2024 - RecMind Large Language Model Powered Agent For Recommendation.pdf:application/pdf},
}

@article{yao_tree_nodate,
	title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
	abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, “Tree of Thoughts” ({ToT}), which generalizes over the popular “Chain of Thought” approach to prompting language models, and enables exploration over coherent units of text (“thoughts”) that serve as intermediate steps toward problem solving. {ToT} allows {LMs} to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that {ToT} significantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while {GPT}-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.},
	author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/D8FFTXMS/Yao et al. - Tree of Thoughts Deliberate Problem Solving with Large Language Models.pdf:application/pdf},
}

@misc{wang_self-consistency_2023,
	title = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
	url = {http://arxiv.org/abs/2203.11171},
	abstract = {Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It ﬁrst samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including {GSM}8K (+17.9\%), {SVAMP} (+11.0\%), {AQuA} (+12.2\%), {StrategyQA} (+6.4\%) and {ARC}-challenge (+3.9\%).},
	number = {{arXiv}:2203.11171},
	publisher = {{arXiv}},
	author = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
	urldate = {2025-03-06},
	date = {2023-03-07},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/NK6NABFV/Wang et al. - 2023 - Self-Consistency Improves Chain of Thought Reasoning in Language Models.pdf:application/pdf},
}

@article{lin_swiftsage_nodate,
	title = {{SWIFTSAGE}: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks},
	author = {Lin, Bill Yuchen and Fu, Yicheng and Yang, Karina and Brahman, Faeze and Huang, Shiyu and Bhagavatula, Chandra and Ammanabrolu, Prithviraj and Choi, Yejin and Ren, Xiang},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/7TVAI9HW/Lin et al. - SWIFTSAGE A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks.pdf:application/pdf},
}

@misc{xu_rewoo_2023,
	title = {{ReWOO}: Decoupling Reasoning from Observations for Efficient Augmented Language Models},
	url = {http://arxiv.org/abs/2305.18323},
	shorttitle = {{ReWOO}},
	abstract = {Augmented Language Models ({ALMs}) blend the reasoning capabilities of Large Language Models ({LLMs}) with tools that allow for knowledge retrieval and action execution. Existing {ALM} systems trigger {LLM} thought processes while pulling observations from these tools in an interleaved fashion. Specifically, an {LLM} reasons to call an external tool, gets halted to fetch the tool's response, and then decides the next action based on all preceding response tokens. Such a paradigm, though straightforward and easy to implement, often leads to huge computation complexity from redundant prompts and repeated execution. This study addresses such challenges for the first time, proposing a modular paradigm {ReWOO} (Reasoning {WithOut} Observation) that detaches the reasoning process from external observations, thus significantly reducing token consumption. Comprehensive evaluations across six public {NLP} benchmarks and a curated dataset reveal consistent performance enhancements with our proposed methodology. Notably, {ReWOO} achieves 5x token efficiency and 4\% accuracy improvement on {HotpotQA}, a multi-step reasoning benchmark. Furthermore, {ReWOO} demonstrates robustness under tool-failure scenarios. Beyond prompt efficiency, decoupling parametric modules from non-parametric tool calls enables instruction fine-tuning to offload {LLMs} into smaller language models, thus substantially reducing model parameters. Our illustrative work offloads reasoning ability from 175B {GPT}3.5 into 7B {LLaMA}, demonstrating the significant potential for truly efficient and scalable {ALM} systems.},
	number = {{arXiv}:2305.18323},
	publisher = {{arXiv}},
	author = {Xu, Binfeng and Peng, Zhiyuan and Lei, Bowen and Mukherjee, Subhabrata and Liu, Yuchen and Xu, Dongkuan},
	urldate = {2025-03-06},
	date = {2023-05-23},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/EL27CQ2G/Xu et al. - 2023 - ReWOO Decoupling Reasoning from Observations for Efficient Augmented Language Models.pdf:application/pdf},
}

@article{raman_planning_nodate,
	title = {Planning with Large Language Models via Corrective Re-prompting},
	abstract = {Extracting the common sense knowledge present in Large Language Models ({LLMs}) offers a path to designing intelligent, embodied agents. Related works have queried {LLMs} with a wide-range of contextual information, such as goals, sensor observations and scene descriptions, to generate high-level action plans for specific tasks; however these approaches often involve human intervention or additional machinery to enable sensor-motor interactions. In this work, we propose a prompting-based strategy for extracting executable plans from an {LLM}, which leverages a novel and readily-accessible source of information: precondition errors. Our approach assumes that actions are only afforded execution in certain contexts, i.e., implicit preconditions must be met for an action to execute (e.g., a door must be unlocked to open it), and that the embodied agent has the ability to determine if the action is/is not executable in the current context (e.g., detect if a precondition error is present). When an agent is unable to execute an action, our approach re-prompts the {LLM} with precondition error information to extract an executable corrective action to achieve the intended goal in the current context. We evaluate our approach in the {VirtualHome} simulation environment on 88 different tasks and 7 scenes. We evaluate different prompt templates and compare to methods that naively re-sample actions from the {LLM}. Our approach, using precondition errors, improves executability and semantic correctness of plans, while also reducing the number of re-prompts required when querying actions.},
	author = {Raman, Shreyas Sundara and Cohen, Vanya and Rosen, Eric and Idrees, Ifrah and Paulius, David and Tellex, Stefanie},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/M34IQWBJ/Raman et al. - Planning with Large Language Models via Corrective Re-prompting.pdf:application/pdf},
}

@article{zhao_expel_2024,
	title = {{ExpeL}: {LLM} Agents Are Experiential Learners},
	volume = {38},
	rights = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/29936},
	shorttitle = {{ExpeL}},
	abstract = {The recent surge in research interest in applying large language models ({LLMs}) to decision-making tasks has flourished by leveraging the extensive world knowledge embedded in {LLMs}. While there is a growing demand to tailor {LLMs} for custom decision-making tasks, finetuning them for specific tasks is resource-intensive and may diminish the model's generalization capabilities. Moreover, state-of-the-art language models like {GPT}-4 and Claude are primarily accessible through {API} calls, with their parametric weights remaining proprietary and unavailable to the public. This scenario emphasizes the growing need for new methodologies that allow learning from agent experiences without requiring parametric updates. To address these problems, we introduce the Experiential Learning ({ExpeL}) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results highlight the robust learning efficacy of the {ExpeL} agent, indicating a consistent enhancement in its performance as it accumulates experiences. We further explore the emerging capabilities and transfer learning potential of the {ExpeL} agent through qualitative observations and additional experiments.},
	pages = {19632--19642},
	number = {17},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Zhao, Andrew and Huang, Daniel and Xu, Quentin and Lin, Matthieu and Liu, Yong-Jin and Huang, Gao},
	urldate = {2025-03-06},
	date = {2024-03-24},
	langid = {english},
	note = {Number: 17},
	keywords = {{PRS}: Planning with Language Models},
	file = {Full Text PDF:/home/martin/Zotero/storage/S8N4NCTK/Zhao et al. - 2024 - ExpeL LLM Agents Are Experiential Learners.pdf:application/pdf},
}

@article{zhong_memorybank_2024,
	title = {{MemoryBank}: Enhancing Large Language Models with Long-Term Memory},
	volume = {38},
	rights = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/29946},
	shorttitle = {{MemoryBank}},
	abstract = {Large Language Models ({LLMs}) have drastically reshaped our interactions with artificial intelligence ({AI}) systems, showcasing impressive performance across an extensive array of tasks. Despite this, a notable hindrance remains—the deficiency of a long-term memory mechanism within these models. This shortfall becomes increasingly evident in situations demanding sustained interaction, such as personal companion systems, psychological counseling, and secretarial assistance. Recognizing the necessity for long-term memory, we propose {MemoryBank}, a novel memory mechanism tailored for {LLMs}. {MemoryBank} enables the models to summon relevant memories, continually evolve through continuous memory updates, comprehend, and adapt to a user's personality over time by synthesizing information from previous interactions. To mimic anthropomorphic behaviors and selectively preserve memory, {MemoryBank} incorporates a memory updating mechanism, inspired by the Ebbinghaus Forgetting Curve theory. This mechanism permits the {AI} to forget and reinforce memory based on time elapsed and the relative significance of the memory, thereby offering a more human-like memory mechanism and enriched user experience. {MemoryBank} is versatile in accommodating both closed-source models like {ChatGPT} and open-source models such as {ChatGLM}. To validate {MemoryBank}'s effectiveness, we exemplify its application through the creation of an {LLM}-based chatbot named {SiliconFriend} in a long-term {AI} Companion scenario. Further tuned with psychological dialog data, {SiliconFriend} displays heightened empathy and discernment in its interactions. Experiment involves both qualitative analysis with real-world user dialogs and quantitative analysis with simulated dialogs. In the latter, {ChatGPT} acts as multiple users with diverse characteristics and generates long-term dialog contexts covering a wide array of topics. The results of our analysis reveal that {SiliconFriend}, equipped with {MemoryBank}, exhibits a strong capability for long-term companionship as it can provide emphatic response, recall relevant memories and understand user personality.},
	pages = {19724--19731},
	number = {17},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Zhong, Wanjun and Guo, Lianghong and Gao, Qiqi and Ye, He and Wang, Yanlin},
	urldate = {2025-03-05},
	date = {2024-03-24},
	langid = {english},
	note = {Number: 17},
	keywords = {{NLP}: Generation},
	file = {Full Text PDF:/home/martin/Zotero/storage/K74XSWDP/Zhong et al. - 2024 - MemoryBank Enhancing Large Language Models with Long-Term Memory.pdf:application/pdf},
}

@book{liang_unleashing_2023,
	title = {Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System},
	abstract = {Large-scale Language Models ({LLMs}) are constrained by their inability to process lengthy inputs. To address this limitation, we propose the Self-Controlled Memory ({SCM}) system to unleash infinite-length input capacity for large-scale language models. Our {SCM} system is composed of three key modules: the language model agent, the memory stream, and the memory controller. The language model agent iteratively processes ultra-long inputs and stores all historical information in the memory stream. The memory controller provides the agent with both long-term memory (archived memory) and short-term memory (flash memory) to generate precise and coherent responses. The controller determines which memories from archived memory should be activated and how to incorporate them into the model input. Our {SCM} system can be integrated with any {LLMs} to enable them to process ultra-long texts without any modification or fine-tuning. Experimental results show that our {SCM} system enables {LLMs}, which are not optimized for multi-turn dialogue, to achieve multi-turn dialogue capabilities that are comparable to {ChatGPT}, and to outperform {ChatGPT} in scenarios involving ultra-long document summarization or long-term conversations. Additionally, we will supply a test set, which covers common long-text input scenarios, for evaluating the abilities of {LLMs} in processing long documents.{\textasciitilde}{\textbackslash}footnote\{Working in progress.\}{\textbackslash}footnote\{{\textbackslash}url\{https://github.com/wbbeyourself/{SCM}4LLMs\}\}},
	author = {Liang, Xinnian and Wang, Bing and Huang, Hui and Wu, Shuangzhi and Wu, Peihao and Lu, Lu and Ma, Zejun and Li, Zhoujun},
	date = {2023-04-26},
}

@article{shinn_reflexion_nodate,
	title = {Reflexion: Language Agents with Verbal Reinforcement Learning},
	abstract = {Large language models ({LLMs}) have been increasingly used to interact with external environments (e.g., games, compilers, {APIs}) as goal-driven agents. However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning. We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback. Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials. Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning). For example, Reflexion achieves a 91\% pass@1 accuracy on the {HumanEval} coding benchmark, surpassing the previous state-of-the-art {GPT}-4 that achieves 80\%. We also conduct ablation and analysis studies using different feedback signals, feedback incorporation methods, and agent types, and provide insights into how they affect performance. We release all code, demos, and datasets at https://github.com/noahshinn024/reflexion.},
	author = {Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/F4ILBTJK/Shinn et al. - Reflexion Language Agents with Verbal Reinforcement Learning.pdf:application/pdf},
}

@misc{zhu_ghost_2023,
	title = {Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory},
	url = {http://arxiv.org/abs/2305.17144},
	shorttitle = {Ghost in the Minecraft},
	abstract = {The captivating realm of Minecraft has attracted substantial research interest in recent years, serving as a rich platform for developing intelligent agents capable of functioning in open-world environments. However, the current research landscape predominantly focuses on specific objectives, such as the popular "{ObtainDiamond}" task, and has not yet shown effective generalization to a broader spectrum of tasks. Furthermore, the current leading success rate for the "{ObtainDiamond}" task stands at around 20\%, highlighting the limitations of Reinforcement Learning ({RL}) based controllers used in existing methods. To tackle these challenges, we introduce Ghost in the Minecraft ({GITM}), a novel framework integrates Large Language Models ({LLMs}) with text-based knowledge and memory, aiming to create Generally Capable Agents ({GCAs}) in Minecraft. These agents, equipped with the logic and common sense capabilities of {LLMs}, can skillfully navigate complex, sparse-reward environments with text-based interactions. We develop a set of structured actions and leverage {LLMs} to generate action plans for the agents to execute. The resulting {LLM}-based agent markedly surpasses previous methods, achieving a remarkable improvement of +47.5\% in success rate on the "{ObtainDiamond}" task, demonstrating superior robustness compared to traditional {RL}-based controllers. Notably, our agent is the first to procure all items in the Minecraft Overworld technology tree, demonstrating its extensive capabilities. {GITM} does not need any {GPU} for training, but a single {CPU} node with 32 {CPU} cores is enough. This research shows the potential of {LLMs} in developing capable agents for handling long-horizon, complex tasks and adapting to uncertainties in open-world environments. See the project website at https://github.com/ {OpenGVLab}/{GITM}.},
	number = {{arXiv}:2305.17144},
	publisher = {{arXiv}},
	author = {Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and Qiao, Yu and Zhang, Zhaoxiang and Dai, Jifeng},
	urldate = {2025-03-05},
	date = {2023-06-01},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/martin/Zotero/storage/IERGWSYP/Zhu et al. - 2023 - Ghost in the Minecraft Generally Capable Agents for Open-World Environments via Large Language Mode.pdf:application/pdf},
}

@inproceedings{park_generative_2023,
	location = {San Francisco {CA} {USA}},
	title = {Generative Agents: Interactive Simulacra of Human Behavior},
	isbn = {979-8-4007-0132-0},
	url = {https://dl.acm.org/doi/10.1145/3586183.3606763},
	shorttitle = {Generative Agents},
	eventtitle = {{UIST} '23: The 36th Annual {ACM} Symposium on User Interface Software and Technology},
	pages = {1--22},
	booktitle = {Proceedings of the 36th Annual {ACM} Symposium on User Interface Software and Technology},
	publisher = {{ACM}},
	author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
	urldate = {2025-03-05},
	date = {2023-10-29},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/MJZUFUX2/Park et al. - 2023 - Generative Agents Interactive Simulacra of Human Behavior.pdf:application/pdf},
}

@misc{wang_describe_2024,
	title = {Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents},
	url = {http://arxiv.org/abs/2302.01560},
	shorttitle = {Describe, Explain, Plan and Select},
	abstract = {We investigate the challenge of task planning for multi-task embodied agents in open-world environments.2 Two main difficulties are identified: 1) executing plans in an open-world environment (e.g., Minecraft) necessitates accurate and multi-step reasoning due to the long-term nature of tasks, and 2) as vanilla planners do not consider how easy the current agent can achieve a given sub-task when ordering parallel sub-goals within a complicated plan, the resulting plan could be inefficient or even infeasible. To this end, we propose “Describe, Explain, Plan and Select” ({DEPS}), an interactive planning approach based on Large Language Models ({LLMs}). {DEPS} facilitates better error correction on initial {LLM}-generated plan by integrating description of the plan execution process and providing selfexplanation of feedback when encountering failures during the extended planning phases. Furthermore, it includes a goal selector, which is a trainable module that ranks parallel candidate sub-goals based on the estimated steps of completion, consequently refining the initial plan. Our experiments mark the milestone of the first zero-shot multi-task agent that can robustly accomplish 70+ Minecraft tasks and nearly double the overall performances. Further testing reveals our method’s general effectiveness in popularly adopted non-open-ended domains as well (i.e., {ALFWorld} and tabletop manipulation). The ablation and exploratory studies detail how our design beats the counterparts and provide a promising update on the {ObtainDiamond} grand challenge with our approach. The code is released at https://github.com/{CraftJarvis}/{MC}-Planner.},
	number = {{arXiv}:2302.01560},
	publisher = {{arXiv}},
	author = {Wang, Zihao and Cai, Shaofei and Chen, Guanzhou and Liu, Anji and Ma, Xiaojian and Liang, Yitao},
	urldate = {2025-03-05},
	date = {2024-07-08},
	langid = {english},
	keywords = {Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/4QIU3WCL/Wang et al. - 2024 - Describe, Explain, Plan and Select Interactive Planning with Large Language Models Enables Open-Wor.pdf:application/pdf},
}

@online{noauthor_httpsarxivorgpdf230706135_nodate,
	title = {https://arxiv.org/pdf/2307.06135},
	url = {https://arxiv.org/pdf/2307.06135},
	urldate = {2025-03-04},
	file = {https\://arxiv.org/pdf/2307.06135:/home/martin/Zotero/storage/BKX7AYGW/2307.pdf:application/pdf},
}

@misc{fischer_reflective_2023,
	title = {Reflective Linguistic Programming ({RLP}): A Stepping Stone in Socially-Aware {AGI} ({SocialAGI})},
	url = {http://arxiv.org/abs/2305.12647},
	shorttitle = {Reflective Linguistic Programming ({RLP})},
	abstract = {This paper presents Reﬂective Linguistic Programming ({RLP}), a unique approach to conversational {AI} that emphasizes self-awareness and strategic planning. {RLP} encourages models to introspect on their own predeﬁned personality traits, emotional responses to incoming messages, and planned strategies, enabling contextually rich, coherent, and engaging interactions. A striking illustration of {RLP}’s potential involves a toy example, an {AI} persona with an adversarial orientation, a demon named ‘Bogus’ inspired by the children’s fairy tale Hansel \& Gretel. Bogus exhibits sophisticated behaviors, such as strategic deception and sensitivity to user discomfort, that spontaneously arise from the model’s introspection and strategic planning. These behaviors are not pre-programmed or prompted, but emerge as a result of the model’s advanced cognitive modeling. The potential applications of {RLP} in socially-aware {AGI} (Social {AGI}) are vast, from nuanced negotiations and mental health support systems to the creation of diverse and dynamic {AI} personas. Our exploration of deception serves as a stepping stone towards a new frontier in {AGI}, one ﬁlled with opportunities for advanced cognitive modeling and the creation of truly human ‘digital souls’.},
	number = {{arXiv}:2305.12647},
	publisher = {{arXiv}},
	author = {Fischer, Kevin A.},
	urldate = {2025-03-04},
	date = {2023-05-22},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
	file = {PDF:/home/martin/Zotero/storage/ZKUMXSLY/Fischer - 2023 - Reflective Linguistic Programming (RLP) A Stepping Stone in Socially-Aware AGI (SocialAGI).pdf:application/pdf},
}

@online{noauthor_httpssimgbaaiaccnpaperfile25a43194-c74c-4cd3-b60f-0a1f27f8b8afpdf_nodate,
	title = {https://simg.baai.ac.cn/paperfile/25a43194-c74c-4cd3-b60f-0a1f27f8b8af.pdf},
	url = {https://simg.baai.ac.cn/paperfile/25a43194-c74c-4cd3-b60f-0a1f27f8b8af.pdf},
	urldate = {2025-03-04},
	file = {https\://simg.baai.ac.cn/paperfile/25a43194-c74c-4cd3-b60f-0a1f27f8b8af.pdf:/home/martin/Zotero/storage/8ZCP7REC/25a43194-c74c-4cd3-b60f-0a1f27f8b8af.pdf:application/pdf},
}

@misc{gao_retrieval-augmented_2024,
	title = {Retrieval-Augmented Generation for Large Language Models: A Survey},
	url = {http://arxiv.org/abs/2312.10997},
	shorttitle = {Retrieval-Augmented Generation for Large Language Models},
	abstract = {Large Language Models ({LLMs}) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation ({RAG}) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. {RAG} synergistically merges {LLMs}' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of {RAG} paradigms, encompassing the Naive {RAG}, the Advanced {RAG}, and the Modular {RAG}. It meticulously scrutinizes the tripartite foundation of {RAG} frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in {RAG} systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
	number = {{arXiv}:2312.10997},
	publisher = {{arXiv}},
	author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
	urldate = {2025-03-04},
	date = {2024-03-27},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/J9W8RP5P/Gao et al. - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey.pdf:application/pdf},
}

@article{schick_toolformer_nodate,
	title = {Toolformer: Language Models Can Teach Themselves to Use Tools},
	abstract = {Language models ({LMs}) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller specialized models excel. In this paper, we show that {LMs} can teach themselves to use external tools via simple {APIs} and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which {APIs} to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each {API}. We incorporate a range of tools, including a calculator, a Q\&A system, a search engine, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.},
	author = {Schick, Timo and Dwivedi-Yu, Jane and Dessì, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/USFM5BPU/Schick et al. - Toolformer Language Models Can Teach Themselves to Use Tools.pdf:application/pdf},
}

@misc{wang_knowledgpt_2023,
	title = {{KnowledGPT}: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases},
	url = {http://arxiv.org/abs/2308.11761},
	shorttitle = {{KnowledGPT}},
	abstract = {Large language models ({LLMs}) have demonstrated impressive impact in the field of natural language processing, but they still struggle with several issues regarding, such as completeness, timeliness, faithfulness and adaptability. While recent efforts have focuses on connecting {LLMs} with external knowledge sources, the integration of knowledge bases ({KBs}) remains understudied and faces several challenges. In this paper, we introduce {KnowledGPT}, a comprehensive framework to bridge {LLMs} with various knowledge bases, facilitating both the retrieval and storage of knowledge. The retrieval process employs the program of thought prompting, which generates search language for {KBs} in code format with pre-defined functions for {KB} operations. Besides retrieval, {KnowledGPT} offers the capability to store knowledge in a personalized {KB}, catering to individual user demands. With extensive experiments, we show that by integrating {LLMs} with {KBs}, {KnowledGPT} properly answers a broader range of questions requiring world knowledge compared with vanilla {LLMs}, utilizing both knowledge existing in widelyknown {KBs} and extracted into personalized {KBs}.},
	number = {{arXiv}:2308.11761},
	publisher = {{arXiv}},
	author = {Wang, Xintao and Yang, Qianwen and Qiu, Yongting and Liang, Jiaqing and He, Qianyu and Gu, Zhouhong and Xiao, Yanghua and Wang, Wei},
	urldate = {2025-03-04},
	date = {2023-08-17},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/IXF4XF9J/Wang et al. - 2023 - KnowledGPT Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases.pdf:application/pdf},
}

@misc{modarressi_ret-llm_2024,
	title = {{RET}-{LLM}: Towards a General Read-Write Memory for Large Language Models},
	url = {http://arxiv.org/abs/2305.14322},
	shorttitle = {{RET}-{LLM}},
	abstract = {Large language models ({LLMs}) have significantly advanced the field of natural language processing ({NLP}) through their extensive parameters and comprehensive data utilization. However, existing {LLMs} lack a dedicated memory unit, limiting their ability to explicitly store and retrieve knowledge for various tasks. In this paper, we propose {RET}-{LLM} a novel framework that equips {LLMs} with a general write-read memory unit, allowing them to extract, store, and recall knowledge from the text as needed for task performance. Inspired by Davidsonian semantics theory, we extract and save knowledge in the form of triplets. The memory unit is designed to be scalable, aggregatable, updatable, and interpretable. Through qualitative evaluations, we demonstrate the superiority of our proposed framework over baseline approaches in question answering tasks. Moreover, our framework exhibits robust performance in handling temporal-based question answering tasks, showcasing its ability to effectively manage time-dependent information.},
	number = {{arXiv}:2305.14322},
	publisher = {{arXiv}},
	author = {Modarressi, Ali and Imani, Ayyoob and Fayyaz, Mohsen and Schütze, Hinrich},
	urldate = {2025-03-04},
	date = {2024-10-24},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/2P4W7S7S/Modarressi et al. - 2024 - RET-LLM Towards a General Read-Write Memory for Large Language Models.pdf:application/pdf},
}

@misc{trivedi_interleaving_2023,
	title = {Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions},
	url = {http://arxiv.org/abs/2212.10509},
	abstract = {Prompting-based large language models ({LLMs}) are surprisingly powerful at generating natural language reasoning steps or Chains-of-Thoughts ({CoT}) for multi-step question answering ({QA}). They struggle, however, when the necessary knowledge is either unavailable to the {LLM} or not up-to-date within its parameters. While using the question to retrieve relevant text from an external knowledge source helps {LLMs}, we observe that this one-step retrieve-and-read approach is insufficient for multi-step {QA}. Here, what to retrieve depends on what has already been derived, which in turn may depend on what was previously retrieved. To address this, we propose {IRCoT}, a new approach for multi-step {QA} that interleaves retrieval with steps (sentences) in a {CoT}, guiding the retrieval with {CoT} and in turn using retrieved results to improve {CoT}. Using {IRCoT} with {GPT}3 substantially improves retrieval (up to 21 points) as well as downstream {QA} (up to 15 points) on four datasets: {HotpotQA}, 2WikiMultihopQA, {MuSiQue}, and {IIRC}. We observe similar substantial gains in out-ofdistribution ({OOD}) settings as well as with much smaller models such as Flan-T5-large without additional training. {IRCoT} reduces model hallucination, resulting in factually more accurate {CoT} reasoning.1.},
	number = {{arXiv}:2212.10509},
	publisher = {{arXiv}},
	author = {Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
	urldate = {2025-03-03},
	date = {2023-06-23},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/L2E6KQU4/Trivedi et al. - 2023 - Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions.pdf:application/pdf},
}

@inproceedings{feng_retrieval-generation_2024,
	title = {Retrieval-Generation Synergy Augmented Large Language Models},
	url = {https://ieeexplore.ieee.org/document/10448015/},
	abstract = {Large language models augmented with task-relevant documents have demonstrated impressive performance on knowledge-intensive tasks. However, regarding how to obtain effective documents, the existing methods are mainly divided into two categories. One is to retrieve from an external knowledge base, and the other is to utilize large language models to generate documents. We propose an iterative retrieval-generation collaborative framework. It is not only able to leverage both parametric and non-parametric knowledge, but also helps to find the correct reasoning path through retrieval-generation interactions, which is very important for tasks that require multi-step reasoning. We conduct experiments on four question answering datasets, including single-hop {QA} and multi-hop {QA} tasks. Empirical results show that our method significantly improves the reasoning ability of large language models and outperforms previous baselines.},
	eventtitle = {{ICASSP} 2024 - 2024 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {11661--11665},
	booktitle = {{ICASSP} 2024 - 2024 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Feng, Zhangyin and Feng, Xiaocheng and Zhao, Dezhi and Yang, Maojin and Qin, Bing},
	urldate = {2025-03-03},
	date = {2024-04},
	note = {{ISSN}: 2379-190X},
	keywords = {Cognition, Knowledge based systems, Acoustics, Collaboration, Iterative methods, large language models, question answering, Question answering (information retrieval), retrieval augmented, Signal processing},
	file = {IEEE Xplore Abstract Record:/home/martin/Zotero/storage/MHUSH6EH/10448015.html:text/html;Submitted Version:/home/martin/Zotero/storage/DQB8JTLZ/Feng et al. - 2024 - Retrieval-Generation Synergy Augmented Large Language Models.pdf:application/pdf},
}

@misc{li_classification_2023,
	title = {From Classification to Generation: Insights into Crosslingual Retrieval Augmented {ICL}},
	url = {http://arxiv.org/abs/2311.06595},
	shorttitle = {From Classification to Generation},
	abstract = {The remarkable ability of Large Language Models ({LLMs}) to understand and follow instructions has sometimes been limited by their in-context learning ({ICL}) performance in low-resource languages. To address this, we introduce a novel approach that leverages cross-lingual retrieval-augmented in-context learning ({CREA}-{ICL}). By extracting semantically similar prompts from high-resource languages, we aim to improve the zero-shot performance of multilingual pre-trained language models ({MPLMs}) across diverse tasks. Though our approach yields steady improvements in classification tasks, it faces challenges in generation tasks. Our evaluation offers insights into the performance dynamics of retrieval-augmented in-context learning across both classification and generation domains.},
	number = {{arXiv}:2311.06595},
	publisher = {{arXiv}},
	author = {Li, Xiaoqian and Nie, Ercong and Liang, Sheng},
	urldate = {2025-03-03},
	date = {2023-12-02},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/API3KY5J/Li et al. - 2023 - From Classification to Generation Insights into Crosslingual Retrieval Augmented ICL.pdf:application/pdf},
}

@article{lin_ra-dit_2024,
	title = {{RA}-{DIT}: {RETRIEVAL}-{AUGMENTED} {DUAL} {INSTRUC}- {TION} {TUNING}},
	abstract = {Retrieval-augmented language models ({RALMs}) improve performance by accessing long-tail and up-to-date knowledge from external data stores, but are challenging to build. Existing approaches require either expensive retrieval-specific modifications to {LM} pre-training or use post-hoc integration of the data store that leads to suboptimal performance. We introduce Retrieval-Augmented Dual Instruction Tuning ({RA}-{DIT}), a lightweight fine-tuning methodology that provides a third option by retrofitting any {LLM} with retrieval capabilities. Our approach operates in two distinct fine-tuning steps: (1) one updates a pre-trained {LM} to better use retrieved information, while (2) the other updates the retriever to return more relevant results, as preferred by the {LM}. By fine-tuning over tasks that require both knowledge utilization and contextual awareness, we demonstrate that each stage yields significant performance improvements, and using both leads to additional gains. Our best model, {RA}-{DIT} 65B, achieves state-of-the-art performance across a range of knowledge-intensive zero- and few-shot learning benchmarks, significantly outperforming existing in-context {RALM} approaches by up to +8.9\% in 0-shot setting and +1.4\% in 5-shot setting on average.},
	author = {Lin, Xi Victoria and Chen, Xilun and Chen, Mingda and Shi, Weijia and Lomeli, Maria and James, Rich and Rodriguez, Pedro and Kahn, Jacob and Szilvasy, Gergely and Lewis, Mike and Zettlemoyer, Luke and Yih, Scott},
	date = {2024},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/M9AXRI65/Lin et al. - 2024 - RA-DIT RETRIEVAL-AUGMENTED DUAL INSTRUC- TION TUNING.pdf:application/pdf},
}

@misc{guu_realm_2020,
	title = {{REALM}: Retrieval-Augmented Language Model Pre-Training},
	url = {http://arxiv.org/abs/2002.08909},
	shorttitle = {{REALM}},
	abstract = {Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for {NLP} tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pretraining with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, ﬁne-tuning and inference. For the ﬁrst time, we show how to pretrain such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training ({REALM}) by ﬁne-tuning on the challenging task of Open-domain Question Answering (Open-{QA}). We compare against state-of-theart models for both explicit and implicit knowledge storage on three popular Open-{QA} benchmarks, and ﬁnd that we outperform all previous methods by a signiﬁcant margin (4-16\% absolute accuracy), while also providing qualitative beneﬁts such as interpretability and modularity.},
	number = {{arXiv}:2002.08909},
	publisher = {{arXiv}},
	author = {Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei},
	urldate = {2025-03-03},
	date = {2020-02-10},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {PDF:/home/martin/Zotero/storage/U5AELYKD/Guu et al. - 2020 - REALM Retrieval-Augmented Language Model Pre-Training.pdf:application/pdf},
}

@article{borgeaud_improving_nodate,
	title = {Improving Language Models by Retrieving from Trillions of Tokens},
	abstract = {We enhance auto-regressive language models by conditioning on document chunks retrieved from a large corpus, based on local similarity with preceding tokens. With a 2 trillion token database, our Retrieval-Enhanced Transformer ({RETRO}) obtains comparable performance to {GPT}-3 and Jurassic-1 on the Pile, despite using 25× fewer parameters. After ﬁne-tuning, {RETRO} performance translates to downstream knowledge-intensive tasks such as question answering. {RETRO} combines a frozen {BERT} retriever, a differentiable encoder and a chunked cross-attention mechanism to predict tokens based on an order of magnitude more data than what is typically consumed during training. We typically train {RETRO} from scratch, yet can also rapidly {RETROﬁt} pre-trained transformers with retrieval and still achieve good performance. Our work opens up new avenues for improving language models through explicit memory at unprecedented scale.},
	author = {Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/HPVJJ367/Borgeaud et al. - Improving Language Models by Retrieving from Trillions of Tokens.pdf:application/pdf},
}

@misc{kang_knowledge_2023,
	title = {Knowledge Graph-Augmented Language Models for Knowledge-Grounded Dialogue Generation},
	url = {http://arxiv.org/abs/2305.18846},
	abstract = {Language models have achieved impressive performances on dialogue generation tasks. However, when generating responses for a conversation that requires factual knowledge, they are far from perfect, due to an absence of mechanisms to retrieve, encode, and reflect the knowledge in the generated responses. Some knowledgegrounded dialogue generation methods tackle this problem by leveraging facts from Knowledge Graphs ({KGs}); however, they do not guarantee that the model utilizes a relevant piece of knowledge from the {KG}. To overcome this limitation, we propose {SUbgraph} Retrieval-augmented {GEneration} ({SURGE}), a framework for generating context-relevant and knowledge-grounded dialogues with the {KG}. Specifically, our {SURGE} framework first retrieves the relevant subgraph from the {KG}, and then enforces consistency across facts by perturbing their word embeddings conditioned by the retrieved subgraph. Then, we utilize contrastive learning to ensure that the generated texts have high similarity to the retrieved subgraphs. We validate our {SURGE} framework on {OpendialKG} and {KOMODIS} datasets, showing that it generates high-quality dialogues that faithfully reflect the knowledge from {KG}.},
	number = {{arXiv}:2305.18846},
	publisher = {{arXiv}},
	author = {Kang, Minki and Kwak, Jin Myung and Baek, Jinheon and Hwang, Sung Ju},
	urldate = {2025-03-03},
	date = {2023-05-30},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/QUVPGSVQ/Kang et al. - 2023 - Knowledge Graph-Augmented Language Models for Knowledge-Grounded Dialogue Generation.pdf:application/pdf},
}

@article{cheng_lift_nodate,
	title = {Lift Yourself Up: Retrieval-augmented Text Generation with Self-Memory},
	abstract = {With direct access to human-written reference as memory, retrieval-augmented generation has achieved much progress in a wide range of text generation tasks. Since better memory would typically prompt better generation (we define this as primal problem). The traditional approach for memory retrieval involves selecting memory that exhibits the highest similarity to the input. However, this method is constrained by the quality of the fixed corpus from which memory is retrieved. In this paper, by exploring the duality of the primal problem: better generation also prompts better memory, we propose a novel framework, Selfmem, which addresses this limitation by iteratively employing a retrieval-augmented generator to create an unbounded memory pool and using a memory selector to choose one output as memory for the subsequent generation round. This enables the model to leverage its own output, referred to as self-memory, for improved generation. We evaluate the effectiveness of Selfmem on three distinct text generation tasks: neural machine translation, abstractive text summarization, and dialogue generation, under two generation paradigms: fine-tuned small model and few-shot {LLM}. Our approach achieves state-of-the-art results in four directions in {JRC}-Acquis translation dataset, 50.3 {ROUGE}-1 in {XSum}, and 62.9 {ROUGE}-1 in {BigPatent}, demonstrating the potential of self-memory in enhancing retrieval-augmented generation models. Furthermore, we conduct thorough analyses of each component in the Selfmem framework to identify current system bottlenecks and provide insights for future research1.},
	author = {Cheng, Xin and Luo, Di and Chen, Xiuying and Liu, Lemao and Zhao, Dongyan and Yan, Rui},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/JZ3D7XNV/Cheng et al. - Lift Yourself Up Retrieval-augmented Text Generation with Self-Memory.pdf:application/pdf},
}

@inproceedings{ma_large_2023,
	title = {Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!},
	url = {http://arxiv.org/abs/2303.08559},
	abstract = {Large Language Models ({LLMs}) have made remarkable strides in various tasks. Whether {LLMs} are competitive few-shot solvers for information extraction ({IE}) tasks, however, remains an open problem. In this work, we aim to provide a thorough answer to this question. Through extensive experiments on nine datasets across four {IE} tasks, we demonstrate that current advanced {LLMs} consistently exhibit inferior performance, higher latency, and increased budget requirements compared to fine-tuned {SLMs} under most settings. Therefore, we conclude that {LLMs} are not effective few-shot information extractors in general 1. Nonetheless, we illustrate that with appropriate prompting strategies, {LLMs} can effectively complement {SLMs} and tackle challenging samples that {SLMs} struggle with. And moreover, we propose an adaptive filter-thenrerank paradigm to combine the strengths of {LLMs} and {SLMs}. In this paradigm, {SLMs} serve as filters and {LLMs} serve as rerankers. By prompting {LLMs} to rerank a small portion of difficult samples identified by {SLMs}, our preliminary system consistently achieves promising improvements (2.4\% F1-gain on average) on various {IE} tasks, with an acceptable time and cost investment. Our code is available at https://github.com/mayubo2333/{LLM}-{IE}.},
	pages = {10572--10601},
	booktitle = {Findings of the Association for Computational Linguistics: {EMNLP} 2023},
	author = {Ma, Yubo and Cao, Yixin and Hong, {YongChing} and Sun, Aixin},
	urldate = {2025-03-03},
	date = {2023},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/5MWRULD9/Ma et al. - 2023 - Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samp.pdf:application/pdf},
}

@misc{luo_augmented_2023,
	title = {Augmented Large Language Models with Parametric Knowledge Guiding},
	url = {http://arxiv.org/abs/2305.04757},
	abstract = {Large Language Models ({LLMs}) have signiﬁcantly advanced natural language processing ({NLP}) with their impressive language understanding and generation capabilities. However, their performance may be suboptimal for domain-speciﬁc tasks that require specialized knowledge due to limited exposure to the related data. Additionally, the lack of transparency of most state-of-the-art ({SOTA}) {LLMs}, which can only be accessed via {APIs}, impedes further ﬁne-tuning with domain custom data. Moreover, providing private data to the {LLMs}’ owner leads to data privacy problems. To address these challenges, we propose the novel Parametric Knowledge Guiding ({PKG}) framework, which equips {LLMs} with a knowledge-guiding module to access relevant knowledge without altering the {LLMs}’ parameters. Our {PKG} is based on open-source "white-box" language models, allowing ofﬂine memory of any knowledge that {LLMs} require. We demonstrate that our {PKG} framework can enhance the performance of "black-box" {LLMs} on a range of domain knowledge-intensive tasks that require factual (+7.9\%), tabular (+11.9\%), medical (+3.0\%), and multimodal (+8.1\%) knowledge.},
	number = {{arXiv}:2305.04757},
	publisher = {{arXiv}},
	author = {Luo, Ziyang and Xu, Can and Zhao, Pu and Geng, Xiubo and Tao, Chongyang and Ma, Jing and Lin, Qingwei and Jiang, Daxin},
	urldate = {2025-03-02},
	date = {2023-05-18},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/BRVQSI4C/Luo et al. - 2023 - Augmented Large Language Models with Parametric Knowledge Guiding.pdf:application/pdf},
}

@misc{berchansky_optimizing_2023,
	title = {Optimizing Retrieval-augmented Reader Models via Token Elimination},
	url = {http://arxiv.org/abs/2310.13682},
	abstract = {Fusion-in-Decoder ({FiD}) is an effective retrieval-augmented language model applied across a variety of open-domain tasks, such as question answering, fact checking, etc. In {FiD}, supporting passages are first retrieved and then processed using a generative model (Reader), which can cause a significant bottleneck in decoding time, particularly with long outputs. In this work, we analyze the contribution and necessity of all the retrieved passages to the performance of reader models, and propose eliminating some of the retrieved information, at the token level, that might not contribute essential information to the answer generation process. We demonstrate that our method can reduce run-time by up to 62.2\%, with only a 2\% reduction in performance, and in some cases, even improve the performance results.},
	number = {{arXiv}:2310.13682},
	publisher = {{arXiv}},
	author = {Berchansky, Moshe and Izsak, Peter and Caciularu, Avi and Dagan, Ido and Wasserblat, Moshe},
	urldate = {2025-03-02},
	date = {2023-11-05},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/6VQVKPYK/Berchansky et al. - 2023 - Optimizing Retrieval-augmented Reader Models via Token Elimination.pdf:application/pdf},
}

@misc{yang_prca_2023,
	title = {{PRCA}: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter},
	url = {http://arxiv.org/abs/2310.18347},
	shorttitle = {{PRCA}},
	abstract = {The Retrieval Question Answering ({ReQA}) task employs the retrieval-augmented framework, composed of a retriever and generator. The generator formulates the answer based on the documents retrieved by the retriever. Incorporating Large Language Models ({LLMs}) as generators is beneficial due to their advanced {QA} capabilities, but they are typically too large to be fine-tuned with budget constraints while some of them are only accessible via {APIs}. To tackle this issue and further improve {ReQA} performance, we propose a trainable Pluggable Reward-Driven Contextual Adapter ({PRCA}), keeping the generator as a black box. Positioned between the retriever and generator in a Pluggable manner, {PRCA} refines the retrieved information by operating in a tokenautoregressive strategy via maximizing rewards of the reinforcement learning phase. Our experiments validate {PRCA}’s effectiveness in enhancing {ReQA} performance on three datasets by up to 20\% improvement to fit black-box {LLMs} into existing frameworks, demonstrating its considerable potential in the {LLMs} era.},
	number = {{arXiv}:2310.18347},
	publisher = {{arXiv}},
	author = {Yang, Haoyan and Li, Zhitao and Zhang, Yong and Wang, Jianzong and Cheng, Ning and Li, Ming and Xiao, Jing},
	urldate = {2025-03-02},
	date = {2023-10-23},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/GDXKQCC6/Yang et al. - 2023 - PRCA Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-.pdf:application/pdf},
}

@misc{xu_recomp_2023,
	title = {{RECOMP}: Improving Retrieval-Augmented {LMs} with Compression and Selective Augmentation},
	url = {http://arxiv.org/abs/2310.04408},
	shorttitle = {{RECOMP}},
	abstract = {Retrieving documents and prepending them in-context at inference time improves performance of language model ({LMs}) on a wide range of tasks. However, these documents, often spanning hundreds of words, make inference substantially more expensive. We propose compressing the retrieved documents into textual summaries prior to in-context integration. This not only reduces the computational costs but also relieves the burden of {LMs} to identify relevant information in long retrieved documents. We present two compressors -- an extractive compressor which selects useful sentences from retrieved documents and an abstractive compressor which generates summaries by synthesizing information from multiple documents. Both compressors are trained to improve {LMs}' performance on end tasks when the generated summaries are prepended to the {LMs}' input, while keeping the summary concise.If the retrieved documents are irrelevant to the input or offer no additional information to {LM}, our compressor can return an empty string, implementing selective augmentation.We evaluate our approach on language modeling task and open domain question answering task. We achieve a compression rate of as low as 6\% with minimal loss in performance for both tasks, significantly outperforming the off-the-shelf summarization models. We show that our compressors trained for one {LM} can transfer to other {LMs} on the language modeling task and provide summaries largely faithful to the retrieved documents.},
	number = {{arXiv}:2310.04408},
	publisher = {{arXiv}},
	author = {Xu, Fangyuan and Shi, Weijia and Choi, Eunsol},
	urldate = {2025-03-02},
	date = {2023-10-06},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/EIU4K7E8/Xu et al. - 2023 - RECOMP Improving Retrieval-Augmented LMs with Compression and Selective Augmentation.pdf:application/pdf},
}

@misc{shi_replug_2023,
	title = {{REPLUG}: Retrieval-Augmented Black-Box Language Models},
	url = {http://arxiv.org/abs/2301.12652},
	shorttitle = {{REPLUG}},
	abstract = {We introduce {REPLUG}, a retrieval-augmented language modeling framework that treats the language model ({LM}) as a black box and augments it with a tuneable retrieval model. Unlike prior retrieval-augmented {LMs} that train language models with special cross attention mechanisms to encode the retrieved text, {REPLUG} simply prepends retrieved documents to the input for the frozen black-box {LM}. This simple design can be easily applied to any existing retrieval and language models. Furthermore, we show that the {LM} can be used to supervise the retrieval model, which can then find documents that help the {LM} make better predictions. Our experiments demonstrate that {REPLUG} with the tuned retriever significantly improves the performance of {GPT}-3 (175B) on language modeling by 6.3\%, as well as the performance of Codex on five-shot {MMLU} by 5.1\%.},
	number = {{arXiv}:2301.12652},
	publisher = {{arXiv}},
	author = {Shi, Weijia and Min, Sewon and Yasunaga, Michihiro and Seo, Minjoon and James, Rich and Lewis, Mike and Zettlemoyer, Luke and Yih, Wen-tau},
	urldate = {2025-03-01},
	date = {2023-05-24},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/6BG7UD8Q/Shi et al. - 2023 - REPLUG Retrieval-Augmented Black-Box Language Models.pdf:application/pdf},
}

@misc{yu_augmentation-adapted_2023,
	title = {Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In},
	url = {http://arxiv.org/abs/2305.17331},
	abstract = {Retrieval augmentation can aid language models ({LMs}) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the {LM}, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target {LMs} that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target {LMs}, we propose augmentation-adapted retriever ({AAR}), which learns {LM}’s preferences obtained from a known source {LM}. Experiments on the {MMLU} and {PopQA} datasets demonstrate that our {AAR} trained with a small source {LM} is able to significantly improve the zero-shot generalization of larger target {LMs} ranging from 250M Flan-T5 to 175B {InstructGPT}. Further analysis indicates that the preferences of different {LMs} overlap, enabling {AAR} trained with a single source {LM} to serve as a generic plug-in for various target {LMs}. Our code is open-sourced at https://github.com/{OpenMatch}/{AugmentationAdapted}-Retriever.},
	number = {{arXiv}:2305.17331},
	publisher = {{arXiv}},
	author = {Yu, Zichun and Xiong, Chenyan and Yu, Shi and Liu, Zhiyuan},
	urldate = {2025-03-01},
	date = {2023-05-27},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {PDF:/home/martin/Zotero/storage/RI2KWISV/Yu et al. - 2023 - Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In.pdf:application/pdf},
}

@misc{li_structure-aware_2023,
	title = {Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data},
	url = {http://arxiv.org/abs/2305.19912},
	abstract = {This paper presents Structure Aware {DeNse} {ReTrievAl} ({SANTA}) model, which encodes user queries and structured data in one universal embedding space for retrieving structured data. {SANTA} proposes two pretraining methods to make language models structureaware and learn effective representations for structured data: 1) Structured Data Alignment, which utilizes the natural alignment relations between structured data and unstructured data for structure-aware pretraining. It contrastively trains language models to represent multi-modal text data and teaches models to distinguish matched structured data for unstructured texts. 2) Masked Entity Prediction, which designs an entity-oriented mask strategy and asks language models to fill in the masked entities. Our experiments show that {SANTA} achieves state-of-the-art on code search and product search and conducts convincing results in the zero-shot setting. {SANTA} learns tailored representations for multi-modal text data by aligning structured and unstructured data pairs and capturing structural semantics by masking and predicting entities in the structured data. All codes are available at https: //github.com/{OpenMatch}/{OpenMatch}.},
	number = {{arXiv}:2305.19912},
	publisher = {{arXiv}},
	author = {Li, Xinze and Liu, Zhenghao and Xiong, Chenyan and Yu, Shi and Gu, Yu and Liu, Zhiyuan and Yu, Ge},
	urldate = {2025-02-28},
	date = {2023-05-31},
	langid = {english},
	keywords = {Computer Science - Information Retrieval},
	file = {PDF:/home/martin/Zotero/storage/62U2UUZW/Li et al. - 2023 - Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data.pdf:application/pdf},
}

@misc{zheng_take_2024,
	title = {Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models},
	url = {http://arxiv.org/abs/2310.06117},
	shorttitle = {Take a Step Back},
	abstract = {We present {STEP}-{BACK} {PROMPTING}, a simple prompting technique that enables {LLMs} to do abstractions to derive high-level concepts and first principles from instances containing specific details. Using the concepts and principles to guide reasoning, {LLMs} significantly improve their abilities in following a correct reasoning path towards the solution. We conduct experiments of {STEP}-{BACK} {PROMPTING} with {PaLM}-2L, {GPT}-4 and Llama2-70B models, and observe substantial performance gains on various challenging reasoning-intensive tasks including {STEM}, Knowledge {QA}, and Multi-Hop Reasoning. For instance, {STEP}-{BACK} {PROMPTING} improves {PaLM}-2L performance on {MMLU} (Physics and Chemistry) by 7\% and 11\% respectively, {TimeQA} by 27\%, and {MuSiQue} by 7\%.},
	number = {{arXiv}:2310.06117},
	publisher = {{arXiv}},
	author = {Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
	urldate = {2025-02-28},
	date = {2024-03-12},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/QQQH3T2M/Zheng et al. - 2024 - Take a Step Back Evoking Reasoning via Abstraction in Large Language Models.pdf:application/pdf},
}

@inproceedings{gao_precise_2023,
	location = {Toronto, Canada},
	title = {Precise Zero-Shot Dense Retrieval without Relevance Labels},
	url = {https://aclanthology.org/2023.acl-long.99},
	eventtitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	pages = {1762--1777},
	booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Gao, Luyu and Ma, Xueguang and Lin, Jimmy and Callan, Jamie},
	urldate = {2025-02-28},
	date = {2023},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/J33MWIH7/Gao et al. - 2023 - Precise Zero-Shot Dense Retrieval without Relevance Labels.pdf:application/pdf},
}

@article{asai_self-rag_2024,
	title = {{SELF}-{RAG}: {LEARNING} {TO} {RETRIEVE}, {GENERATE}, {AND} {CRITIQUE} {THROUGH} {SELF}-{REFLECTION}},
	author = {Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
	date = {2024},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/ZPU8G9HH/Asai et al. - 2024 - SELF-RAG LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION.pdf:application/pdf},
}

@misc{yoran_answering_2024,
	title = {Answering Questions by Meta-Reasoning over Multiple Chains of Thought},
	url = {http://arxiv.org/abs/2304.13007},
	abstract = {Modern systems for multi-hop question answering ({QA}) typically break questions into a sequence of reasoning steps, termed chain-ofthought ({CoT}), before arriving at a final answer. Often, multiple chains are sampled and aggregated through a voting mechanism over the final answers, but the intermediate steps themselves are discarded. While such approaches improve performance, they do not consider the relations between intermediate steps across chains and do not provide a unified explanation for the predicted answer. We introduce {MultiChain} Reasoning ({MCR}), an approach which prompts large language models to meta-reason over multiple chains of thought, rather than aggregate their answers. {MCR} examines different reasoning chains, mixes information between them and selects the most relevant facts in generating an explanation and predicting the answer. {MCR} outperforms strong baselines on 7 multi-hop {QA} datasets. Moreover, our analysis reveals that {MCR} explanations exhibit high quality, enabling humans to verify its answers.},
	number = {{arXiv}:2304.13007},
	publisher = {{arXiv}},
	author = {Yoran, Ori and Wolfson, Tomer and Bogin, Ben and Katz, Uri and Deutch, Daniel and Berant, Jonathan},
	urldate = {2025-02-27},
	date = {2024-08-02},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/VC5PX4F3/Yoran et al. - 2024 - Answering Questions by Meta-Reasoning over Multiple Chains of Thought.pdf:application/pdf},
}

@misc{press_measuring_2023,
	title = {Measuring and Narrowing the Compositionality Gap in Language Models},
	url = {http://arxiv.org/abs/2210.03350},
	abstract = {We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the {GPT}-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.},
	number = {{arXiv}:2210.03350},
	publisher = {{arXiv}},
	author = {Press, Ofir and Zhang, Muru and Min, Sewon and Schmidt, Ludwig and Smith, Noah A. and Lewis, Mike},
	urldate = {2025-02-27},
	date = {2023-10-17},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/7PEWBJII/Press et al. - 2023 - Measuring and Narrowing the Compositionality Gap in Language Models.pdf:application/pdf},
}

@misc{khattab_demonstrate-search-predict_2023,
	title = {Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive {NLP}},
	url = {http://arxiv.org/abs/2212.14024},
	shorttitle = {Demonstrate-Search-Predict},
	abstract = {Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models ({LM}) and retrieval models ({RM}). Existing work has combined these in simple “retrievethen-read” pipelines in which the {RM} retrieves passages that are inserted into the {LM} prompt. To begin to fully realize the potential of frozen {LMs} and {RMs}, we propose {DEMONSTRATE}–{SEARCH}–{PREDICT} ({DSP}), a framework that relies on passing natural language texts in sophisticated pipelines between an {LM} and an {RM}. {DSP} can express high-level programs that bootstrap pipeline-aware demonstrations, search for relevant passages, and generate grounded predictions, systematically breaking down problems into small transformations that the {LM} and {RM} can handle more reliably. We have written novel {DSP} programs for answering questions in open-domain, multi-hop, and conversational settings, establishing in early evaluations new state-of-the-art incontext learning results and delivering 37–120\%, 8–39\%, and 80–290\% relative gains against the vanilla {LM} ({GPT}-3.5), a standard retrieve-thenread pipeline, and a contemporaneous self-ask pipeline, respectively. We release {DSP} at https: //github.com/stanfordnlp/dsp.},
	number = {{arXiv}:2212.14024},
	publisher = {{arXiv}},
	author = {Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},
	urldate = {2025-02-27},
	date = {2023-01-23},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {PDF:/home/martin/Zotero/storage/LKZXUC6I/Khattab et al. - 2023 - Demonstrate-Search-Predict Composing retrieval and language models for knowledge-intensive NLP.pdf:application/pdf},
}

@misc{levine_standing_2022,
	title = {Standing on the Shoulders of Giant Frozen Language Models},
	url = {http://arxiv.org/abs/2204.10019},
	abstract = {Huge pretrained language models ({LMs}) have demonstrated surprisingly good zero-shot capabilities on a wide variety of tasks. This gives rise to the appealing vision of a single, versatile model with a wide range of functionalities across disparate applications. However, current leading techniques for leveraging a “frozen” {LM}—i.e., leaving its weights untouched—still often underperform ﬁne-tuning approaches which modify these weights in a task-dependent way. Those, in turn, suffer forgetfulness and compromise versatility, suggesting a tradeoff between performance and versatility. The main message of this paper is that current frozenmodel techniques such as prompt tuning are only the tip of the iceberg, and more powerful methods for leveraging frozen {LMs} can do just as well as ﬁne tuning in challenging domains without sacriﬁcing the underlying model’s versatility. To demonstrate this, we introduce three novel methods for leveraging frozen models: input-dependent prompt tuning, frozen readers, and recursive {LMs}, each of which vastly improves on current frozen-model approaches. Indeed, some of our methods even outperform ﬁne-tuning approaches in domains currently dominated by the latter. The computational cost of each method is higher than that of existing frozen model methods, but still negligible relative to a single pass through a huge frozen {LM}. Each of these methods constitutes a meaningful contribution in its own right, but by presenting these contributions together we aim to convince the reader of a broader message that goes beyond the details of any given method: that frozen models have untapped potential and that ﬁne-tuning is often unnecessary.},
	number = {{arXiv}:2204.10019},
	publisher = {{arXiv}},
	author = {Levine, Yoav and Dalmedigos, Itay and Ram, Ori and Zeldes, Yoel and Jannai, Daniel and Muhlgay, Dor and Osin, Yoni and Lieber, Opher and Lenz, Barak and Shalev-Shwartz, Shai and Shashua, Amnon and Leyton-Brown, Kevin and Shoham, Yoav},
	urldate = {2025-02-27},
	date = {2022-04-21},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/JDABXUWT/Levine et al. - 2022 - Standing on the Shoulders of Giant Frozen Language Models.pdf:application/pdf},
}

@article{khattab_baleen_nodate,
	title = {Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval},
	abstract = {Multi-hop reasoning (i.e., reasoning across two or more documents) is a key ingredient for {NLP} models that leverage large corpora to exhibit broad knowledge. To retrieve evidence passages, multi-hop models must contend with a fast-growing search space across the hops, represent complex queries that combine multiple information needs, and resolve ambiguity about the best order in which to hop between training passages. We tackle these problems via Baleen, a system that improves the accuracy of multi-hop retrieval while learning robustly from weak training signals in the many-hop setting. To tame the search space, we propose condensed retrieval, a pipeline that summarizes the retrieved passages after each hop into a single compact context. To model complex queries, we introduce a focused late interaction retriever that allows different parts of the same query representation to match disparate relevant passages. Lastly, to infer the hopping dependencies among unordered training passages, we devise latent hop ordering, a weak-supervision strategy in which the trained retriever itself selects the sequence of hops. We evaluate Baleen on retrieval for two-hop question answering and many-hop claim veriﬁcation, establishing state-of-the-art performance.},
	author = {Khattab, Omar and Potts, Christopher and Zaharia, Matei},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/5JH82E3W/Khattab et al. - Baleen Robust Multi-Hop Reasoning at Scale via Condensed Retrieval.pdf:application/pdf},
}

@misc{khattab_relevance-guided_2021,
	title = {Relevance-guided Supervision for {OpenQA} with {ColBERT}},
	url = {http://arxiv.org/abs/2007.00814},
	abstract = {Systems for Open-Domain Question Answering ({OpenQA}) generally depend on a retriever for ﬁnding candidate passages in a large corpus and a reader for extracting answers from those passages. In much recent work, the retriever is a learned component that uses coarse-grained vector representations of questions and passages. We argue that this modeling choice is insufﬁciently expressive for dealing with the complexity of natural language questions. To address this, we deﬁne {ColBERT}-{QA}, which adapts the scalable neural retrieval model {ColBERT} to {OpenQA}. {ColBERT} creates ﬁne-grained interactions between questions and passages. We propose an efﬁcient weak supervision strategy that iteratively uses {ColBERT} to create its own training data. This greatly improves {OpenQA} retrieval on Natural Questions, {SQuAD}, and {TriviaQA}, and the resulting system attains state-of-the-art extractive {OpenQA} performance on all three datasets.},
	number = {{arXiv}:2007.00814},
	publisher = {{arXiv}},
	author = {Khattab, Omar and Potts, Christopher and Zaharia, Matei},
	urldate = {2025-02-26},
	date = {2021-08-02},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {PDF:/home/martin/Zotero/storage/U9QYDVIP/Khattab et al. - 2021 - Relevance-guided Supervision for OpenQA with ColBERT.pdf:application/pdf},
}

@misc{qi_answering_2021,
	title = {Answering Open-Domain Questions of Varying Reasoning Steps from Text},
	url = {http://arxiv.org/abs/2010.12527},
	abstract = {We develop a uniﬁed system to answer directly from text open-domain questions that may require a varying number of retrieval steps. We employ a single multi-task transformer model to perform all the necessary subtasks—retrieving supporting facts, reranking them, and predicting the answer from all retrieved documents—in an iterative fashion. We avoid crucial assumptions of previous work that do not transfer well to real-world settings, including exploiting knowledge of the ﬁxed number of retrieval steps required to answer each question or using structured metadata like knowledge bases or web links that have limited availability. Instead, we design a system that can answer open-domain questions on any text collection without prior knowledge of reasoning complexity. To emulate this setting, we construct a new benchmark, called {BeerQA}, by combining existing one- and twostep datasets with a new collection of 530 questions that require three Wikipedia pages to answer, unifying Wikipedia corpora versions in the process. We show that our model demonstrates competitive performance on both existing benchmarks and this new benchmark. We make the new benchmark available at https: //beerqa.github.io/.},
	number = {{arXiv}:2010.12527},
	publisher = {{arXiv}},
	author = {Qi, Peng and Lee, Haejun and Sido, Oghenetegiri "{TG}" and Manning, Christopher D.},
	urldate = {2025-02-26},
	date = {2021-10-29},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/UKXQ9JBI/Qi et al. - 2021 - Answering Open-Domain Questions of Varying Reasoning Steps from Text.pdf:application/pdf},
}

@misc{khattab_demonstrate-search-predict_2023-1,
	title = {Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive {NLP}},
	url = {http://arxiv.org/abs/2212.14024},
	shorttitle = {Demonstrate-Search-Predict},
	abstract = {Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models ({LM}) and retrieval models ({RM}). Existing work has combined these in simple “retrievethen-read” pipelines in which the {RM} retrieves passages that are inserted into the {LM} prompt. To begin to fully realize the potential of frozen {LMs} and {RMs}, we propose {DEMONSTRATE}–{SEARCH}–{PREDICT} ({DSP}), a framework that relies on passing natural language texts in sophisticated pipelines between an {LM} and an {RM}. {DSP} can express high-level programs that bootstrap pipeline-aware demonstrations, search for relevant passages, and generate grounded predictions, systematically breaking down problems into small transformations that the {LM} and {RM} can handle more reliably. We have written novel {DSP} programs for answering questions in open-domain, multi-hop, and conversational settings, establishing in early evaluations new state-of-the-art incontext learning results and delivering 37–120\%, 8–39\%, and 80–290\% relative gains against the vanilla {LM} ({GPT}-3.5), a standard retrieve-thenread pipeline, and a contemporaneous self-ask pipeline, respectively. We release {DSP} at https: //github.com/stanfordnlp/dsp.},
	number = {{arXiv}:2212.14024},
	publisher = {{arXiv}},
	author = {Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},
	urldate = {2025-02-26},
	date = {2023-01-23},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {PDF:/home/martin/Zotero/storage/9PZKH3P7/Khattab et al. - 2023 - Demonstrate-Search-Predict Composing retrieval and language models for knowledge-intensive NLP.pdf:application/pdf},
}

@misc{sun_recitation-augmented_2023,
	title = {Recitation-Augmented Language Models},
	url = {http://arxiv.org/abs/2210.01296},
	abstract = {We propose a new paradigm to help Large Language Models ({LLMs}) generate more accurate factual knowledge without retrieving from an external corpus, called {RECITation}-augmented {gEneration} ({RECITE}). Different from retrievalaugmented language models that retrieve relevant documents before generating the outputs, given an input, {RECITE} ﬁrst recites one or several relevant passages from {LLMs}’ own memory via sampling, and then produces the ﬁnal answers. We show that {RECITE} is a powerful paradigm for knowledge-intensive {NLP} tasks. Speciﬁcally, we show that by utilizing recitation as the intermediate step, a recite-and-answer scheme can achieve new state-of-the-art performance in various closed-book question answering ({CBQA}) tasks. In experiments, we verify the effectiveness of {RECITE} on four pre-trained models ({PaLM}, {UL}2, {OPT}, and Codex) and three {CBQA} tasks (Natural Questions, {TriviaQA}, and {HotpotQA}). Our code is available at https://github.com/Edward-Sun/{RECITE}.},
	number = {{arXiv}:2210.01296},
	publisher = {{arXiv}},
	author = {Sun, Zhiqing and Wang, Xuezhi and Tay, Yi and Yang, Yiming and Zhou, Denny},
	urldate = {2025-02-25},
	date = {2023-02-16},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/E5A5T33Z/Sun et al. - 2023 - Recitation-Augmented Language Models.pdf:application/pdf},
}

@misc{yu_generate_2023,
	title = {Generate rather than Retrieve: Large Language Models are Strong Context Generators},
	url = {http://arxiv.org/abs/2209.10063},
	shorttitle = {Generate rather than Retrieve},
	abstract = {Knowledge-intensive tasks, such as open-domain question answering ({QA}), require access to a large amount of world or domain knowledge. A common approach for knowledge-intensive tasks is to employ a retrieve-then-read pipeline that ﬁrst retrieves a handful of relevant contextual documents from an external corpus such as Wikipedia and then predicts an answer conditioned on the retrieved documents. In this paper, we present a novel perspective for solving knowledge-intensive tasks by replacing document retrievers with large language model generators. We call our method generate-then-read ({GENREAD}), which ﬁrst prompts a large language model to generate contextual documents based on a given question, and then reads the generated documents to produce the ﬁnal answer. Furthermore, we propose a novel clustering-based prompting method that selects distinct prompts, in order to generate diverse documents that cover different perspectives, leading to better recall over acceptable answers. We conduct extensive experiments on three different knowledge-intensive tasks, including open-domain {QA}, fact checking, and dialogue system. Notably, {GENREAD} achieves 71.6 and 54.4 exact match scores on {TriviaQA} and {WebQ}, signiﬁcantly outperforming the state-of-the-art retrieve-thenread pipeline {DPR}-{FiD} by +4.0 and +3.9, without retrieving any documents from any external knowledge source. Lastly, we demonstrate the model performance can be further improved by combining retrieval and generation. Our code and generated documents can be found at https://github.com/wyu97/{GenRead}.},
	number = {{arXiv}:2209.10063},
	publisher = {{arXiv}},
	author = {Yu, Wenhao and Iter, Dan and Wang, Shuohang and Xu, Yichong and Ju, Mingxuan and Sanyal, Soumya and Zhu, Chenguang and Zeng, Michael and Jiang, Meng},
	urldate = {2025-02-25},
	date = {2023-01-25},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/U2BGESZH/Yu et al. - 2023 - Generate rather than Retrieve Large Language Models are Strong Context Generators.pdf:application/pdf},
}

@article{ma_query_nodate,
	title = {Query Rewriting for Retrieval-Augmented Large Language Models},
	abstract = {Large Language Models ({LLMs}) play powerful, black-box readers in the retrieve-thenread pipeline, making remarkable progress in knowledge-intensive tasks. This work introduces a new framework, Rewrite-{RetrieveRead} instead of the previous retrieve-then-read for the retrieval-augmented {LLMs} from the perspective of the query rewriting. Unlike prior studies focusing on adapting either the retriever or the reader, our approach pays attention to the adaptation of the search query itself, for there is inevitably a gap between the input text and the needed knowledge in retrieval. We first prompt an {LLM} to generate the query, then use a web search engine to retrieve contexts. Furthermore, to better align the query to the frozen modules, we propose a trainable scheme for our pipeline. A small language model is adopted as a trainable rewriter to cater to the black-box {LLM} reader. The rewriter is trained using the feedback of the {LLM} reader by reinforcement learning. Evaluation is conducted on downstream tasks, open-domain {QA} and multiple-choice {QA}. Experiments results show consistent performance improvement, indicating that our framework is proven effective and scalable, and brings a new framework for retrieval-augmented {LLM} 1.},
	author = {Ma, Xinbei and Gong, Yeyun and He, Pengcheng and Zhao, Hai and Duan, Nan},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/N69RXH44/Ma et al. - Query Rewriting for Retrieval-Augmented Large Language Models.pdf:application/pdf},
}

@misc{cheng_uprise_2023,
	title = {{UPRISE}: Universal Prompt Retrieval for Improving Zero-Shot Evaluation},
	url = {http://arxiv.org/abs/2303.08518},
	shorttitle = {{UPRISE}},
	abstract = {Large Language Models ({LLMs}) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose {UPRISE} (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a crosstask and cross-model scenario: the retriever is tuned on diverse tasks, but tested on unseen task types; we use a small frozen {LLM}, {GPT}-Neo-2.7B, for tuning the retriever, but test the retriever on different {LLMs} of much larger scales, such as {BLOOM}-7.1B, {OPT}-66B and {GPT}3-175B. Additionally, we show that {UPRISE} mitigates the hallucination problem in our experiments with {ChatGPT}, suggesting its potential to improve even the strongest {LLMs}. Our model and code are available at https://github.com/microsoft/{LMOps}.},
	number = {{arXiv}:2303.08518},
	publisher = {{arXiv}},
	author = {Cheng, Daixuan and Huang, Shaohan and Bi, Junyu and Zhan, Yuefeng and Liu, Jianfeng and Wang, Yujing and Sun, Hao and Wei, Furu and Deng, Denvy and Zhang, Qi},
	urldate = {2025-02-25},
	date = {2023-12-16},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/AJVBXC8L/Cheng et al. - 2023 - UPRISE Universal Prompt Retrieval for Improving Zero-Shot Evaluation.pdf:application/pdf},
}

@misc{gao_retrieval-augmented_2024-1,
	title = {Retrieval-Augmented Generation for Large Language Models: A Survey},
	url = {http://arxiv.org/abs/2312.10997},
	shorttitle = {Retrieval-Augmented Generation for Large Language Models},
	abstract = {Large Language Models ({LLMs}) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation ({RAG}) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. {RAG} synergistically merges {LLMs}' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of {RAG} paradigms, encompassing the Naive {RAG}, the Advanced {RAG}, and the Modular {RAG}. It meticulously scrutinizes the tripartite foundation of {RAG} frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in {RAG} systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
	number = {{arXiv}:2312.10997},
	publisher = {{arXiv}},
	author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
	urldate = {2025-02-25},
	date = {2024-03-27},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/T362V5C7/Gao et al. - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey.pdf:application/pdf},
}

@misc{cho_improving_2023,
	title = {Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering},
	url = {http://arxiv.org/abs/2310.17490},
	abstract = {Large language models ({LLMs}) enable zeroshot approaches in open-domain question answering ({ODQA}), yet with limited advancements as the reader is compared to the retriever. This study aims at the feasibility of a zero-shot reader that addresses the challenges of computational cost and the need for labeled data. We find that {LLMs} are distracted due to irrelevant documents in the retrieved set and the overconfidence of the generated answers when they are exploited as zero-shot readers. To tackle these problems, we mitigate the impact of such documents via Distraction-aware Answer Selection ({DAS}) with a negation-based instruction and score adjustment for proper answer selection. Experimental results show that our approach successfully handles distraction across diverse scenarios, enhancing the performance of zeroshot readers. Furthermore, unlike supervised readers struggling with unseen data, zero-shot readers demonstrate outstanding transferability without any training.},
	number = {{arXiv}:2310.17490},
	publisher = {{arXiv}},
	author = {Cho, Sukmin and Seo, Jeongyeon and Jeong, Soyeong and Park, Jong C.},
	urldate = {2025-02-25},
	date = {2023-11-14},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/Z4L7ZZFU/Cho et al. - 2023 - Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Questio.pdf:application/pdf},
}

@misc{zhu_retrieving_2021,
	title = {Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering},
	url = {http://arxiv.org/abs/2101.00774},
	shorttitle = {Retrieving and Reading},
	abstract = {Open-domain Question Answering ({OpenQA}) is an important task in Natural Language Processing ({NLP}), which aims to answer a question in the form of natural language based on large-scale unstructured documents. Recently, there has been a surge in the amount of research literature on {OpenQA}, particularly on techniques that integrate with neural Machine Reading Comprehension ({MRC}). While these research works have advanced performance to new heights on benchmark datasets, they have been rarely covered in existing surveys on {QA} systems. In this work, we review the latest research trends in {OpenQA}, with particular attention to systems that incorporate neural {MRC} techniques. Speciﬁcally, we begin with revisiting the origin and development of {OpenQA} systems. We then introduce modern {OpenQA} architecture named “Retriever-Reader” and analyze the various systems that follow this architecture as well as the speciﬁc techniques adopted in each of the components. We then discuss key challenges to developing {OpenQA} systems and offer an analysis of benchmarks that are commonly used. We hope our work would enable researchers to be informed of the recent advancement and also the open challenges in {OpenQA} research, so as to stimulate further progress in this ﬁeld.},
	number = {{arXiv}:2101.00774},
	publisher = {{arXiv}},
	author = {Zhu, Fengbin and Lei, Wenqiang and Wang, Chao and Zheng, Jianming and Poria, Soujanya and Chua, Tat-Seng},
	urldate = {2025-02-24},
	date = {2021-05-08},
	langid = {english},
	keywords = {Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/RVPC8M8X/Zhu et al. - 2021 - Retrieving and Reading A Comprehensive Survey on Open-domain Question Answering.pdf:application/pdf},
}

@misc{jeong_adaptive-rag_2024,
	title = {Adaptive-{RAG}: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity},
	url = {http://arxiv.org/abs/2403.14403},
	shorttitle = {Adaptive-{RAG}},
	abstract = {Retrieval-Augmented Large Language Models ({LLMs}), which incorporate the non-parametric knowledge from external knowledge bases into {LLMs}, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering ({QA}). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries; yet, not all user requests fall into only one of the simple or complex categories. In this work, we propose a novel adaptive {QA} framework that can dynamically select the most suitable strategy for (retrieval-augmented) {LLMs} from the simplest to the most sophisticated ones based on the query complexity. Also, this selection process is operationalized with a classifier, which is a smaller {LM} trained to predict the complexity level of incoming queries with automatically collected labels, obtained from actual predicted outcomes of models and inherent inductive biases in datasets. This approach offers a balanced strategy, seamlessly adapting between the iterative and single-step retrieval-augmented {LLMs}, as well as the noretrieval methods, in response to a range of query complexities. We validate our model on a set of open-domain {QA} datasets, covering multiple query complexities, and show that ours enhances the overall efficiency and accuracy of {QA} systems, compared to relevant baselines including the adaptive retrieval approaches. Code is available at: https:// github.com/starsuzi/Adaptive-{RAG}.},
	number = {{arXiv}:2403.14403},
	publisher = {{arXiv}},
	author = {Jeong, Soyeong and Baek, Jinheon and Cho, Sukmin and Hwang, Sung Ju and Park, Jong C.},
	urldate = {2025-02-23},
	date = {2024-03-28},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/KYAWSIJU/Jeong et al. - 2024 - Adaptive-RAG Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexit.pdf:application/pdf},
}

@inproceedings{balfroid_towards_2024,
	title = {Towards {LLM}-Generated Code Tours for Onboarding},
	url = {https://ieeexplore.ieee.org/document/10647178/},
	abstract = {Onboarding new developers is a challenge for any software project. Addressing this challenge relies on human resources (e.g., having a senior developer write documentation or mentor the new developer). One promising solution is using annotated code tours. While this approach partially lifts the need for mentorship, it still requires a senior developer to write this interactive form of documentation. This paper argues that a Large Language Model ({LLM}) might help with this documentation process. Our approach is to record the stack trace between a failed test and a faulty method We then extract code snippets from the methods in this stack trace using {CodeQL}, a static analysis tool and have them explained by gpt-3.5-turbo-1106, the {LLM} behind {ChatGPT}. Finally, we evaluate the quality of a sample of these generated tours using a checklist We show that the automatic generation of code tours is feasible but has limitations like redundant and low-level explanations.{CCS} {CONCEPTS}• Computing methodologies → Natural language generation; • Software and its engineering → Software development process management.},
	eventtitle = {2024 {IEEE}/{ACM} International Workshop on Natural Language-Based Software Engineering ({NLBSE})},
	pages = {65--68},
	booktitle = {2024 {IEEE}/{ACM} International Workshop on Natural Language-Based Software Engineering ({NLBSE})},
	author = {Balfroid, Martin and Vanderose, Benoît and Devroey, Xavier},
	urldate = {2025-02-18},
	date = {2024-04},
	keywords = {Codes, large language models, code tour, Conferences, Debugging, developer onboarding, Documentation, Large language models, Natural language generation, Static analysis},
	file = {IEEE Xplore Abstract Record:/home/martin/Zotero/storage/56NXEBCJ/10647178.html:text/html},
}

@inproceedings{azanza_can_2024,
	title = {Can {LLMs} Facilitate Onboarding Software Developers? An Ongoing Industrial Case Study},
	url = {https://ieeexplore.ieee.org/document/10662989},
	shorttitle = {Can {LLMs} Facilitate Onboarding Software Developers?},
	abstract = {Onboarding new software developers presents per-sistent challenges for teams, with newcomers facing steep learning curves and senior staff burdened by providing training and mentoring. This research explores leveraging Large Language Models ({LLMs}) to streamline onboarding, mitigating productivity losses from disrupted workflows. We collaborated with {LKS} Next, an {IT} consulting firm that has experienced first hand the challenges onboarding new developers brings. This paper presents an ongoing case study within {LKS} Next, conducted using action design research methodology. Two cycles have been completed, gathering feedback from newcomers, team leaders, and managers on issues like the need to prioritize self-directed learning resources over “burdening” mentors, and considerations around using third-party {LLMs}. The third cycle will focus on evaluating open source {LLMs} to maintain control within the company. Our envisioned goal is to develop an {LLM}-powered conversational agent, delivering tailored onboarding support while avoiding privacy risks.},
	eventtitle = {2024 36th International Conference on Software Engineering Education and Training ({CSEE}\&T)},
	pages = {1--6},
	booktitle = {2024 36th International Conference on Software Engineering Education and Training ({CSEE}\&T)},
	author = {Azanza, Maider and Pereira, Juanan and Irastorza, Arantza and Galdos, Aritz},
	urldate = {2025-02-18},
	date = {2024-07},
	note = {{ISSN}: 2377-570X},
	keywords = {Large language models, Companies, Pressing, Privacy, Productivity, Prototypes, Training},
	file = {IEEE Xplore Abstract Record:/home/martin/Zotero/storage/L4SX3IVM/10662989.html:text/html},
}

@article{carrera-rivera_how-conduct_2022,
	title = {How-to conduct a systematic literature review: A quick guide for computer science research},
	volume = {9},
	issn = {2215-0161},
	url = {https://www.sciencedirect.com/science/article/pii/S2215016122002746},
	shorttitle = {How-to conduct a systematic literature review},
	abstract = {Performing a literature review is a critical first step in research to understanding the state-of-the-art and identifying gaps and challenges in the field. A systematic literature review is a method which sets out a series of steps to methodically organize the review. In this paper, we present a guide designed for researchers and in particular early-stage researchers in the computer-science field. The contribution of the article is the following:•Clearly defined strategies to follow for a systematic literature review in computer science research, and•Algorithmic method to tackle a systematic literature review.},
	pages = {101895},
	journaltitle = {{MethodsX}},
	shortjournal = {{MethodsX}},
	author = {Carrera-Rivera, Angela and Ochoa, William and Larrinaga, Felix and Lasa, Ganix},
	urldate = {2025-02-18},
	date = {2022-01-01},
	keywords = {computer science, doctoral studies, literature reviews, research methodology, Systematic literature reviews},
	file = {Full Text:/home/martin/Zotero/storage/QMYXZJI3/Carrera-Rivera et al. - 2022 - How-to conduct a systematic literature review A quick guide for computer science research.pdf:application/pdf;ScienceDirect Snapshot:/home/martin/Zotero/storage/C94Z362L/S2215016122002746.html:text/html},
}

@misc{lyu_gitagent_2023,
	title = {{GitAgent}: Facilitating Autonomous Agent with {GitHub} by Tool Extension},
	url = {http://arxiv.org/abs/2312.17294},
	shorttitle = {{GitAgent}},
	abstract = {While Large Language Models ({LLMs}) like {ChatGPT} and {GPT}-4 have demonstrated exceptional proficiency in natural language processing, their efficacy in addressing complex, multifaceted tasks remains limited. A growing area of research focuses on {LLM}-based agents equipped with external tools capable of performing diverse tasks. However, existing {LLM}-based agents only support a limited set of tools which is unable to cover a diverse range of user queries, especially for those involving expertise domains. It remains a challenge for {LLM}-based agents to extend their tools autonomously when confronted with various user queries. As {GitHub} has hosted a multitude of repositories which can be seen as a good resource for tools, a promising solution is that {LLM}-based agents can autonomously integrate the repositories in {GitHub} according to the user queries to extend their tool set. In this paper, we introduce {GITAGENT}, an agent capable of achieving the autonomous tool extension from {GitHub}. {GITAGENT} follows a four-phase procedure to incorporate repositories and it can learn human experience by resorting to {GitHub} Issues/{PRs} to solve problems encountered during the procedure. Experimental evaluation involving 30 user queries demonstrates {GITAGENT}’s effectiveness, achieving a 69.4\% success rate on average.},
	number = {{arXiv}:2312.17294},
	publisher = {{arXiv}},
	author = {Lyu, Bohan and Cong, Xin and Yu, Heyang and Yang, Pan and Qin, Yujia and Ye, Yining and Lu, Yaxi and Zhang, Zhong and Yan, Yukun and Lin, Yankai and Liu, Zhiyuan and Sun, Maosong},
	urldate = {2025-02-17},
	date = {2023-12-28},
	langid = {english},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Software Engineering},
	file = {PDF:/home/martin/Zotero/storage/YKU7T8FK/Lyu et al. - 2023 - GitAgent Facilitating Autonomous Agent with GitHub by Tool Extension.pdf:application/pdf},
}

@misc{liu_odyssey_2024,
	title = {Odyssey: Empowering Minecraft Agents with Open-World Skills},
	url = {http://arxiv.org/abs/2407.15325},
	shorttitle = {Odyssey},
	abstract = {Recent studies have delved into constructing generalist agents for open-world environments like Minecraft. Despite the encouraging results, existing efforts mainly focus on solving basic programmatic tasks, e.g., material collection and tool-crafting following the Minecraft tech-tree, treating the {ObtainDiamond} task as the ultimate goal. This limitation stems from the narrowly defined set of actions available to agents, requiring them to learn effective long-horizon strategies from scratch. Consequently, discovering diverse gameplay opportunities in the open world becomes challenging. In this work, we introduce {ODYSSEY}, a new framework that empowers Large Language Model ({LLM})-based agents with open-world skills to explore the vast Minecraft world. {ODYSSEY} comprises three key parts: (1) An interactive agent with an open-world skill library that consists of 40 primitive skills and 183 compositional skills. (2) A fine-tuned {LLaMA}-3 model trained on a large question-answering dataset with 390k+ instruction entries derived from the Minecraft Wiki. (3) A new agent capability benchmark includes the long-term planning task, the dynamic-immediate planning task, and the autonomous exploration task. Extensive experiments demonstrate that the proposed {ODYSSEY} framework can effectively evaluate different capabilities of {LLM}-based agents. All datasets, model weights, and code are publicly available to motivate future research on more advanced autonomous agent solutions.},
	number = {{arXiv}:2407.15325},
	publisher = {{arXiv}},
	author = {Liu, Shunyu and Li, Yaoru and Zhang, Kongcheng and Cui, Zhenyu and Fang, Wenkai and Zheng, Yuxuan and Zheng, Tongya and Song, Mingli},
	urldate = {2025-02-17},
	date = {2024-10-07},
	langid = {english},
	keywords = {Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/DYEG4UBJ/Liu et al. - 2024 - Odyssey Empowering Minecraft Agents with Open-World Skills.pdf:application/pdf},
}

@misc{wang_voyager_2023,
	title = {Voyager: An Open-Ended Embodied Agent with Large Language Models},
	url = {http://arxiv.org/abs/2305.16291},
	shorttitle = {Voyager},
	abstract = {We introduce {VOYAGER}, the first {LLM}-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. {VOYAGER} consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. {VOYAGER} interacts with {GPT}-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by {VOYAGER} are temporally extended, interpretable, and compositional, which compounds the agent’s abilities rapidly and alleviates catastrophic forgetting. Empirically, {VOYAGER} shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3× more unique items, travels 2.3× longer distances, and unlocks key tech tree milestones up to 15.3× faster than prior {SOTA}. {VOYAGER} is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize.},
	number = {{arXiv}:2305.16291},
	publisher = {{arXiv}},
	author = {Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
	urldate = {2025-02-17},
	date = {2023-10-19},
	langid = {english},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/BQM4B2W6/Wang et al. - 2023 - Voyager An Open-Ended Embodied Agent with Large Language Models.pdf:application/pdf},
}

@misc{dong_self-collaboration_2024,
	title = {Self-collaboration Code Generation via {ChatGPT}},
	url = {http://arxiv.org/abs/2304.07590},
	abstract = {Although Large Language Models ({LLMs}) have demonstrated remarkable code-generation ability, they still struggle with complex tasks. In real-world software development, humans usually tackle complex tasks through collaborative teamwork, a strategy that significantly controls development complexity and enhances software quality. Inspired by this, we present a self-collaboration framework for code generation employing {LLMs}, exemplified by {ChatGPT}. Specifically, through role instructions, 1) Multiple {LLM} agents act as distinct ‘experts’, each responsible for a specific subtask within a complex task; 2) Specify the way to collaborate and interact, so that different roles form a virtual team to facilitate each other’s work, ultimately the virtual team addresses code generation tasks collaboratively without the need for human intervention. To effectively organize and manage this virtual team, we incorporate software-development methodology into the framework. Thus, we assemble an elementary team consisting of three {LLM} roles (i.e., analyst, coder, and tester) responsible for software development’s analysis, coding, and testing stages. We conduct comprehensive experiments on various code-generation benchmarks. Experimental results indicate that self-collaboration code generation relatively improves 29.9\%-47.1\% Pass@1 compared to the base {LLM} agent. Moreover, we showcase that selfcollaboration could potentially enable {LLMs} to efficiently handle complex repository-level tasks that are not readily solved by the single {LLM} agent. {CCS} Concepts: • Software and its engineering → Software creation and management; • Computing methodologies → Artificial intelligence.},
	number = {{arXiv}:2304.07590},
	publisher = {{arXiv}},
	author = {Dong, Yihong and Jiang, Xue and Jin, Zhi and Li, Ge},
	urldate = {2025-02-11},
	date = {2024-05-11},
	langid = {english},
	keywords = {Computer Science - Software Engineering},
	file = {PDF:/home/martin/Zotero/storage/7KRB39EK/Dong et al. - 2024 - Self-collaboration Code Generation via ChatGPT.pdf:application/pdf},
}

@misc{jin_llms_2024,
	title = {From {LLMs} to {LLM}-based Agents for Software Engineering: A Survey of Current, Challenges and Future},
	url = {http://arxiv.org/abs/2408.02479},
	shorttitle = {From {LLMs} to {LLM}-based Agents for Software Engineering},
	abstract = {With the rise of large language models ({LLMs}), researchers are increasingly exploring their applications in various vertical domains, such as software engineering. {LLMs} have achieved remarkable success in areas including code generation and vulnerability detection. However, they also exhibit numerous limitations and shortcomings. {LLM}-based agents, a novel technology with the potential for Artificial General Intelligence ({AGI}), combine {LLMs} as the core for decision-making and action-taking, addressing some of the inherent limitations of {LLMs} such as lack of autonomy and self-improvement. Despite numerous studies and surveys exploring the possibility of using {LLMs} in software engineering, it lacks a clear distinction between {LLMs} and {LLMbased} agents. It is still in its early stage for a unified standard and benchmarking to qualify an {LLM} solution as an {LLM}-based agent in its domain. In this survey, we broadly investigate the current practice and solutions for {LLMs} and {LLM}-based agents for software engineering. In particular we summarise six key topics: requirement engineering, code generation, autonomous decision-making, software design, test generation, and software maintenance. We review and differentiate the work of {LLMs} and {LLM}-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Finally, we discuss the models and benchmarks used, providing a comprehensive analysis of their applications and effectiveness in software engineering. We anticipate this work will shed some lights on pushing the boundaries of {LLM}-based agents in software engineering for future research.},
	number = {{arXiv}:2408.02479},
	publisher = {{arXiv}},
	author = {Jin, Haolin and Huang, Linghan and Cai, Haipeng and Yan, Jun and Li, Bo and Chen, Huaming},
	urldate = {2025-02-11},
	date = {2024-08-05},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {PDF:/home/martin/Zotero/storage/LX4GP7RJ/Jin et al. - 2024 - From LLMs to LLM-based Agents for Software Engineering A Survey of Current, Challenges and Future.pdf:application/pdf},
}

@misc{xi_agentgym_2024,
	title = {{AgentGym}: Evolving Large Language Model-based Agents across Diverse Environments},
	url = {http://arxiv.org/abs/2406.04151},
	shorttitle = {{AgentGym}},
	abstract = {Building generalist agents that can handle diverse tasks and evolve themselves across different environments is a long-term goal in the {AI} community. Large language models ({LLMs}) are considered a promising foundation to build such agents due to their generalized capabilities. Current approaches either have {LLM}-based agents imitate expert-provided trajectories step-by-step, requiring human supervision, which is hard to scale and limits environmental exploration; or they let agents explore and learn in isolated environments, resulting in specialist agents with limited generalization. In this paper, we take the first step towards building generally-capable {LLM}-based agents with self-evolution ability. We identify a trinity of ingredients: 1) diverse environments for agent exploration and learning, 2) a trajectory set to equip agents with basic capabilities and prior knowledge, and 3) an effective and scalable evolution method. We propose {AGENTGYM}, a new framework featuring a variety of environments and tasks for broad, real-time, uni-format, and concurrent agent exploration. {AGENTGYM} also includes a database with expanded instructions, a benchmark suite, and high-quality trajectories across environments. Next, we propose a novel method, {AGENTEVOL}, to investigate the potential of agent self-evolution beyond previously seen data across tasks and environments. Experimental results show that the evolved agents can achieve results comparable to {SOTA} models. We release the {AGENTGYM} suite, including the platform, dataset, benchmark, checkpoints, and algorithm implementations.},
	number = {{arXiv}:2406.04151},
	publisher = {{arXiv}},
	author = {Xi, Zhiheng and Ding, Yiwen and Chen, Wenxiang and Hong, Boyang and Guo, Honglin and Wang, Junzhe and Yang, Dingwen and Liao, Chenyang and Guo, Xin and He, Wei and Gao, Songyang and Chen, Lu and Zheng, Rui and Zou, Yicheng and Gui, Tao and Zhang, Qi and Qiu, Xipeng and Huang, Xuanjing and Wu, Zuxuan and Jiang, Yu-Gang},
	urldate = {2025-01-24},
	date = {2024-06-06},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/LXCMEB5Q/Xi et al. - 2024 - AgentGym Evolving Large Language Model-based Agents across Diverse Environments.pdf:application/pdf},
}

@misc{chen_fireact_2023,
	title = {{FireAct}: Toward Language Agent Fine-tuning},
	url = {http://arxiv.org/abs/2310.05915},
	shorttitle = {{FireAct}},
	abstract = {Recent efforts have augmented language models ({LMs}) with external tools or environments, leading to the development of language agents that can reason and act. However, most of these agents rely on few-shot prompting techniques with off-the-shelf {LMs}. In this paper, we investigate and argue for the overlooked direction of fine-tuning {LMs} to obtain language agents. Using a setup of question answering ({QA}) with a Google search {API}, we explore a variety of base {LMs}, prompting methods, fine-tuning data, and {QA} tasks, and find language agents are consistently improved after fine-tuning their backbone {LMs}. For example, fine-tuning Llama2-7B with 500 agent trajectories generated by {GPT}-4 leads to a 77\% {HotpotQA} performance increase. Furthermore, we propose {FireAct}, a novel approach to fine-tuning {LMs} with trajectories from multiple tasks and prompting methods, and show having more diverse fine-tuning data can further improve agents. Along with other findings regarding scaling effects, robustness, generalization, efficiency and cost, our work establishes comprehensive benefits of fine-tuning {LMs} for agents, and provides an initial set of experimental designs, insights, as well as open questions toward language agent fine-tuning.},
	number = {{arXiv}:2310.05915},
	publisher = {{arXiv}},
	author = {Chen, Baian and Shu, Chang and Shareghi, Ehsan and Collier, Nigel and Narasimhan, Karthik and Yao, Shunyu},
	urldate = {2025-01-24},
	date = {2023-10-09},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/MWV8UZ3N/Chen et al. - 2023 - FireAct Toward Language Agent Fine-tuning.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/CVUY9IGR/2310.html:text/html},
}

@misc{chen_agent-flan_2024,
	title = {Agent-{FLAN}: Designing Data and Methods of Effective Agent Tuning for Large Language Models},
	url = {http://arxiv.org/abs/2403.12881},
	shorttitle = {Agent-{FLAN}},
	abstract = {Open-sourced Large Language Models ({LLMs}) have achieved great success in various {NLP} tasks, however, they are still far inferior to {API}-based models when acting as agents. How to integrate agent ability into general {LLMs} becomes a crucial and urgent problem. This paper first delivers three key observations: (1) the current agent training corpus is entangled with both formats following and agent reasoning, which significantly shifts from the distribution of its pre-training data; (2) {LLMs} exhibit different learning speeds on the capabilities required by agent tasks; and (3) current approaches have side-effects when improving agent abilities by introducing hallucinations. Based on the above findings, we propose {AgentFLAN} to effectively Fine-tune {LANguage} models for Agents. Through careful decomposition and redesign of the training corpus, Agent-{FLAN} enables Llama2-7B to outperform prior best works by 3.5\% across various agent evaluation datasets. With comprehensively constructed negative samples, Agent-{FLAN} greatly alleviates the hallucination issues based on our established evaluation benchmark. Besides, it consistently improves the agent capability of {LLMs} when scaling model sizes while slightly enhancing the general capability of {LLMs}. The code will be available at https://github.com/{InternLM}/Agent-{FLAN}.},
	number = {{arXiv}:2403.12881},
	publisher = {{arXiv}},
	author = {Chen, Zehui and Liu, Kuikun and Wang, Qiuchen and Zhang, Wenwei and Liu, Jiangning and Lin, Dahua and Chen, Kai and Zhao, Feng},
	urldate = {2025-01-24},
	date = {2024-03-19},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/CTZ68LA2/Chen et al. - 2024 - Agent-FLAN Designing Data and Methods of Effective Agent Tuning for Large Language Models.pdf:application/pdf},
}

@misc{zhang_offline_2024,
	title = {Offline Training of Language Model Agents with Functions as Learnable Weights},
	url = {http://arxiv.org/abs/2402.11359},
	abstract = {Researchers and practitioners have recently reframed powerful Large Language Models ({LLMs}) as agents, enabling them to automate complex tasks largely via the use of specialized functions. To facilitate the development of {LLM} agents, we present a novel paradigm of training {LLM} agents without modifying the {LLM} weights, which is particularly useful when the {LLMs} are difficult or inaccessible for modifications. Inspired by how humans continuously forge tools to adapt to realworld tasks, rather than change our biological structure to fit a static set of tools, we propose to progressively forge agent’s functions to better solve the downstream tasks instead of modifying the {LLM} weights. By treating the functions as learnable ‘agent parameters’ and leveraging the fundamental idea of model training in artificial intelligence, we develop {AgentOptimizer} that employs the {LLM} to update agents’ functions and devise an agent training algorithm with two strategies, roll-back, and early-stop, to streamline the training process. With extensive experiments, we showcase that the agent training paradigm could significantly improve the performance of representative {LLM} agents in various downstream tasks. We also study the behavior of the agent training regarding aspects like the learning curve and domain transferability. We have integrated our method into {AutoGen} library.},
	number = {{arXiv}:2402.11359},
	publisher = {{arXiv}},
	author = {Zhang, Shaokun and Zhang, Jieyu and Liu, Jiale and Song, Linxin and Wang, Chi and Krishna, Ranjay and Wu, Qingyun},
	urldate = {2025-01-23},
	date = {2024-07-30},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/3UDDRSCV/Zhang et al. - 2024 - Offline Training of Language Model Agents with Functions as Learnable Weights.pdf:application/pdf},
}

@misc{kim_llm_2024,
	title = {An {LLM} Compiler for Parallel Function Calling},
	url = {http://arxiv.org/abs/2312.04511},
	abstract = {The reasoning capabilities of the recent {LLMs} enable them to execute external function calls to overcome their inherent limitations, such as knowledge cutoffs, poor arithmetic skills, or lack of access to private data. This development has allowed {LLMs} to select and coordinate multiple functions based on the context to tackle more complex problems. However, current methods for function calling often require sequential reasoning and acting for each function which can result in high latency, cost, and sometimes inaccurate behavior. To address this, we introduce {LLMCompiler}, which executes functions in parallel to efficiently orchestrate multiple function calls. Drawing inspiration from the principles of classical compilers, {LLMCompiler} enables parallel function calling with three components: (i) a Function Calling Planner, formulating execution plans for function calling; (ii) a Task Fetching Unit, dispatching function calling tasks; and (iii) an Executor, executing these tasks in parallel. {LLMCompiler} automatically generates an optimized orchestration for the function calls and can be used with both open-source and closed-source models. We have benchmarked {LLMCompiler} on a range of tasks with different patterns of function calling. We observe consistent latency speedup of up to 3.7×, cost savings of up to 6.7×, and accuracy improvement of up to ∼9\% compared to {ReAct}. Our code is available at https://github.com/{SqueezeAILab}/{LLMCompiler}.},
	number = {{arXiv}:2312.04511},
	publisher = {{arXiv}},
	author = {Kim, Sehoon and Moon, Suhong and Tabrizi, Ryan and Lee, Nicholas and Mahoney, Michael W. and Keutzer, Kurt and Gholami, Amir},
	urldate = {2025-01-23},
	date = {2024-06-05},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/R4M6UYKS/Kim et al. - 2024 - An LLM Compiler for Parallel Function Calling.pdf:application/pdf},
}

@online{noauthor_deepseek-r1deepseek_r1pdf_nodate,
	title = {{DeepSeek}-R1/{DeepSeek}\_R1.pdf at main · deepseek-ai/{DeepSeek}-R1},
	url = {https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf},
	abstract = {Contribute to deepseek-ai/{DeepSeek}-R1 development by creating an account on {GitHub}.},
	titleaddon = {{GitHub}},
	urldate = {2025-01-22},
	langid = {english},
	file = {Snapshot:/home/martin/Zotero/storage/ZYJKHVGL/DeepSeek_R1.html:text/html},
}

@misc{cai_survey_2024,
	title = {A Survey on Mixture of Experts},
	url = {http://arxiv.org/abs/2407.06204},
	abstract = {Large language models ({LLMs}) have garnered unprecedented advancements across diverse fields, ranging from natural language processing to computer vision and beyond. The prowess of {LLMs} is underpinned by their substantial model size, extensive and diverse datasets, and the vast computational power harnessed during training, all of which contribute to the emergent abilities of {LLMs} (e.g., in-context learning) that are not present in small models. Within this context, the mixture of experts ({MoE}) has emerged as an effective method for substantially scaling up model capacity with minimal computation overhead, gaining significant attention from academia and industry. Despite its growing prevalence, there lacks a systematic and comprehensive review of the literature on {MoE}. This survey seeks to bridge that gap, serving as an essential resource for researchers delving into the intricacies of {MoE}. We first briefly introduce the structure of the {MoE} layer, followed by proposing a new taxonomy of {MoE}. Next, we overview the core designs for various {MoE} models including both algorithmic and systemic aspects, alongside collections of available open-source implementations, hyperparameter configurations and empirical evaluations. Furthermore, we delineate the multifaceted applications of {MoE} in practice, and outline some potential directions for future research. To facilitate ongoing updates and the sharing of cutting-edge advances in {MoE} research, we have established a resource repository accessible at https://github.com/withinmiaov/A-Survey-on-Mixture-of-Experts.},
	number = {{arXiv}:2407.06204},
	publisher = {{arXiv}},
	author = {Cai, Weilin and Jiang, Juyong and Wang, Fan and Tang, Jing and Kim, Sunghun and Huang, Jiayi},
	urldate = {2025-01-22},
	date = {2024-08-08},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {PDF:/home/martin/Zotero/storage/VDCWNGE8/Cai et al. - 2024 - A Survey on Mixture of Experts.pdf:application/pdf},
}

@misc{bai_training_2022,
	title = {Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},
	url = {http://arxiv.org/abs/2204.05862},
	abstract = {We apply preference modeling and reinforcement learning from human feedback ({RLHF}) to ﬁnetune language models to act as helpful and harmless assistants. We ﬁnd this alignment training improves performance on almost all {NLP} evaluations, and is fully compatible with training for specialized skills such as python coding and summarization. We explore an iterated online mode of training, where preference models and {RL} policies are updated on a weekly cadence with fresh human feedback data, efﬁciently improving our datasets and models. Finally, we investigate the robustness of {RLHF} training, and identify a roughly linear relation between the {RL} reward and the square root of the {KL} divergence between the policy and its initialization. Alongside our main results, we perform peripheral analyses on calibration, competing objectives, and the use of {OOD} detection, compare our models with human writers, and provide samples from our models using prompts appearing in recent related work.},
	number = {{arXiv}:2204.05862},
	publisher = {{arXiv}},
	author = {Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and {DasSarma}, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and Joseph, Nicholas and Kadavath, Saurav and Kernion, Jackson and Conerly, Tom and El-Showk, Sheer and Elhage, Nelson and Hatfield-Dodds, Zac and Hernandez, Danny and Hume, Tristan and Johnston, Scott and Kravec, Shauna and Lovitt, Liane and Nanda, Neel and Olsson, Catherine and Amodei, Dario and Brown, Tom and Clark, Jack and {McCandlish}, Sam and Olah, Chris and Mann, Ben and Kaplan, Jared},
	urldate = {2025-01-22},
	date = {2022-04-12},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {PDF:/home/martin/Zotero/storage/7S9Y3VMB/Bai et al. - 2022 - Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback.pdf:application/pdf},
}

@misc{sun_survey_2024,
	title = {A Survey of Reasoning with Foundation Models},
	url = {http://arxiv.org/abs/2312.11562},
	abstract = {Reasoning, a crucial ability for complex problem-solving, plays a pivotal role in various real-world settings such as negotiation, medical diagnosis, and criminal investigation. It serves as a fundamental methodology in the field of Artificial General Intelligence ({AGI}). With the ongoing development of foundation models, e.g., Large Language Models ({LLMs}), there is a growing interest in exploring their abilities in reasoning tasks. In this paper, we introduce seminal foundation models proposed or adaptable for reasoning, highlighting the latest advancements in various reasoning tasks, methods, and benchmarks. We then delve into the potential future directions behind the emergence of reasoning abilities within foundation models. We also discuss the relevance of multimodal learning, autonomous agents, and super alignment in the context of reasoning. By discussing these future research directions, we hope to inspire researchers in their exploration of this field, stimulate further advancements in reasoning with foundation models, and contribute to the development of {AGI}.},
	number = {{arXiv}:2312.11562},
	publisher = {{arXiv}},
	author = {Sun, Jiankai and Zheng, Chuanyang and Xie, Enze and Liu, Zhengying and Chu, Ruihang and Qiu, Jianing and Xu, Jiaqi and Ding, Mingyu and Li, Hongyang and Geng, Mengzhe and Wu, Yue and Wang, Wenhai and Chen, Junsong and Yin, Zhangyue and Ren, Xiaozhe and Fu, Jie and He, Junxian and Yuan, Wu and Liu, Qi and Liu, Xihui and Li, Yu and Dong, Hao and Cheng, Yu and Zhang, Ming and Heng, Pheng Ann and Dai, Jifeng and Luo, Ping and Wang, Jingdong and Wen, Ji-Rong and Qiu, Xipeng and Guo, Yike and Xiong, Hui and Liu, Qun and Li, Zhenguo},
	urldate = {2025-01-22},
	date = {2024-01-25},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/martin/Zotero/storage/FPBNG69C/Sun et al. - 2024 - A Survey of Reasoning with Foundation Models.pdf:application/pdf},
}

@misc{herandi_skill-llm_2024,
	title = {Skill-{LLM}: Repurposing General-Purpose {LLMs} for Skill Extraction},
	url = {http://arxiv.org/abs/2410.12052},
	shorttitle = {Skill-{LLM}},
	abstract = {Accurate skill extraction from job descriptions is crucial in the hiring process but remains challenging. Named Entity Recognition ({NER}) is a common approach used to address this issue. With the demonstrated success of large language models ({LLMs}) in various {NLP} tasks, including {NER}, we propose ﬁne-tuning a specialized Skill-{LLM} and a light weight model to improve the precision and quality of skill extraction. In our study, we evaluated the ﬁne-tuned Skill-{LLM} and the light weight model using a benchmark dataset and compared its performance against state-of-the-art ({SOTA}) methods. Our results show that this approach outperforms existing {SOTA} techniques.},
	number = {{arXiv}:2410.12052},
	publisher = {{arXiv}},
	author = {Herandi, Amirhossein and Li, Yitao and Liu, Zhanlin and Hu, Ximin and Cai, Xiao},
	urldate = {2024-12-03},
	date = {2024-10-15},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/5A2P2BCR/Herandi et al. - 2024 - Skill-LLM Repurposing General-Purpose LLMs for Skill Extraction.pdf:application/pdf},
}

@misc{li_skillgpt_2023,
	title = {{SkillGPT}: a {RESTful} {API} service for skill extraction and standardization using a Large Language Model},
	url = {http://arxiv.org/abs/2304.11060},
	shorttitle = {{SkillGPT}},
	abstract = {We present {SkillGPT}, a tool for skill extraction and standardization ({SES}) from free-style job descriptions and user profiles with an open-source Large Language Model ({LLM}) as backbone. Most previous methods for similar tasks either need supervision or rely on heavy data-preprocessing and feature engineering. Directly prompting the latest conversational {LLM} for standard skills, however, is slow, costly and inaccurate. In contrast, {SkillGPT} utilizes a {LLM} to perform its tasks in steps via summarization and vector similarity search, to balance speed with precision. The backbone {LLM} of {SkillGPT} is based on Llama, free for academic use and thus useful for exploratory research and prototype development. Hence, our cost-free {SkillGPT} gives users the convenience of conversational {SES}, efficiently and reliably.},
	number = {{arXiv}:2304.11060},
	publisher = {{arXiv}},
	author = {Li, Nan and Kang, Bo and Bie, Tijl De},
	urldate = {2024-12-03},
	date = {2023-10-18},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/7CTVVVTL/Li et al. - 2023 - SkillGPT a RESTful API service for skill extraction and standardization using a Large Language Mode.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/YGI5EMUZ/2304.html:text/html},
}

@article{gugnani_implicit_2020,
	title = {Implicit Skills Extraction Using Document Embedding and Its Use in Job Recommendation},
	volume = {34},
	rights = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/7038},
	abstract = {This paper presents a job recommender system to match resumes to job descriptions ({JD}), both of which are non-standard and unstructured/semi-structured in form. First, the paper proposes a combination of natural language processing ({NLP}) techniques for the task of skill extraction. The performance of the combined techniques on an industrial scale dataset yielded a precision and recall of 0.78 and 0.88 respectively. The paper then introduces the concept of extracting implicit skills – the skills which are not explicitly mentioned in a {JD} but may be implicit in the context of geography, industry or role. To mine and infer implicit skills for a {JD}, we find the other {JDs} similar to this {JD}. This similarity match is done in the semantic space. A Doc2Vec model is trained on 1.1 Million {JDs} covering several domains crawled from the web, and all the {JDs} are projected onto this semantic space. The skills absent in the {JD} but present in similar {JDs} are obtained, and the obtained skills are weighted using several techniques to obtain the set of final implicit skills. Finally, several similarity measures are explored to match the skills extracted from a candidate's resume to explicit and implicit skills of {JDs}. Empirical results for matching resumes and {JDs} demonstrate that the proposed approach gives a mean reciprocal rank of 0.88, an improvement of 29.4\% when compared to the performance of a baseline method that uses only explicit skills.},
	pages = {13286--13293},
	number = {8},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Gugnani, Akshay and Misra, Hemant},
	urldate = {2024-12-03},
	date = {2020-04-03},
	langid = {english},
	note = {Number: 08},
	file = {Full Text PDF:/home/martin/Zotero/storage/6MEDF9CA/Gugnani and Misra - 2020 - Implicit Skills Extraction Using Document Embedding and Its Use in Job Recommendation.pdf:application/pdf},
}

@inproceedings{gao_precise_2023-1,
	location = {Toronto, Canada},
	title = {Precise Zero-Shot Dense Retrieval without Relevance Labels},
	url = {https://aclanthology.org/2023.acl-long.99/},
	abstract = {While dense retrieval has been shown to be effective and efficient across tasks and languages, it remains difficult to create effective fully zero-shot dense retrieval systems when no relevance labels are available. In this paper, we recognize the difficulty of zero-shot learning and encoding relevance. Instead, we propose to pivot through Hypothetical Document Embeddings ({HyDE}). Given a query, {HyDE} first zero-shot prompts an instruction-following language model (e.g., {InstructGPT}) to generate a hypothetical document. The document captures relevance patterns but is “fake” and may contain hallucinations. Then, an unsupervised contrastively learned encoder (e.g., Contriever) encodes the document into an embedding vector. This vector identifies a neighborhood in the corpus embedding space, from which similar real documents are retrieved based on vector similarity. This second step grounds the generated document to the actual corpus, with the encoder`s dense bottleneck filtering out the hallucinations. Our experiments show that {HyDE} significantly outperforms the state-of-the-art unsupervised dense retriever Contriever and shows strong performance comparable to fine-tuned retrievers across various tasks (e.g. web search, {QA}, fact verification) and in non-English languages (e.g., sw, ko, ja, bn).},
	eventtitle = {{ACL} 2023},
	pages = {1762--1777},
	booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Gao, Luyu and Ma, Xueguang and Lin, Jimmy and Callan, Jamie},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	urldate = {2025-04-07},
	date = {2023-07},
	file = {Full Text PDF:/home/martin/Zotero/storage/9LXWS7DJ/Gao et al. - 2023 - Precise Zero-Shot Dense Retrieval without Relevance Labels.pdf:application/pdf},
}

@online{kelk_what_nodate,
	title = {What is {RAG}? (Retrieval Augmented Generation)},
	url = {https://www.clarifai.com/blog/what-is-rag-retrieval-augmented-generation},
	shorttitle = {What is {RAG}?},
	abstract = {Retrieval Augmented Generation ({RAG}) enhances {LLMs} by integrating real-time, external knowledge, improving the quality of their responses.},
	author = {Kelk, Ian},
	urldate = {2025-04-09},
	langid = {english},
	file = {Snapshot:/home/martin/Zotero/storage/XEFDJAYP/what-is-rag-retrieval-augmented-generation.html:text/html},
}

@misc{krishna_rankgen_2022,
	title = {{RankGen}: Improving Text Generation with Large Ranking Models},
	url = {http://arxiv.org/abs/2205.09726},
	shorttitle = {{RankGen}},
	abstract = {Given an input sequence (or prefix), modern language models often assign high probabilities to output sequences that are repetitive, incoherent, or irrelevant to the prefix; as such, model-generated text also contains such artifacts. To address these issues we present {RankGen}, a 1.2B parameter encoder model for English that scores model generations given a prefix. {RankGen} can be flexibly incorporated as a scoring function in beam search and used to decode from any pretrained language model. We train {RankGen} using large-scale contrastive learning to map a prefix close to the ground-truth sequence that follows it and far away from two types of negatives: (1) random sequences from the same document as the prefix, and (2) sequences generated from a large language model conditioned on the prefix. Experiments across four different language models (345M-11B parameters) and two domains show that {RankGen} significantly outperforms decoding algorithms like nucleus, top-k, and typical sampling, as well as contrastive decoding and search, on both automatic metrics (85.0 vs 77.3 {MAUVE} over nucleus) as well as human evaluations with English writers (74.5\% human preference over nucleus sampling). Analysis reveals that {RankGen} outputs are more relevant to the prefix and improve continuity and coherence compared to baselines. We release our model checkpoints, code, and human preference data with explanations to facilitate future research.},
	number = {{arXiv}:2205.09726},
	publisher = {{arXiv}},
	author = {Krishna, Kalpesh and Chang, Yapei and Wieting, John and Iyyer, Mohit},
	urldate = {2025-04-09},
	date = {2022-11-14},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {PDF:/home/martin/Zotero/storage/8RKQ6YUD/Krishna et al. - 2022 - RankGen Improving Text Generation with Large Ranking Models.pdf:application/pdf},
}

@misc{xiong_approximate_2020,
	title = {Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval},
	url = {http://arxiv.org/abs/2007.00808},
	abstract = {Conducting text retrieval in a dense representation space has many intriguing advantages. Yet the end-to-end learned dense retrieval ({DR}) often underperforms word-based sparse retrieval. In this paper, we ﬁrst theoretically show the learning bottleneck of dense retrieval is due to the domination of uninformative negatives sampled locally in batch, which yield diminishing gradient norms, large stochastic gradient variances, and slow learning convergence. We then propose Approximate nearest neighbor Negative Contrastive Learning ({ANCE}), a learning mechanism that selects hard training negatives globally from the entire corpus, using an asynchronously updated {ANN} index. Our experiments demonstrate the effectiveness of {ANCE} on web search, question answering, and in a commercial search environment, showing {ANCE} dot-product retrieval nearly matches the accuracy of {BERT}-based cascade {IR} pipeline, while being 100x more efﬁcient.},
	number = {{arXiv}:2007.00808},
	publisher = {{arXiv}},
	author = {Xiong, Lee and Xiong, Chenyan and Li, Ye and Tang, Kwok-Fung and Liu, Jialin and Bennett, Paul and Ahmed, Junaid and Overwijk, Arnold},
	urldate = {2025-04-09},
	date = {2020-10-20},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Information Retrieval},
	file = {PDF:/home/martin/Zotero/storage/BX2AFM9V/Xiong et al. - 2020 - Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval.pdf:application/pdf},
}

@misc{izacard_leveraging_2021,
	title = {Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering},
	url = {http://arxiv.org/abs/2007.01282},
	abstract = {Generative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can beneﬁt from retrieving text passages, potentially containing evidence. We obtain state-of-theart results on the Natural Questions and {TriviaQA} open benchmarks. Interestingly, we observe that the performance of this method signiﬁcantly improves when increasing the number of retrieved passages. This is evidence that sequence-to-sequence models offers a ﬂexible framework to efﬁciently aggregate and combine evidence from multiple passages.},
	number = {{arXiv}:2007.01282},
	publisher = {{arXiv}},
	author = {Izacard, Gautier and Grave, Edouard},
	urldate = {2025-04-09},
	date = {2021-02-03},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {PDF:/home/martin/Zotero/storage/27SAFRYV/Izacard and Grave - 2021 - Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering.pdf:application/pdf},
}

@misc{lazaridou_internet-augmented_2022,
	title = {Internet-augmented language models through few-shot prompting for open-domain question answering},
	url = {http://arxiv.org/abs/2203.05115},
	abstract = {In this work, we aim to capitalize on the unique few-shot capabilities of large-scale language models ({LSLMs}) to overcome some of their challenges with respect to grounding to factual and up-to-date information. Motivated by semi-parametric language models ({LMs}), which ground their decisions in external retrieved evidence, we use few-shot prompting to learn to condition {LMs} on information returned from the web using Google Search, a broad and constantly updated knowledge source. Our approach does not involve fine-tuning or learning additional parameters, thus making it applicable to any {LM}, offering therefore a strong baseline. Indeed, we find that {LMs} conditioned on the web surpass performance of closed-book models of similar, or even larger, model sizes in open-domain question answering. Finally, we find that increasing the inference-time compute of models, achieved via using multiple retrieved evidences to generate multiple answers followed by a reranking stage that uses scores generated by the same {LMs}, leads to better performance and alleviates lower performance of smaller few-shot {LMs}. All in all, our findings suggest that it might be beneficial to slow down the race towards the biggest model and instead shift attention towards finding more effective ways to use models, including but not limited to, better prompting or increasing inference-time compute.},
	number = {{arXiv}:2203.05115},
	publisher = {{arXiv}},
	author = {Lazaridou, Angeliki and Gribovskaya, Elena and Stokowiec, Wojciech and Grigorev, Nikolai},
	urldate = {2025-04-09},
	date = {2022-05-23},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/home/martin/Zotero/storage/B7IG38NP/Lazaridou et al. - 2022 - Internet-augmented language models through few-shot prompting for open-domain question answering.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/78MPWR2I/2203.html:text/html},
}

@misc{cho_improving_2023-1,
	title = {Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering},
	url = {http://arxiv.org/abs/2310.17490},
	abstract = {Large language models ({LLMs}) enable zero-shot approaches in open-domain question answering ({ODQA}), yet with limited advancements as the reader is compared to the retriever. This study aims at the feasibility of a zero-shot reader that addresses the challenges of computational cost and the need for labeled data. We find that {LLMs} are distracted due to irrelevant documents in the retrieved set and the overconfidence of the generated answers when they are exploited as zero-shot readers. To tackle these problems, we mitigate the impact of such documents via Distraction-aware Answer Selection ({DAS}) with a negation-based instruction and score adjustment for proper answer selection. Experimental results show that our approach successfully handles distraction across diverse scenarios, enhancing the performance of zero-shot readers. Furthermore, unlike supervised readers struggling with unseen data, zero-shot readers demonstrate outstanding transferability without any training.},
	number = {{arXiv}:2310.17490},
	publisher = {{arXiv}},
	author = {Cho, Sukmin and Seo, Jeongyeon and Jeong, Soyeong and Park, Jong C.},
	urldate = {2025-04-09},
	date = {2023-11-14},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/G3DRH4FD/Cho et al. - 2023 - Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Questio.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/TFUIHWPE/2310.html:text/html},
}

@inproceedings{shao_enhancing_2023,
	location = {Singapore},
	title = {Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy},
	url = {https://aclanthology.org/2023.findings-emnlp.620/},
	abstract = {Retrieval-augmented generation has raise extensive attention as it is promising to address the limitations of large language models including outdated knowledge and hallucinations. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to guide retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-{RetGen}, which synergizes retrieval and generation in an iterative manner: a model`s response to a task input shows what might be needed to finish the task, and thus can serve as an informative context for retrieving more relevant knowledge which in turn helps generate a better response in another iteration. Compared with recent work which interleaves retrieval with generation when completing a single output, Iter-{RetGen} processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate Iter-{RetGen} on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.},
	eventtitle = {Findings 2023},
	pages = {9248--9274},
	booktitle = {Findings of the Association for Computational Linguistics: {EMNLP} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Huang, Minlie and Duan, Nan and Chen, Weizhu},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	urldate = {2025-04-09},
	date = {2023-12},
	file = {Full Text PDF:/home/martin/Zotero/storage/MSJYJA72/Shao et al. - 2023 - Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy.pdf:application/pdf},
}

@misc{izacard_atlas_2022,
	title = {Atlas: Few-shot Learning with Retrieval Augmented Language Models},
	url = {http://arxiv.org/abs/2208.03299},
	shorttitle = {Atlas},
	abstract = {Large language models have shown impressive few-shot results on a wide range of tasks. However, when knowledge is key for such results, as is the case for tasks such as question answering and fact checking, massive parameter counts to store knowledge seem to be needed. Retrieval augmented models are known to excel at knowledge intensive tasks without the need for as many parameters, but it is unclear whether they work in few-shot settings. In this work we present Atlas, a carefully designed and pre-trained retrieval augmented language model able to learn knowledge intensive tasks with very few training examples. We perform evaluations on a wide range of tasks, including {MMLU}, {KILT} and {NaturalQuestions}, and study the impact of the content of the document index, showing that it can easily be updated. Notably, Atlas reaches over 42\% accuracy on Natural Questions using only 64 examples, outperforming a 540B parameters model by 3\% despite having 50x fewer parameters.},
	number = {{arXiv}:2208.03299},
	publisher = {{arXiv}},
	author = {Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
	urldate = {2025-04-09},
	date = {2022-11-16},
	langid = {english},
	keywords = {Computer Science - Computation and Language},
	file = {PDF:/home/martin/Zotero/storage/BV89SMCW/Izacard et al. - 2022 - Atlas Few-shot Learning with Retrieval Augmented Language Models.pdf:application/pdf},
}

@misc{jeong_adaptive-rag_2024-1,
	title = {Adaptive-{RAG}: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity},
	url = {http://arxiv.org/abs/2403.14403},
	shorttitle = {Adaptive-{RAG}},
	abstract = {Retrieval-Augmented Large Language Models ({LLMs}), which incorporate the non-parametric knowledge from external knowledge bases into {LLMs}, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering ({QA}). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries; yet, not all user requests fall into only one of the simple or complex categories. In this work, we propose a novel adaptive {QA} framework, that can dynamically select the most suitable strategy for (retrieval-augmented) {LLMs} from the simplest to the most sophisticated ones based on the query complexity. Also, this selection process is operationalized with a classifier, which is a smaller {LM} trained to predict the complexity level of incoming queries with automatically collected labels, obtained from actual predicted outcomes of models and inherent inductive biases in datasets. This approach offers a balanced strategy, seamlessly adapting between the iterative and single-step retrieval-augmented {LLMs}, as well as the no-retrieval methods, in response to a range of query complexities. We validate our model on a set of open-domain {QA} datasets, covering multiple query complexities, and show that ours enhances the overall efficiency and accuracy of {QA} systems, compared to relevant baselines including the adaptive retrieval approaches. Code is available at: https://github.com/starsuzi/Adaptive-{RAG}.},
	number = {{arXiv}:2403.14403},
	publisher = {{arXiv}},
	author = {Jeong, Soyeong and Baek, Jinheon and Cho, Sukmin and Hwang, Sung Ju and Park, Jong C.},
	urldate = {2025-04-09},
	date = {2024-03-28},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/EGWE4BH5/Jeong et al. - 2024 - Adaptive-RAG Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexit.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/CSDZ7PS3/2403.html:text/html},
}

@misc{rana_sayplan_2023,
	title = {{SayPlan}: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning},
	url = {http://arxiv.org/abs/2307.06135},
	shorttitle = {{SayPlan}},
	abstract = {Large language models ({LLMs}) have demonstrated impressive results in developing generalist planning agents for diverse tasks. However, grounding these plans in expansive, multi-floor, and multi-room environments presents a significant challenge for robotics. We introduce {SayPlan}, a scalable approach to {LLM}-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations. To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow {LLMs} to conduct a 'semantic search' for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the {LLM} by integrating a classical path planner and (3) introduce an 'iterative replanning' pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures. We evaluate our approach on two large-scale environments spanning up to 3 floors and 36 rooms with 140 assets and objects and show that our approach is capable of grounding large-scale, long-horizon task plans from abstract, and natural language instruction for a mobile manipulator robot to execute. We provide real robot video demonstrations on our project page https://sayplan.github.io.},
	number = {{arXiv}:2307.06135},
	publisher = {{arXiv}},
	author = {Rana, Krishan and Haviland, Jesse and Garg, Sourav and Abou-Chakra, Jad and Reid, Ian and Suenderhauf, Niko},
	urldate = {2025-04-09},
	date = {2023-09-27},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
	file = {Preprint PDF:/home/martin/Zotero/storage/AL3NGMTC/Rana et al. - 2023 - SayPlan Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/JF3R63CV/2307.html:text/html},
}

@misc{qian_chatdev_2024,
	title = {{ChatDev}: Communicative Agents for Software Development},
	url = {http://arxiv.org/abs/2307.07924},
	shorttitle = {{ChatDev}},
	abstract = {Software development is a complex task that necessitates cooperation among multiple members with diverse skills. Numerous studies used deep learning to improve specific phases in a waterfall model, such as design, coding, and testing. However, the deep learning model in each phase requires unique designs, leading to technical inconsistencies across various phases, which results in a fragmented and ineffective development process. In this paper, we introduce {ChatDev}, a chat-powered software development framework in which specialized agents driven by large language models ({LLMs}) are guided in what to communicate (via chat chain) and how to communicate (via communicative dehallucination). These agents actively contribute to the design, coding, and testing phases through unified language-based communication, with solutions derived from their multi-turn dialogues. We found their utilization of natural language is advantageous for system design, and communicating in programming language proves helpful in debugging. This paradigm demonstrates how linguistic communication facilitates multi-agent collaboration, establishing language as a unifying bridge for autonomous task-solving among {LLM} agents. The code and data are available at https://github.com/{OpenBMB}/{ChatDev}.},
	number = {{arXiv}:2307.07924},
	publisher = {{arXiv}},
	author = {Qian, Chen and Liu, Wei and Liu, Hongzhang and Chen, Nuo and Dang, Yufan and Li, Jiahao and Yang, Cheng and Chen, Weize and Su, Yusheng and Cong, Xin and Xu, Juyuan and Li, Dahai and Liu, Zhiyuan and Sun, Maosong},
	urldate = {2025-04-09},
	date = {2024-06-05},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Multiagent Systems, Computer Science - Software Engineering},
	file = {PDF:/home/martin/Zotero/storage/YZSX4PJP/Qian et al. - 2024 - ChatDev Communicative Agents for Software Development.pdf:application/pdf},
}

@misc{zhang_graph-toolformer_2023,
	title = {Graph-{ToolFormer}: To Empower {LLMs} with Graph Reasoning Ability via Prompt Augmented by {ChatGPT}},
	url = {http://arxiv.org/abs/2304.11116},
	shorttitle = {Graph-{ToolFormer}},
	abstract = {In this paper, we aim to develop a large language model ({LLM}) with the reasoning ability on complex graph data. Currently, {LLMs} have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing {LLMs} present very serious flaws due to their several inherited weaknesses in performing \{multi-step logic reasoning\}, \{precise mathematical calculation\} and \{perception about the spatial and temporal factors\}. To address such challenges, in this paper, we will investigate the principles, methodologies and algorithms to empower existing {LLMs} with graph reasoning ability, which will have tremendous impacts on the current research of both {LLMs} and graph learning. Inspired by the latest {ChatGPT} and Toolformer models, we propose the Graph-{ToolFormer} (Graph Reasoning oriented Toolformer) framework to teach {LLMs} themselves with prompts augmented by {ChatGPT} to use external graph reasoning {API} tools. Specifically, we will investigate to teach Graph-{ToolFormer} to handle various graph data reasoning tasks in this paper, including both (1) very basic graph data loading and graph property reasoning tasks, ranging from simple graph order and size to the graph diameter and periphery, and (2) more advanced reasoning tasks on real-world graph data, such as bibliographic networks, protein molecules, sequential recommender systems, social networks and knowledge graphs.},
	number = {{arXiv}:2304.11116},
	publisher = {{arXiv}},
	author = {Zhang, Jiawei},
	urldate = {2025-04-09},
	date = {2023-05-11},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/7JDU8EZE/Zhang - 2023 - Graph-ToolFormer To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/KN2FWLRL/2304.html:text/html},
}

@article{wang_survey_2024,
	title = {A survey on large language model based autonomous agents},
	volume = {18},
	issn = {2095-2236},
	url = {https://doi.org/10.1007/s11704-024-40231-1},
	abstract = {Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models ({LLMs}) have shown potential in human-level intelligence, leading to a surge in research on {LLM}-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of {LLM}-based autonomous agents from a holistic perspective. We first discuss the construction of {LLM}-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of {LLM}-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for {LLM}-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.},
	pages = {186345},
	number = {6},
	journaltitle = {Frontiers of Computer Science},
	shortjournal = {Front. Comput. Sci.},
	author = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Jirong},
	urldate = {2025-04-09},
	date = {2024-03-22},
	langid = {english},
	keywords = {Artificial Intelligence, autonomous agent, human-level intelligence, large language model},
	file = {Full Text PDF:/home/martin/Zotero/storage/MNG4J64P/Wang et al. - 2024 - A survey on large language model based autonomous agents.pdf:application/pdf},
}

@misc{deepseek-ai_deepseek-r1_2025,
	title = {{DeepSeek}-R1: Incentivizing Reasoning Capability in {LLMs} via Reinforcement Learning},
	url = {http://arxiv.org/abs/2501.12948},
	shorttitle = {{DeepSeek}-R1},
	abstract = {We introduce our first-generation reasoning models, {DeepSeek}-R1-Zero and {DeepSeek}-R1. {DeepSeek}-R1-Zero, a model trained via large-scale reinforcement learning ({RL}) without supervised fine-tuning ({SFT}) as a preliminary step, demonstrates remarkable reasoning capabilities. Through {RL}, {DeepSeek}-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce {DeepSeek}-R1, which incorporates multi-stage training and cold-start data before {RL}. {DeepSeekR}1 achieves performance comparable to {OpenAI}-o1-1217 on reasoning tasks. To support the research community, we open-source {DeepSeek}-R1-Zero, {DeepSeek}-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from {DeepSeek}-R1 based on Qwen and Llama.},
	number = {{arXiv}:2501.12948},
	publisher = {{arXiv}},
	author = {{DeepSeek}-{AI} and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
	urldate = {2025-04-10},
	date = {2025-01-22},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/Z4E9HL5Y/DeepSeek-AI et al. - 2025 - DeepSeek-R1 Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.pdf:application/pdf},
}

@online{kalliamvakou_research_2022,
	title = {Research: quantifying {GitHub} Copilot’s impact on developer productivity and happiness},
	url = {https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness/},
	shorttitle = {Research},
	abstract = {When the {GitHub} Copilot Technical Preview launched just over one year ago, we wanted to know one thing: Is this tool helping developers? The {GitHub} Next team conducted research using a combination of surveys and experiments, which led us to expected and unexpected answers.},
	titleaddon = {The {GitHub} Blog},
	author = {Kalliamvakou, Eirini},
	urldate = {2025-04-12},
	date = {2022-09-07},
	langid = {american},
	file = {Snapshot:/home/martin/Zotero/storage/7BBSNV2Q/research-quantifying-github-copilots-impact-on-developer-productivity-and-happiness.html:text/html},
}

@online{noauthor_github_nodate,
	title = {{GitHub} Copilot features},
	url = {https://docs-internal.github.com/en/copilot/about-github-copilot/github-copilot-features},
	abstract = {{GitHub} Copilot offers a suite of features. Copilot also offers a suite of features for administrators.},
	titleaddon = {{GitHub} Docs},
	urldate = {2025-04-12},
	langid = {english},
	file = {Snapshot:/home/martin/Zotero/storage/YQAYC4GM/github-copilot-features.html:text/html},
}

@misc{jimenez_swe-bench_2024,
	title = {{SWE}-bench: Can Language Models Resolve Real-World {GitHub} Issues?},
	url = {http://arxiv.org/abs/2310.06770},
	shorttitle = {{SWE}-bench},
	abstract = {Language models have outpaced our ability to evaluate them effectively, but for their future development it is essential to study the frontier of their capabilities. We find real-world software engineering to be a rich, sustainable, and challenging testbed for evaluating the next generation of language models. To this end, we introduce {SWE}-bench, an evaluation framework consisting of 2,294 software engineering problems drawn from real {GitHub} issues and corresponding pull requests across 12 popular Python repositories. Given a codebase along with a description of an issue to be resolved, a language model is tasked with editing the codebase to address the issue. Resolving issues in {SWE}-bench frequently requires understanding and coordinating changes across multiple functions, classes, and even files simultaneously, calling for models to interact with execution environments, process extremely long contexts and perform complex reasoning that goes far beyond traditional code generation tasks. Our evaluations show that both state-ofthe-art proprietary models and our fine-tuned model {SWE}-Llama can resolve only the simplest issues. The best-performing model, Claude 2, is able to solve a mere 1.96\% of the issues. Advances on {SWE}-bench represent steps towards {LMs} that are more practical, intelligent, and autonomous.},
	number = {{arXiv}:2310.06770},
	publisher = {{arXiv}},
	author = {Jimenez, Carlos E. and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
	urldate = {2025-04-12},
	date = {2024-11-11},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {PDF:/home/martin/Zotero/storage/YAT7D3Y7/Jimenez et al. - 2024 - SWE-bench Can Language Models Resolve Real-World GitHub Issues.pdf:application/pdf},
}

@online{noauthor_swe-bench_nodate,
	title = {{SWE}-bench},
	url = {https://www.swebench.com/},
	abstract = {{SWE}-bench: Evaluate Language Models on Open Source Software Tasks},
	urldate = {2025-04-12},
	file = {Snapshot:/home/martin/Zotero/storage/FHXSTZK6/www.swebench.com.html:text/html},
}

@software{noauthor_aider-aiaider_2025,
	title = {Aider-{AI}/aider},
	rights = {Apache-2.0},
	url = {https://github.com/Aider-AI/aider},
	abstract = {aider is {AI} pair programming in your terminal},
	publisher = {Aider {AI}},
	urldate = {2025-04-12},
	date = {2025-04-12},
	note = {original-date: 2023-05-09T18:57:49Z},
	keywords = {anthropic, chatgpt, claude-3, cli, command-line, gemini, gpt-3, gpt-35-turbo, gpt-4, gpt-4o, llama, openai, sonnet},
}

@online{noauthor_building_2023,
	title = {Building a better repository map with tree sitter},
	url = {https://aider.chat/2023/10/22/repomap.html},
	abstract = {Tree-sitter allows aider to build a repo map that better summarizes large code bases.},
	titleaddon = {aider},
	urldate = {2025-04-12},
	date = {2023-10-22},
	langid = {american},
	file = {Snapshot:/home/martin/Zotero/storage/SZFZ2QQB/repomap.html:text/html},
}

@online{acharya_devin_2025,
	title = {Devin: A Cautionary Tale of the Autonomous {AI} Engineer},
	url = {https://medium.com/@lotussavy/devin-a-cautionary-tale-of-the-autonomous-ai-engineer-e1339ede8f8a},
	shorttitle = {Devin},
	abstract = {The emergence of Devin, an {AI} promising to revolutionize software development as a fully autonomous engineer, captured the tech world’s…},
	titleaddon = {Medium},
	author = {Acharya, Kamal},
	urldate = {2025-04-12},
	date = {2025-01-30},
	langid = {english},
	file = {Snapshot:/home/martin/Zotero/storage/S29FNAPW/devin-a-cautionary-tale-of-the-autonomous-ai-engineer-e1339ede8f8a.html:text/html},
}

@online{noauthor_sourcegraphsourcegraph-public-snapshot_nodate,
	title = {sourcegraph/sourcegraph-public-snapshot: Code {AI} platform with Code Search \& Cody},
	url = {https://github.com/sourcegraph/sourcegraph-public-snapshot},
	urldate = {2025-04-12},
	file = {sourcegraph/sourcegraph-public-snapshot\: Code AI platform with Code Search & Cody:/home/martin/Zotero/storage/9CP7ETKS/sourcegraph-public-snapshot.html:text/html},
}

@online{noauthor_cody_nodate,
	title = {Cody - Sourcegraph docs},
	url = {https://sourcegraph.com/docs},
	abstract = {Documentation for Sourcegraph, the code intelligence platform.},
	urldate = {2025-04-12},
	langid = {english},
	file = {Snapshot:/home/martin/Zotero/storage/HWG2P9B3/cody.html:text/html},
}

@software{noauthor_sourcegraphscip_2025,
	title = {sourcegraph/scip},
	rights = {Apache-2.0},
	url = {https://github.com/sourcegraph/scip},
	abstract = {{SCIP} Code Intelligence Protocol},
	publisher = {Sourcegraph},
	urldate = {2025-04-12},
	date = {2025-04-11},
	note = {original-date: 2022-05-10T13:18:47Z},
}

@misc{hu_lora_2021,
	title = {{LoRA}: Low-Rank Adaptation of Large Language Models},
	url = {http://arxiv.org/abs/2106.09685},
	shorttitle = {{LoRA}},
	abstract = {The dominant paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, conventional ﬁne-tuning, which retrains all model parameters, becomes less feasible. Using {GPT}-3 175B as an example, deploying many independent instances of ﬁne-tuned models, each with 175B parameters, is extremely expensive. We propose Low-Rank Adaptation, or {LoRA}, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. For {GPT}-3, {LoRA} can reduce the number of trainable parameters by 10,000 times and the computation hardware requirement by 3 times compared to full ﬁne-tuning. {LoRA} performs on-par or better than ﬁne-tuning in model quality on both {GPT}-3 and {GPT}-2, despite having fewer trainable parameters, a higher training throughput, and no additional inference latency. We also provide an empirical investigation into rank-deﬁciency in language model adaptations, which sheds light on the efﬁcacy of {LoRA}. We release our implementation in {GPT}-2 at https://github.com/microsoft/{LoRA}.},
	number = {{arXiv}:2106.09685},
	publisher = {{arXiv}},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	urldate = {2025-04-12},
	date = {2021-10-16},
	langid = {english},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/martin/Zotero/storage/PU7GXEYG/Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf:application/pdf},
}

@misc{zeng_agenttuning_2023,
	title = {{AgentTuning}: Enabling Generalized Agent Abilities for {LLMs}},
	url = {http://arxiv.org/abs/2310.12823},
	shorttitle = {{AgentTuning}},
	abstract = {Open large language models ({LLMs}) with great performance in various tasks have significantly advanced the development of {LLMs}. However, they are far inferior to commercial models such as {ChatGPT} and {GPT}-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ {LLMs} as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust {LLMs} to achieve satisfactory performance. Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of {LLMs} themselves without compromising their general abilities. In this work, we present {AgentTuning}, a simple and general method to enhance the agent abilities of {LLMs} while maintaining their general {LLM} capabilities. We construct {AgentInstruct}, a lightweight instruction-tuning dataset containing high-quality interaction trajectories. We employ a hybrid instruction-tuning strategy by combining {AgentInstruct} with open-source instructions from general domains. {AgentTuning} is used to instruction-tune the Llama 2 series, resulting in {AgentLM}. Our evaluations show that {AgentTuning} enables {LLMs}' agent capabilities without compromising general abilities. The {AgentLM}-70B is comparable to {GPT}-3.5-turbo on unseen agent tasks, demonstrating generalized agent capabilities. We open source the {AgentInstruct} and {AgentLM}-7B, 13B, and 70B models at https://github.com/{THUDM}/{AgentTuning}, serving open and powerful alternatives to commercial {LLMs} for agent tasks.},
	number = {{arXiv}:2310.12823},
	publisher = {{arXiv}},
	author = {Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie},
	urldate = {2025-04-12},
	date = {2023-10-22},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/MW47Z83Y/Zeng et al. - 2023 - AgentTuning Enabling Generalized Agent Abilities for LLMs.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/5VKA2B9R/2310.html:text/html},
}

@inproceedings{azanza_can_2024-1,
	title = {Can {LLMs} Facilitate Onboarding Software Developers? An Ongoing Industrial Case Study},
	url = {https://ieeexplore.ieee.org/abstract/document/10662989},
	shorttitle = {Can {LLMs} Facilitate Onboarding Software Developers?},
	abstract = {Onboarding new software developers presents per-sistent challenges for teams, with newcomers facing steep learning curves and senior staff burdened by providing training and mentoring. This research explores leveraging Large Language Models ({LLMs}) to streamline onboarding, mitigating productivity losses from disrupted workflows. We collaborated with {LKS} Next, an {IT} consulting firm that has experienced first hand the challenges onboarding new developers brings. This paper presents an ongoing case study within {LKS} Next, conducted using action design research methodology. Two cycles have been completed, gathering feedback from newcomers, team leaders, and managers on issues like the need to prioritize self-directed learning resources over “burdening” mentors, and considerations around using third-party {LLMs}. The third cycle will focus on evaluating open source {LLMs} to maintain control within the company. Our envisioned goal is to develop an {LLM}-powered conversational agent, delivering tailored onboarding support while avoiding privacy risks.},
	eventtitle = {2024 36th International Conference on Software Engineering Education and Training ({CSEE}\&T)},
	pages = {1--6},
	booktitle = {2024 36th International Conference on Software Engineering Education and Training ({CSEE}\&T)},
	author = {Azanza, Maider and Pereira, Juanan and Irastorza, Arantza and Galdos, Aritz},
	urldate = {2025-04-12},
	date = {2024-07},
	note = {{ISSN}: 2377-570X},
	keywords = {Large language models, Companies, Pressing, Privacy, Productivity, Prototypes, Training},
	file = {Full Text PDF:/home/martin/Zotero/storage/R8DZYMSK/Azanza et al. - 2024 - Can LLMs Facilitate Onboarding Software Developers An Ongoing Industrial Case Study.pdf:application/pdf},
}

@misc{ionescu_multi-agent_2025,
	title = {A Multi-agent Onboarding Assistant based on Large Language Models, Retrieval Augmented Generation, and Chain-of-Thought},
	url = {http://arxiv.org/abs/2503.23421},
	abstract = {Effective onboarding in software engineering is crucial but difficult due to the fast-paced evolution of technologies. Traditional methods, like exploration and workshops, are costly, time-consuming, and quickly outdated in large projects. We propose the Onboarding Buddy system, which leverages large language models, retrieval augmented generation, and an automated chain-of-thought approach to improve onboarding. It integrates dynamic, context-specific support within the development environment, offering natural language explanations, code insights, and project guidance. Our solution is agent-based and provides customized assistance with minimal human intervention. Our study results among the eight participants show an average helpfulness rating of (M=3.26, {SD}=0.86) and ease of onboarding at (M=3.0, {SD}=0.96) out of four. While similar to tools like {GitHub} Copilot, Onboarding Buddy uniquely integrates a chain-of-thought reasoning mechanism with retrieval-augmented generation, tailored specifically for dynamic onboarding contexts. While our initial evaluation is based on eight participants within one project, we will explore larger teams and multiple real-world codebases in the company to demonstrate broader applicability. Overall, Onboarding Buddy holds great potential for enhancing developer productivity and satisfaction. Our tool, source code [7], and demonstration video [6] are publicly available.},
	number = {{arXiv}:2503.23421},
	publisher = {{arXiv}},
	author = {Ionescu, Andrei Cristian and Titov, Sergey and Izadi, Maliheh},
	urldate = {2025-04-12},
	date = {2025-03-30},
	langid = {english},
	keywords = {Computer Science - Software Engineering},
	file = {PDF:/home/martin/Zotero/storage/VVPGZFRS/Ionescu et al. - 2025 - A Multi-agent Onboarding Assistant based on Large Language Models, Retrieval Augmented Generation, a.pdf:application/pdf},
}

@inproceedings{sim_ramp-up_1998,
	title = {The ramp-up problem in software projects: a case study of how software immigrants naturalize},
	url = {https://ieeexplore.ieee.org/abstract/document/671389},
	shorttitle = {The ramp-up problem in software projects},
	abstract = {Joining a software development team is like moving to a new country to start employment; the immigrant has a lot to learn about the job, the local customs, and sometimes a new language. In an exploratory case study, we interviewed four software immigrants, in order to characterize their naturalization process. Seven patterns in four major categories were found. In this paper, these patterns are substantiated, and their implications discussed. The lessons learned from this study can be applied equally to improving the naturalization process, and to the formulation of further research questions.},
	eventtitle = {the 20th International Conference on Software Engineering},
	pages = {361--370},
	booktitle = {Proceedings of the 20th International Conference on Software Engineering},
	author = {Sim, S.E. and Holt, R.C.},
	urldate = {2025-04-12},
	date = {1998-04},
	note = {{ISSN}: 0270-5257},
	keywords = {Computer aided software engineering, Computer science, Costs, Educational institutions, Management training, Personnel, Programming, Recruitment, Software maintenance, Software systems},
	file = {Submitted Version:/home/martin/Zotero/storage/8K3NARXG/Sim and Holt - 1998 - The ramp-up problem in software projects a case study of how software immigrants naturalize.pdf:application/pdf},
}

@article{steinmacher_systematic_2015,
	title = {A systematic literature review on the barriers faced by newcomers to open source software projects},
	volume = {59},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584914002390},
	abstract = {Context
Numerous open source software projects are based on volunteers collaboration and require a continuous influx of newcomers for their continuity. Newcomers face barriers that can lead them to give up. These barriers hinder both developers willing to make a single contribution and those willing to become a project member.
Objective
This study aims to identify and classify the barriers that newcomers face when contributing to open source software projects.
Method
We conducted a systematic literature review of papers reporting empirical evidence regarding the barriers that newcomers face when contributing to open source software ({OSS}) projects. We retrieved 291 studies by querying 4 digital libraries. Twenty studies were identified as primary. We performed a backward snowballing approach, and searched for other papers published by the authors of the selected papers to identify potential studies. Then, we used a coding approach inspired by open coding and axial coding procedures from Grounded Theory to categorize the barriers reported by the selected studies.
Results
We identified 20 studies providing empirical evidence of barriers faced by newcomers to {OSS} projects while making a contribution. From the analysis, we identified 15 different barriers, which we grouped into five categories: social interaction, newcomers’ previous knowledge, finding a way to start, documentation, and technical hurdles. We also classified the problems with regard to their origin: newcomers, community, or product.
Conclusion
The results are useful to researchers and {OSS} practitioners willing to investigate or to implement tools to support newcomers. We mapped technical and non-technical barriers that hinder newcomers’ first contributions. The most evidenced barriers are related to socialization, appearing in 75\% (15 out of 20) of the studies analyzed, with a high focus on interactions in mailing lists (receiving answers and socialization with other members). There is a lack of in-depth studies on technical issues, such as code issues. We also noticed that the majority of the studies relied on historical data gathered from software repositories and that there was a lack of experiments and qualitative studies in this area.},
	pages = {67--85},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Steinmacher, Igor and Graciotto Silva, Marco Aurelio and Gerosa, Marco Aurelio and Redmiles, David F.},
	urldate = {2025-04-12},
	date = {2015-03-01},
	keywords = {Barriers to entry, Joining, Newcomers, Onboarding, Open source software, Systematic literature review},
	file = {ScienceDirect Snapshot:/home/martin/Zotero/storage/Z29BF2JA/S0950584914002390.html:text/html},
}

@inproceedings{ritz_artificial_2023,
	title = {Artificial Socialization? How Artificial Intelligence Applications Can Shape A New Era of Employee Onboarding Practices},
	url = {http://hdl.handle.net/10125/102648},
	shorttitle = {Artificial Socialization?},
	abstract = {Onboarding has always emphasized personal contact with new employees. Excellent onboarding can extend employee retention and improve loyalty. Even in a physical setting, the onboarding process is demanding for both the newcomer and the onboarding organization. Remote work, in contrast, has made this process even more challenging by forcing a rapid shift from offline to online onboarding practices. Organizations are adopting new technologies like artificial intelligence ({AI}) to support work processes, such as hiring processes or innovation facilitation, which could shape a new era of work practices. However, it has not been studied how {AI} applications can or should support onboarding. Therefore, our research conducts a literature review on current onboarding practices and uses expert interviews to evaluate {AI}'s potential and pitfalls for each action. We contribute to the literature by presenting a holistic picture of onboarding practices and assessing potential application areas of {AI} in the onboarding process.},
	eventtitle = {Hawaii International Conference on System Sciences},
	author = {Ritz, Eva and Donisi, Fabio and Elshan, Edona and Rietsche, Roman},
	urldate = {2025-04-12},
	date = {2023},
	langid = {english},
	file = {PDF:/home/martin/Zotero/storage/PAFRKIZS/Ritz et al. - 2023 - Artificial Socialization How Artificial Intelligence Applications Can Shape A New Era of Employee O.pdf:application/pdf},
}

@misc{yao_react_2023,
	title = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
	url = {http://arxiv.org/abs/2210.03629},
	shorttitle = {{ReAct}},
	abstract = {While large language models ({LLMs}) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of {LLMs} to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named {ReAct}, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering ({HotpotQA}) and fact verification (Fever), {ReAct} overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia {API}, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks ({ALFWorld} and {WebShop}), {ReAct} outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
	number = {{arXiv}:2210.03629},
	publisher = {{arXiv}},
	author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
	urldate = {2025-04-12},
	date = {2023-03-10},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/UXWIFLWG/Yao et al. - 2023 - ReAct Synergizing Reasoning and Acting in Language Models.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/L9C78XJC/2210.html:text/html},
}

@online{noauthor_model_nodate,
	title = {Model Context Protocol ({MCP})},
	url = {https://docs.anthropic.com/en/docs/agents-and-tools/mcp},
	titleaddon = {Anthropic},
	urldate = {2025-04-12},
	langid = {english},
	file = {Snapshot:/home/martin/Zotero/storage/5G3MA7IT/mcp.html:text/html},
}

@misc{wei_chain--thought_2023,
	title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
	url = {http://arxiv.org/abs/2201.11903},
	abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the {GSM}8K benchmark of math word problems, surpassing even finetuned {GPT}-3 with a verifier.},
	number = {{arXiv}:2201.11903},
	publisher = {{arXiv}},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
	urldate = {2025-04-12},
	date = {2023-01-10},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/martin/Zotero/storage/8MMWS6ZJ/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/X64CRP2B/2201.html:text/html},
}

@online{noauthor_number_2024,
	title = {Number of Parameters in {GPT}-4 (Latest Data)},
	url = {https://explodingtopics.com/blog/gpt-parameters},
	abstract = {An extensive list of statistics covering the number of parameters in {ChatGPT}-4, {ChatGPT}-4o, and other {AI} models.},
	titleaddon = {Exploding Topics},
	urldate = {2025-04-13},
	date = {2024-08-06},
	langid = {english},
	file = {Snapshot:/home/martin/Zotero/storage/QU5JTKX5/gpt-parameters.html:text/html},
}

@misc{zhang_building_2024-1,
	title = {Building Cooperative Embodied Agents Modularly with Large Language Models},
	url = {http://arxiv.org/abs/2307.02485},
	abstract = {In this work, we address challenging multi-agent cooperation problems with decentralized control, raw sensory observations, costly communication, and multi-objective tasks instantiated in various embodied environments. While previous research either presupposes a cost-free communication channel or relies on a centralized controller with shared observations, we harness the commonsense knowledge, reasoning ability, language comprehension, and text generation prowess of {LLMs} and seamlessly incorporate them into a cognitive-inspired modular framework that integrates with perception, memory, and execution. Thus building a Cooperative Embodied Language Agent {CoELA}, who can plan, communicate, and cooperate with others to accomplish long-horizon tasks efficiently. Our experiments on C-{WAH} and {TDW}-{MAT} demonstrate that {CoELA} driven by {GPT}-4 can surpass strong planning-based methods and exhibit emergent effective communication. Though current Open {LMs} like {LLAMA}-2 still underperform, we fine-tune a {CoELA} with data collected with our agents and show how they can achieve promising performance. We also conducted a user study for human-agent interaction and discovered that {CoELA} communicating in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of {LLMs} for future research in multi-agent cooperation. Videos can be found on the project website https://vis-www.cs.umass.edu/Co-{LLM}-Agents/.},
	number = {{arXiv}:2307.02485},
	publisher = {{arXiv}},
	author = {Zhang, Hongxin and Du, Weihua and Shan, Jiaming and Zhou, Qinhong and Du, Yilun and Tenenbaum, Joshua B. and Shu, Tianmin and Gan, Chuang},
	urldate = {2025-04-13},
	date = {2024-02-17},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {Preprint PDF:/home/martin/Zotero/storage/9EMF28H4/Zhang et al. - 2024 - Building Cooperative Embodied Agents Modularly with Large Language Models.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/W5JXWCS2/2307.html:text/html},
}

@misc{luo_repoagent_2024,
	title = {{RepoAgent}: An {LLM}-Powered Open-Source Framework for Repository-level Code Documentation Generation},
	url = {http://arxiv.org/abs/2402.16667},
	shorttitle = {{RepoAgent}},
	abstract = {Generative models have demonstrated considerable potential in software engineering, particularly in tasks such as code generation and debugging. However, their utilization in the domain of code documentation generation remains underexplored. To this end, we introduce {RepoAgent}, a large language model powered open-source framework aimed at proactively generating, maintaining, and updating code documentation. Through both qualitative and quantitative evaluations, we have validated the effectiveness of our approach, showing that {RepoAgent} excels in generating high-quality repository-level documentation. The code and results are publicly accessible at https://github.com/{OpenBMB}/{RepoAgent}.},
	number = {{arXiv}:2402.16667},
	publisher = {{arXiv}},
	author = {Luo, Qinyu and Ye, Yining and Liang, Shihao and Zhang, Zhong and Qin, Yujia and Lu, Yaxi and Wu, Yesai and Cong, Xin and Lin, Yankai and Zhang, Yingli and Che, Xiaoyin and Liu, Zhiyuan and Sun, Maosong},
	urldate = {2025-05-01},
	date = {2024-02-26},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/home/martin/Zotero/storage/FCVR9SIH/Luo et al. - 2024 - RepoAgent An LLM-Powered Open-Source Framework for Repository-level Code Documentation Generation.pdf:application/pdf;Snapshot:/home/martin/Zotero/storage/94DTV5UP/2402.html:text/html},
}

@online{noauthor_c4_nodate,
	title = {C4 - Abstractions},
	url = {https://c4model.com/abstractions},
	abstract = {The C4 model for visualising software architecture},
	titleaddon = {C4 model},
	urldate = {2025-05-01},
	langid = {american},
	file = {Snapshot:/home/martin/Zotero/storage/KJ5SJAAI/abstractions.html:text/html},
}
