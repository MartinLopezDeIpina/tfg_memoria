\begin{thebibliography}{10}

\bibitem{sim_ramp-up_1998}
S.E. Sim and R.C. Holt.
\newblock The ramp-up problem in software projects: a case study of how software immigrants naturalize.
\newblock In {\em Proceedings of the 20th International Conference on Software Engineering}, pages 361--370.
\newblock {ISSN}: 0270-5257.

\bibitem{steinmacher_systematic_2015}
Igor Steinmacher, Marco~Aurelio Graciotto~Silva, Marco~Aurelio Gerosa, and David~F. Redmiles.
\newblock A systematic literature review on the barriers faced by newcomers to open source software projects.
\newblock 59:67--85.

\bibitem{ritz_artificial_2023}
Eva Ritz, Fabio Donisi, Edona Elshan, and Roman Rietsche.
\newblock Artificial socialization? how artificial intelligence applications can shape a new era of employee onboarding practices.

\bibitem{azanza_can_2024}
Maider Azanza, Juanan Pereira, Arantza Irastorza, and Aritz Galdos.
\newblock Can {LLMs} facilitate onboarding software developers? an ongoing industrial case study.
\newblock In {\em 2024 36th International Conference on Software Engineering Education and Training ({CSEE}\&T)}, pages 1--6.
\newblock {ISSN}: 2377-570X.

\bibitem{ionescu_multi-agent_2025}
Andrei~Cristian Ionescu, Sergey Titov, and Maliheh Izadi.
\newblock A multi-agent onboarding assistant based on large language models, retrieval augmented generation, and chain-of-thought.

\bibitem{vaswani_attention_2023}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.

\bibitem{yao_react_2023}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
\newblock {ReAct}: Synergizing reasoning and acting in language models.

\bibitem{noauthor_model_nodate}
Model context protocol ({MCP}).

\bibitem{zhu_retrieving_2021}
Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, and Tat-Seng Chua.
\newblock Retrieving and reading: A comprehensive survey on open-domain question answering.

\bibitem{gao_retrieval-augmented_2024}
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi~Dai, Jiawei Sun, Meng Wang, and Haofen Wang.
\newblock Retrieval-augmented generation for large language models: A survey.

\bibitem{ma_query_nodate}
Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan.
\newblock Query rewriting for retrieval-augmented large language models.

\bibitem{levine_standing_2022}
Yoav Levine, Itay Dalmedigos, Ori Ram, Yoel Zeldes, Daniel Jannai, Dor Muhlgay, Yoni Osin, Opher Lieber, Barak Lenz, Shai Shalev-Shwartz, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham.
\newblock Standing on the shoulders of giant frozen language models.

\bibitem{khattab_relevance-guided_2021}
Omar Khattab, Christopher Potts, and Matei Zaharia.
\newblock Relevance-guided supervision for {OpenQA} with {ColBERT}.

\bibitem{khattab_demonstrate-search-predict_2023}
Omar Khattab, Keshav Santhanam, Xiang~Lisa Li, David Hall, Percy Liang, Christopher Potts, and Matei Zaharia.
\newblock Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive {NLP}.

\bibitem{shao_enhancing_2023}
Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen.
\newblock Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, {\em Findings of the Association for Computational Linguistics: {EMNLP} 2023}, pages 9248--9274. Association for Computational Linguistics.

\bibitem{qi_answering_2021}
Peng Qi, Haejun Lee, Oghenetegiri~"{TG}" Sido, and Christopher~D. Manning.
\newblock Answering open-domain questions of varying reasoning steps from text.

\bibitem{zheng_take_2024}
Huaixiu~Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed~H. Chi, Quoc~V. Le, and Denny Zhou.
\newblock Take a step back: Evoking reasoning via abstraction in large language models.

\bibitem{trivedi_interleaving_2023}
Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal.
\newblock Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.

\bibitem{wang_survey_2024}
Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu~Chen, Yankai Lin, Wayne~Xin Zhao, Zhewei Wei, and Jirong Wen.
\newblock A survey on large language model based autonomous agents.
\newblock 18(6):186345.

\bibitem{zhang_building_2024}
Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua~B. Tenenbaum, Tianmin Shu, and Chuang Gan.
\newblock Building cooperative embodied agents modularly with large language models.

\bibitem{fischer_reflective_2023}
Kevin~A. Fischer.
\newblock Reflective linguistic programming ({RLP}): A stepping stone in socially-aware {AGI} ({SocialAGI}).

\bibitem{liang_unleashing_2023}
Xinnian Liang, Bing Wang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu~Lu, Zejun Ma, and Zhoujun Li.
\newblock {\em Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System}.

\bibitem{zhao_expel_2024}
Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang.
\newblock {ExpeL}: {LLM} agents are experiential learners.
\newblock 38(17):19632--19642.
\newblock Number: 17.

\bibitem{zhong_memorybank_2024}
Wanjun Zhong, Lianghong Guo, Qiqi Gao, He~Ye, and Yanlin Wang.
\newblock {MemoryBank}: Enhancing large language models with long-term memory.
\newblock 38(17):19724--19731.
\newblock Number: 17.

\bibitem{park_generative_2023}
Joon~Sung Park, Joseph O'Brien, Carrie~Jun Cai, Meredith~Ringel Morris, Percy Liang, and Michael~S. Bernstein.
\newblock Generative agents: Interactive simulacra of human behavior.
\newblock In {\em Proceedings of the 36th Annual {ACM} Symposium on User Interface Software and Technology}, pages 1--22. {ACM}.

\bibitem{wei_chain--thought_2023}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed~Chi, Quoc Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language models.

\bibitem{yao_tree_nodate}
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas~L Griffiths, Yuan Cao, and Karthik Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language models.

\bibitem{wang_recmind_2024}
Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang.
\newblock {RecMind}: Large language model powered agent for recommendation.

\bibitem{shinn_reflexion_nodate}
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
\newblock Reflexion: Language agents with verbal reinforcement learning.

\bibitem{madaan_self-refine_nodate}
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa~Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark.
\newblock {SELF}-{REFINE}: Iterative refinement with self-feedback.

\bibitem{miao_selfcheck_2023}
Ning Miao, Yee~Whye Teh, and Tom Rainforth.
\newblock {SelfCheck}: Using {LLMs} to zero-shot check their own step-by-step reasoning.

\bibitem{lin_swiftsage_nodate}
Bill~Yuchen Lin, Yicheng Fu, Karina Yang, Faeze Brahman, Shiyu Huang, Chandra Bhagavatula, Prithviraj Ammanabrolu, Yejin Choi, and Xiang Ren.
\newblock {SWIFTSAGE}: A generative agent with fast and slow thinking for complex interactive tasks.

\bibitem{huang_language_nodate}
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.
\newblock Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.

\bibitem{wang_describe_2024}
Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, and Yitao Liang.
\newblock Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.

\bibitem{zhu_ghost_2023}
Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu~Qiao, Zhaoxiang Zhang, and Jifeng Dai.
\newblock Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory.

\bibitem{song_llm-planner_2023}
Chan~Hee Song, Brian~M. Sadler, Jiaman Wu, Wei-Lun Chao, Clayton Washington, and Yu~Su.
\newblock {LLM}-planner: Few-shot grounded planning for embodied agents with large language models.
\newblock In {\em 2023 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})}, pages 2986--2997. {IEEE}.

\bibitem{wang_voyager_2023}
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar.
\newblock Voyager: An open-ended embodied agent with large language models.

\bibitem{liu_odyssey_2024}
Shunyu Liu, Yaoru Li, Kongcheng Zhang, Zhenyu Cui, Wenkai Fang, Yuxuan Zheng, Tongya Zheng, and Mingli Song.
\newblock Odyssey: Empowering minecraft agents with open-world skills.

\bibitem{raman_planning_nodate}
Shreyas~Sundara Raman, Vanya Cohen, Eric Rosen, Ifrah Idrees, David Paulius, and Stefanie Tellex.
\newblock Planning with large language models via corrective re-prompting.

\bibitem{liu_llmp_2023}
{LLM}+p: Empowering large language models with optimal planning proficiency.

\bibitem{dagan_dynamic_2023}
Gautier Dagan, Frank Keller, and Alex Lascarides.
\newblock Dynamic planning with a {LLM}.

\bibitem{noauthor_deepseek-r1deepseek_r1pdf_nodate}
{DeepSeek}-r1/{DeepSeek}\_r1.pdf at main · deepseek-ai/{DeepSeek}-r1.

\bibitem{karpas_mrkl_2022}
Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua, and Moshe Tenenholtz.
\newblock {MRKL} systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.

\bibitem{ge_openagi_nodate}
Yingqiang Ge, Wenyue Hua, Kai Mei, Jianchao Ji, Juntao Tan, Shuyuan Xu, Zelong Li, and Yongfeng Zhang.
\newblock {OpenAGI}: When {LLM} meets domain experts.

\bibitem{zhuge_mindstorms_2023}
Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan~R. Ashley, Róbert Csordás, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al~Kader Hammoud, Vincent Herrmann, Kazuki Irie, Louis Kirsch, Bing Li, Guohao Li, Shuming Liu, Jinjie Mai, Piotr Piękos, Aditya Ramesh, Imanol Schlag, Weimin Shi, Aleksandar Stanić, Wenyi Wang, Yuhui Wang, Mengmeng Xu, Deng-Ping Fan, Bernard Ghanem, and Jürgen Schmidhuber.
\newblock Mindstorms in natural language-based societies of mind.

\bibitem{du_improving_nodate}
Yilun Du, Shuang Li, Antonio Torralba, Joshua~B Tenenbaum, and Igor Mordatch.
\newblock Improving factuality and reasoning in language models through multiagent debate.

\bibitem{qian_chatdev_2024}
Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu, and Maosong Sun.
\newblock {ChatDev}: Communicative agents for software development.

\bibitem{hong_metagpt_2024}
Sirui Hong, Mingchen Zhuge, Jiaqi Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka~Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber.
\newblock {MetaGPT}: Meta programming for a multi-agent collaborative framework.

\bibitem{kalliamvakou_research_2022}
Eirini Kalliamvakou.
\newblock Research: quantifying {GitHub} copilot’s impact on developer productivity and happiness.

\bibitem{noauthor_github_nodate}
{GitHub} copilot features.

\bibitem{noauthor_sourcegraphscip_2025}
sourcegraph/scip.
\newblock original-date: 2022-05-10T13:18:47Z.

\bibitem{noauthor_sourcegraphsourcegraph-public-snapshot_nodate}
sourcegraph/sourcegraph-public-snapshot: Code {AI} platform with code search \& cody.

\bibitem{acharya_devin_2025}
Kamal Acharya.
\newblock Devin: A cautionary tale of the autonomous {AI} engineer.

\bibitem{noauthor_building_2023}
Building a better repository map with tree sitter.

\bibitem{chen_fireact_2023}
Baian Chen, Chang Shu, Ehsan Shareghi, Nigel Collier, Karthik Narasimhan, and Shunyu Yao.
\newblock {FireAct}: Toward language agent fine-tuning.

\bibitem{zeng_agenttuning_2023}
Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, and Jie Tang.
\newblock {AgentTuning}: Enabling generalized agent abilities for {LLMs}.

\bibitem{chen_agent-flan_2024}
Zehui Chen, Kuikun Liu, Qiuchen Wang, Wenwei Zhang, Jiangning Liu, Dahua Lin, Kai Chen, and Feng Zhao.
\newblock Agent-{FLAN}: Designing data and methods of effective agent tuning for large language models.

\bibitem{hu_lora_2021}
Edward~J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen.
\newblock {LoRA}: Low-rank adaptation of large language models.

\end{thebibliography}
