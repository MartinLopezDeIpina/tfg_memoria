\begin{thebibliography}{10}

\bibitem{sim_ramp-up_1998}
S.E. Sim and R.C. Holt.
\newblock The ramp-up problem in software projects: a case study of how software immigrants naturalize.
\newblock In {\em Proceedings of the 20th International Conference on Software Engineering}, pages 361--370.
\newblock {ISSN}: 0270-5257.

\bibitem{steinmacher_systematic_2015}
Igor Steinmacher, Marco~Aurelio Graciotto~Silva, Marco~Aurelio Gerosa, and David~F. Redmiles.
\newblock A systematic literature review on the barriers faced by newcomers to open source software projects.
\newblock 59:67--85.

\bibitem{ritz_artificial_2023}
Eva Ritz, Fabio Donisi, Edona Elshan, and Roman Rietsche.
\newblock Artificial socialization? how artificial intelligence applications can shape a new era of employee onboarding practices.

\bibitem{azanza_can_2024}
Maider Azanza, Juanan Pereira, Arantza Irastorza, and Aritz Galdos.
\newblock Can {LLMs} facilitate onboarding software developers? an ongoing industrial case study.
\newblock In {\em 2024 36th International Conference on Software Engineering Education and Training ({CSEE}\&T)}, pages 1--6.
\newblock {ISSN}: 2377-570X.

\bibitem{ionescu_multi-agent_2025}
Andrei~Cristian Ionescu, Sergey Titov, and Maliheh Izadi.
\newblock A multi-agent onboarding assistant based on large language models, retrieval augmented generation, and chain-of-thought.

\bibitem{vaswani_attention_2023}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.

\bibitem{yao_react_2023}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
\newblock {ReAct}: Synergizing reasoning and acting in language models.

\bibitem{noauthor_model_nodate}
Model context protocol ({MCP}).

\bibitem{zhu_retrieving_2021}
Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, and Tat-Seng Chua.
\newblock Retrieving and reading: A comprehensive survey on open-domain question answering.

\bibitem{gao_retrieval-augmented_2024}
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi~Dai, Jiawei Sun, Meng Wang, and Haofen Wang.
\newblock Retrieval-augmented generation for large language models: A survey.

\bibitem{ma_query_nodate}
Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan.
\newblock Query rewriting for retrieval-augmented large language models.

\bibitem{levine_standing_2022}
Yoav Levine, Itay Dalmedigos, Ori Ram, Yoel Zeldes, Daniel Jannai, Dor Muhlgay, Yoni Osin, Opher Lieber, Barak Lenz, Shai Shalev-Shwartz, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham.
\newblock Standing on the shoulders of giant frozen language models.

\bibitem{khattab_relevance-guided_2021}
Omar Khattab, Christopher Potts, and Matei Zaharia.
\newblock Relevance-guided supervision for {OpenQA} with {ColBERT}.

\bibitem{khattab_demonstrate-search-predict_2023}
Omar Khattab, Keshav Santhanam, Xiang~Lisa Li, David Hall, Percy Liang, Christopher Potts, and Matei Zaharia.
\newblock Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive {NLP}.

\bibitem{shao_enhancing_2023}
Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen.
\newblock Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, {\em Findings of the Association for Computational Linguistics: {EMNLP} 2023}, pages 9248--9274. Association for Computational Linguistics.

\bibitem{qi_answering_2021}
Peng Qi, Haejun Lee, Oghenetegiri~"{TG}" Sido, and Christopher~D. Manning.
\newblock Answering open-domain questions of varying reasoning steps from text.

\bibitem{zheng_take_2024}
Huaixiu~Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed~H. Chi, Quoc~V. Le, and Denny Zhou.
\newblock Take a step back: Evoking reasoning via abstraction in large language models.

\bibitem{trivedi_interleaving_2023}
Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal.
\newblock Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.

\bibitem{wang_survey_2024}
Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu~Chen, Yankai Lin, Wayne~Xin Zhao, Zhewei Wei, and Jirong Wen.
\newblock A survey on large language model based autonomous agents.
\newblock 18(6):186345.

\bibitem{zhang_building_2024}
Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua~B. Tenenbaum, Tianmin Shu, and Chuang Gan.
\newblock Building cooperative embodied agents modularly with large language models.

\bibitem{fischer_reflective_2023}
Kevin~A. Fischer.
\newblock Reflective linguistic programming ({RLP}): A stepping stone in socially-aware {AGI} ({SocialAGI}).

\bibitem{liang_unleashing_2023}
Xinnian Liang, Bing Wang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu~Lu, Zejun Ma, and Zhoujun Li.
\newblock {\em Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System}.

\bibitem{zhao_expel_2024}
Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang.
\newblock {ExpeL}: {LLM} agents are experiential learners.
\newblock 38(17):19632--19642.
\newblock Number: 17.

\bibitem{zhong_memorybank_2024}
Wanjun Zhong, Lianghong Guo, Qiqi Gao, He~Ye, and Yanlin Wang.
\newblock {MemoryBank}: Enhancing large language models with long-term memory.
\newblock 38(17):19724--19731.
\newblock Number: 17.

\bibitem{park_generative_2023}
Joon~Sung Park, Joseph O'Brien, Carrie~Jun Cai, Meredith~Ringel Morris, Percy Liang, and Michael~S. Bernstein.
\newblock Generative agents: Interactive simulacra of human behavior.
\newblock In {\em Proceedings of the 36th Annual {ACM} Symposium on User Interface Software and Technology}, pages 1--22. {ACM}.

\bibitem{wei_chain--thought_2023}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed~Chi, Quoc Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language models.

\bibitem{yao_tree_nodate}
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas~L Griffiths, Yuan Cao, and Karthik Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language models.

\bibitem{wang_recmind_2024}
Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang.
\newblock {RecMind}: Large language model powered agent for recommendation.

\bibitem{shinn_reflexion_nodate}
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
\newblock Reflexion: Language agents with verbal reinforcement learning.

\bibitem{madaan_self-refine_nodate}
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa~Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark.
\newblock {SELF}-{REFINE}: Iterative refinement with self-feedback.

\bibitem{miao_selfcheck_2023}
Ning Miao, Yee~Whye Teh, and Tom Rainforth.
\newblock {SelfCheck}: Using {LLMs} to zero-shot check their own step-by-step reasoning.

\bibitem{lin_swiftsage_nodate}
Bill~Yuchen Lin, Yicheng Fu, Karina Yang, Faeze Brahman, Shiyu Huang, Chandra Bhagavatula, Prithviraj Ammanabrolu, Yejin Choi, and Xiang Ren.
\newblock {SWIFTSAGE}: A generative agent with fast and slow thinking for complex interactive tasks.

\bibitem{huang_language_nodate}
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.
\newblock Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.

\bibitem{wang_describe_2024}
Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, and Yitao Liang.
\newblock Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.

\bibitem{zhu_ghost_2023}
Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu~Qiao, Zhaoxiang Zhang, and Jifeng Dai.
\newblock Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory.

\bibitem{song_llm-planner_2023}
Chan~Hee Song, Brian~M. Sadler, Jiaman Wu, Wei-Lun Chao, Clayton Washington, and Yu~Su.
\newblock {LLM}-planner: Few-shot grounded planning for embodied agents with large language models.
\newblock In {\em 2023 {IEEE}/{CVF} International Conference on Computer Vision ({ICCV})}, pages 2986--2997. {IEEE}.

\bibitem{wang_voyager_2023}
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar.
\newblock Voyager: An open-ended embodied agent with large language models.

\bibitem{liu_odyssey_2024}
Shunyu Liu, Yaoru Li, Kongcheng Zhang, Zhenyu Cui, Wenkai Fang, Yuxuan Zheng, Tongya Zheng, and Mingli Song.
\newblock Odyssey: Empowering minecraft agents with open-world skills.

\bibitem{raman_planning_nodate}
Shreyas~Sundara Raman, Vanya Cohen, Eric Rosen, Ifrah Idrees, David Paulius, and Stefanie Tellex.
\newblock Planning with large language models via corrective re-prompting.

\bibitem{liu_llmp_2023}
{LLM}+p: Empowering large language models with optimal planning proficiency.

\bibitem{dagan_dynamic_2023}
Gautier Dagan, Frank Keller, and Alex Lascarides.
\newblock Dynamic planning with a {LLM}.

\bibitem{noauthor_deepseek-r1deepseek_r1pdf_nodate}
{DeepSeek}-r1/{DeepSeek}\_r1.pdf at main Â· deepseek-ai/{DeepSeek}-r1.

\bibitem{karpas_mrkl_2022}
Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua, and Moshe Tenenholtz.
\newblock {MRKL} systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.

\bibitem{ge_openagi_nodate}
Yingqiang Ge, Wenyue Hua, Kai Mei, Jianchao Ji, Juntao Tan, Shuyuan Xu, Zelong Li, and Yongfeng Zhang.
\newblock {OpenAGI}: When {LLM} meets domain experts.

\bibitem{zhuge_mindstorms_2023}
Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan~R. Ashley, RÃ³bert CsordÃ¡s, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al~Kader Hammoud, Vincent Herrmann, Kazuki Irie, Louis Kirsch, Bing Li, Guohao Li, Shuming Liu, Jinjie Mai, Piotr PiÄkos, Aditya Ramesh, Imanol Schlag, Weimin Shi, Aleksandar StaniÄ, Wenyi Wang, Yuhui Wang, Mengmeng Xu, Deng-Ping Fan, Bernard Ghanem, and JÃ¼rgen Schmidhuber.
\newblock Mindstorms in natural language-based societies of mind.

\bibitem{du_improving_nodate}
Yilun Du, Shuang Li, Antonio Torralba, Joshua~B Tenenbaum, and Igor Mordatch.
\newblock Improving factuality and reasoning in language models through multiagent debate.

\bibitem{qian_chatdev_2024}
Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu, and Maosong Sun.
\newblock {ChatDev}: Communicative agents for software development.

\bibitem{hong_metagpt_2024}
Sirui Hong, Mingchen Zhuge, Jiaqi Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka~Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and JÃ¼rgen Schmidhuber.
\newblock {MetaGPT}: Meta programming for a multi-agent collaborative framework.

\bibitem{kalliamvakou_research_2022}
Eirini Kalliamvakou.
\newblock Research: quantifying {GitHub} copilotâs impact on developer productivity and happiness.

\bibitem{noauthor_github_nodate}
{GitHub} copilot features.

\bibitem{noauthor_sourcegraphscip_2025}
sourcegraph/scip.
\newblock original-date: 2022-05-10T13:18:47Z.

\bibitem{noauthor_sourcegraphsourcegraph-public-snapshot_nodate}
sourcegraph/sourcegraph-public-snapshot: Code {AI} platform with code search \& cody.

\bibitem{acharya_devin_2025}
Kamal Acharya.
\newblock Devin: A cautionary tale of the autonomous {AI} engineer.

\bibitem{noauthor_building_2023}
Building a better repository map with tree sitter.

\bibitem{chen_fireact_2023}
Baian Chen, Chang Shu, Ehsan Shareghi, Nigel Collier, Karthik Narasimhan, and Shunyu Yao.
\newblock {FireAct}: Toward language agent fine-tuning.

\bibitem{zeng_agenttuning_2023}
Aohan Zeng, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, and Jie Tang.
\newblock {AgentTuning}: Enabling generalized agent abilities for {LLMs}.

\bibitem{chen_agent-flan_2024}
Zehui Chen, Kuikun Liu, Qiuchen Wang, Wenwei Zhang, Jiangning Liu, Dahua Lin, Kai Chen, and Feng Zhao.
\newblock Agent-{FLAN}: Designing data and methods of effective agent tuning for large language models.

\bibitem{hu_lora_2021}
Edward~J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen.
\newblock {LoRA}: Low-rank adaptation of large language models.

\end{thebibliography}
