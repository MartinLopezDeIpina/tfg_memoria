Completado el ciclo de desarrollo del proyecto, este capítulo ofrece una síntesis reflexiva del trabajo realizado. Se presentan las conclusiones principales y el repaso de los objetivos, junto con las lecciones aprendidas durante el proceso. Finalmente, se abordan las líneas futuras relacionadas con el proyecto.

\section{Conclusiones}
En este apartado se exponen las conclusiones respecto al uso de agentes LLM en el proceso de incorporación a proyectos software. Primero se presenta una valoración global, para posteriormente extraer conclusiones acerca del protocolo MCP y los mecanismos de orquestación utilizados.

\subsection{Líneas generales}
En términos generales, los agentes han demostrado la capacidad de responder con información valiosa a las preguntas formuladas, obteniendo en ocasiones una precisión superior al 80\% sobre el dataset derivado de la elicitación de preguntas. Constituyen una herramienta eficaz para buscar y sintetizar grandes cantidades de información dispersa en múltiples fuentes (código fuente, documentación, sistemas de gestión de tareas), tarea de gran importancia en procesos de incorporación que requieren una fase de aprendizaje.

No obstante, estas herramientas presentan limitaciones que impiden considerarlas fuentes de información irrefutables. Las evaluaciones revelan que en determinadas ocasiones, los agentes no logran identificar todas las fuentes de información disponibles, además de ocasionalmente generar alucinaciones. Por este motivo, el presente proyecto propone utilizar dichas herramientas como sistemas de búsqueda y fuentes de información complementarias, requiriendo siempre la supervisión y validación humana.

\subsection{Protocolo MCP}
Esta especificación ha demostrado ser de gran utilidad para el proyecto, por la flexibilidad que proporciona emplear un protocolo común para todas las herramientas, su eficacia para integrar herramientas desarrolladas por terceros, y su facilidad de uso mediante un SDK que permite desarrollar clientes y servidores con una dedicación mínima. Dichos beneficios explican su rápida adopción en el sector desde el inicio del presente proyecto\footnote{Google recomienda MCP: \url{https://cloud.google.com/blog/products/ai-machine-learning/build-multilingual-chatbots-with-gemini-gemma-and-mcp}}\footnote{MCP en Windows: \url{https://blogs.windows.com/windowsexperience/2025/05/19/securing-the-model-context-protocol-building-a-safer-agentic-future-on-windows/}}\footnote{MCP en OpenAI Agents SDK: \url{https://openai.github.io/openai-agents-python/mcp/}}, consolidándose como un estándar robusto cuya adopción resulta recomendable.

Por otro lado, al tratarse de un protocolo relativamente reciente, la disponibilidad de servidores MCP para herramientas específicas puede resultar limitada, requiriendo en ocasiones el desarrollo de adaptadores personalizados. 

\subsection{Orquestación de agentes}
\label{sec:conc}
Los resultados de evaluación permiten reflexionar sobre la división de la comunicación entre agentes. Parece evidente que los agentes cuya función consiste en extraer información sobre una temática concreta no deberían disponer de información sobre la perspectiva general de la consulta pertinente. Sin embargo, la cuestión radica en determinar de cuánta información deberían disponer los agentes encargados de distribuir la ejecución del sistema.

El presente proyecto ha concluido que cuanta más información contenga el agente decisor, más fundamentadas resultarán sus decisiones. No obstante, al degradarse la precisión de los LLM conforme aumenta la información de entrada, esta estrategia no resulta viable para los casos más complejos. Queda pendiente explorar, entonces, el punto óptimo donde dividir la fase de orquestación o decisión en varias etapas independientes.


\section{Objetivos del proyecto}
A continuación se enumeran los objetivos establecidos al inicio del proyecto junto a su grado de cumplimiento:
\begin{itemize}
\item\textbf{Estudio de arquitecturas agénticas: }este objetivo comprendió el análisis de diversas arquitecturas presentadas en la Sección \ref{sec:estado_arte}, evaluando varias implementaciones de RAG, diferentes variaciones de planificación y orquestación, y un módulo adicional de memoria.
\item\textbf{Desarrollo de sistema de Onboarding: }el sistema propuesto ha sido implementado y evaluado satisfactoriamente. Para ello, se ha seguido en la medida de lo posible la metodología de trabajo de LKS Next, utilizando los recursos propietarios disponibles y la elicitación de preguntas realizada para su evaluación.
\item\textbf{Integración del Model Context Protocol: }la implementación fue diseñada para la incorporación de dicho protocolo, desarrollando varios servidores y clientes MCP, y utilizándolo para las herramientas de los agentes especializados.
\item\textbf{Evaluación de agentes: }se ha desarrollado el sistema de evaluación automatizado expuesto en el capítulo \ref{ch:chap9}, mediante la librería LangSmith y un conjunto de datos anotado manualmente, incorporando varias métricas personalizadas.
\item\textbf{Valoración de ajuste de agentes: }fue cumplido ajustando y evaluando un modelo específico para su integración en el flujo agéntico (véase Sección \ref{sec:adaptativo}). Dicha valoración ha proporcionado un ejemplo de integración sencilla que permite entrever el potencial detrás de este tipo de optimizaciones.
\end{itemize}

\section{Lecciones aprendidas}
El desarrollo del presente proyecto ha proporcionado una valiosa lección sobre la gestión de proyectos. Esta se fundamenta en la distribución eficiente del tiempo para focalizar los esfuerzos en los aspectos más relevantes para el cumplimiento de objetivos.

Es habitual considerar un proyecto como una obra personal y, por tanto, buscar optimizar todos sus aspectos para realizar el mejor trabajo posible. Dicha filosofía puede conllevar centrar un esfuerzo excesivo en detalles que, aunque importantes, no tienen el impacto final que otros aspectos sí poseen. Por ello, los esfuerzos deben centrarse en las tareas que resulten óptimas para la consecución de objetivos, ya que, independientemente de la dedicación horaria, los recursos disponibles son siempre limitados.

Por ejemplo, en este proyecto se invirtió una cantidad considerable de tiempo investigando e implementando un agente de código cuya funcionalidad RAG considerase la estructura del código fuente. Si bien esto contribuyó al cumplimiento de los objetivos del proyecto, desde una perspectiva general, un agente más simple podría haber realizado la misma labor exploratoria.

\section{Líneas futuras}
A continuación se enumeran algunas posibles direcciones de investigación en el ámbito de los agentes LLM aplicados al Onboarding:
\paragraph{Exploración de embedders especializados} Este proyecto ha realizado una indexación del código junto a su contexto y documentación para una captura semántica contextualizada. Sin embargo, otras estrategias proponen el uso de sistemas de vectorización especializados. Por ejemplo, recientemente Mistral ha presentado un codificador específicamente ajustado para la captura semántica de código \cite{noauthor_codestral_nodate}.

El ajuste fino de un modelo de codificación para su uso agéntico resulta más preciso que uno genérico \cite{khattab_relevance-guided_2021,xiong_approximate_2020,yu_augmentation-adapted_2023}, pero requiere de un trabajo adicional. Una exploración subsiguiente podría comparar la estrategia del proyecto actual, un embedder especializado en código, y un embedder especializado en tareas de Onboarding.

\paragraph{Optimización de orquestación} En la Sección \ref{sec:conc} se ha especulado sobre un punto de inflexión donde separar la fase de planificación en varias etapas conllevaría beneficios. Otro proyecto podría explorar un sistema más complejo, con preguntas más amplias, que genere reportes detallados. Este enfoque seguiría el modelo de sistemas como Deep Research\footnote{Deep Research: \url{https://openai.com/index/introducing-deep-research/}} de OpenAI, aplicándolo sobre repositorios empresariales que involucren diferentes proyectos, o incluso toda la información disponible de la empresa.

\paragraph{Ajuste de agentes} En una línea de investigación complementaria, otro trabajo podría explorar el ajuste de modelos para tareas agénticas especializadas en el Onboarding. Esto incluiría entrenar un modelo para buscar en la base de conocimientos de la empresa, o incluso entrenarlo directamente sobre dicha base de conocimientos de modo que incorpore la información sin requerir búsquedas externas.
