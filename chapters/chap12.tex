Completado el ciclo de desarrollo del proyecto, este capítulo ofrece una síntesis reflexiva del trabajo realizado. Se presentan las conclusiones principales y el repaso de los objetivos, junto con las lecciones aprendidas durante el proceso. Finalmente, se exponen las líneas futuras relacionadas con el proyecto y el ámbito de investigación.

\section{Conclusiones}
En este apartado se presentan las conclusiones obtenidas respecto al uso de los agentes LLM en el proceso de incorporación a proyectos software. Primero se expone una valoración global, para posteriormente analizar el protocolo MCP y los mecanismos de orquestación de agentes.

\subsection{Líneas generales}
En términos generales, los agentes han demostrado la capacidad de responder con información valiosa a las preguntas formuladas. Constituyen una herramienta eficaz para buscar y sintetizar grandes cantidades de información, tarea de gran importancia en procesos de incorporación que requieren un aprendizaje intensivo.

No obstante, estas herramientas presentan limitaciones que impiden considerarlas fuentes de información irrefutables. Las evaluaciones revelan que en determinadas ocasiones, los agentes no logran identificar todas las fuentes de información disponibles, además de presentar errores en las citas o generar alucinaciones. Por este motivo, el presente proyecto propone utilizar dichas herramientas como fuentes de información complementarias o sistemas de búsqueda, manteniendo siempre la supervisión y validación humana.

\subsection{Protocolo MCP}
Este protocolo ha demostrado ser de gran utilidad para el proyecto. Su amplia adopción en la industria durante el desarrollo de este trabajo sugiere que constituye una herramienta robusta cuya adopción resulta recomendable, como evidencian la recomendación de Google para el uso de MCP con sus modelos\footnote{Google recomienda MCP: \url{https://cloud.google.com/blog/products/ai-machine-learning/build-multilingual-chatbots-with-gemini-gemma-and-mcp}}, la integración del protocolo por parte de Microsoft en Windows 11\footnote{MCP en Windows: \url{https://blogs.windows.com/windowsexperience/2025/05/19/securing-the-model-context-protocol-building-a-safer-agentic-future-on-windows/}} e incluso la adopción por parte de OpenAI, competidor directo de Anthropic, en su SDK de agentes\footnote{MCP en OpenAI Agents SDK: \url{https://openai.github.io/openai-agents-python/mcp/}}.

La especificación ha resultado eficaz para la integración de herramientas desarrolladas previamente por terceros, como las del agente Confluence, sin requerir modificaciones. Destaca la flexibilidad que proporciona, ya que al emplear consistentemente el protocolo MCP, la gestión de herramientas sigue un procedimiento uniforme en todos los agentes. Asimismo, su facilidad de uso resulta notable, puesto que el SDK permite desarrollar clientes y servidores MCP con una dedicación mínima.

Por otro lado, al tratarse de un protocolo relativamente reciente, la disponibilidad de servidores MCP para herramientas específicas puede resultar limitada, requiriendo en ocasiones el desarrollo de adaptadores personalizados.

\subsection{Orquestación de agentes}
\label{sec:conc}
Los resultados de evaluación permiten reflexionar sobre la división de la comunicación entre los agentes. Parece evidente que los agentes cuya función consiste en extraer información sobre una temática concreta no deberían disponer de información sobre la perspectiva general de la consulta pertinente. Sin embargo, la cuestión radica en determinar de cuánta información deberían disponer los agentes encargados de distribuir la ejecución del sistema.

El presente proyecto ha concluido que cuanta mayor información contenga el agente decisor, más fundamentadas resultarán sus decisiones. No obstante, al degradarse la precisión de los LLM conforme aumenta la información de entrada, esta estrategia no resulta viable para los casos más complejos. Queda pendiente explorar, entonces, el punto óptimo donde dividir la fase de orquestación o decisión en varias etapas independientes.


\section{Objetivos del proyecto}
A continuación se enumeran los objetivos establecidos al inicio del proyecto y su grado de cumplimiento:
\begin{itemize}
\item\textbf{Estudio de arquitecturas agénticas: }este objetivo comprendió el análisis de diversas arquitecturas presentadas en la Sección \ref{sec:estado_arte}, evaluando varias implementaciones de RAG, diferentes variaciones de planificación y orquestación, y un módulo adicional de memoria.
\item\textbf{Desarrollo de sistema de Onboarding: }el sistema propuesto ha sido implementado y evaluado satisfactoriamente. Para ello, se ha seguido en la medida de lo posible la metodología de trabajo de LKS Next, utilizando los recursos propietarios disponibles y la elicitación de preguntas realizada para su evaluación.
\item\textbf{Integración del Model Context Protocol: }la implementación fue diseñado para la incorporación de dicho protocolo, desarrollando varios servidores y clientes MCP, y utilizándolo en las herramientas de los agentes especializados.
\item\textbf{Evaluación de agentes: }se ha desarrollado el sistema de evaluación automatizado expuesto en el capítulo \ref{ch:chap9}, mediante la evaluación de LangSmith y un conjunto de datos anotado manualmente, incorporando varias métricas personalizadas.
\item\textbf{Valoración de ajuste de agentes: }fue cumplido ajustando y evaluando un modelo específico para su integración en el flujo agéntico (véase Sección \ref{sec:ajuste_modelo}). Dicha valoración ha proporcionado un ejemplo de integración sencilla que permite entrever el potencial detrás de este tipo de optimizaciones.
\end{itemize}

\section{Lecciones aprendidas}
El desarrollo del presente proyecto ha proporcionado una valiosa lección sobre la gestión de proyectos. Esta se fundamenta en la distribución eficiente del tiempo para focalizar los esfuerzos en los aspectos más relevantes para el cumplimiento de objetivos.

Es habitual considerar un proyecto como una obra personal y, por tanto, buscar optimizar todos sus aspectos para realizar el mejor trabajo posible. Dicha filosofía puede conllevar centrar un esfuerzo excesivo en detalles que, aunque importantes, no tienen el impacto final que otros aspectos sí poseen. Por ello, los esfuerzos deben centrarse en las tareas que resulten óptimas para la consecución de objetivos, ya que, independientemente de la dedicación horaria, los recursos disponibles son siempre limitados.

Por ejemplo, en este proyecto se invirtió una cantidad considerable de tiempo investigando e implementando un agente de código cuya funcionalidad RAG considerase la estructura del código fuente. Si bien esto contribuyó al cumplimiento de los objetivos del proyecto, desde una perspectiva general, un agente más simple podría haber realizado la misma labor exploratoria.

\section{Líneas futuras}
A continuación se enumeran algunas posibles direcciones de investigación en el ámbito de los agentes LLM aplicados al Onboarding:
\paragraph{Exploración de embedders especializados} Este proyecto ha realizado una indexación del código junto a su contexto y documentación para una captura semántica contextualizada. Sin embargo, otras estrategias proponen el uso de embedders de código personalizados. Por ejemplo, el pasado 25 de mayo, Mistral presentó un embedder específicamente ajustado para la captura semántica de código \cite{noauthor_codestral_nodate}.

El ajuste fino de un embedder para su uso agéntico resulta más preciso que uno genérico \cite{khattab_relevance-guided_2021,xiong_approximate_2020,yu_augmentation-adapted_2023}, pero requiere de un trabajo adicional. Una exploración subsiguiente podría comparar la estrategia del proyecto actual, un embedder especializado en código, y un embedder especializado en tareas de Onboarding.

\paragraph{Optimización de orquestación} En la Sección \ref{sec:conc} se ha especulado sobre un punto de inflexión donde separar la fase de planificación en varias etapas conllevaría beneficios. Otro proyecto podría explorar un sistema más complejo, con preguntas más amplias, que generen reportes detallados. Dicho sistema imitaría sistemas como Deep Research\footnote{Deep Research: \url{https://openai.com/index/introducing-deep-research/}} de OpenAI, pero aplicado sobre un repositorio empresarial que involucre diferentes proyectos, o incluso toda la información disponible de la empresa.

\paragraph{Ajuste de agentes} En una línea de investigación complementaria, otro trabajo puede explorar el ajuste de modelos para tareas agénticas especializadas en el Onboarding. Esto incluiría entrenar un modelo para buscar en la base de conocimientos de la empresa, o incluso integrarlo con la propia base de conocimientos de modo que no requiera buscar información adicional.
